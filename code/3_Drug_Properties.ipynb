{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Properties of drugs\n",
    "Find various properties of the individual drugs  \n",
    "  \n",
    "1.) ATC  \n",
    "2.) GO Annotations  \n",
    "3.) Disease   \n",
    "4.) KeGG Pathways  \n",
    "5.) SIDER (known effects)  \n",
    "6.) Offside (known off sides)  \n",
    "7.) TwoSides  \n",
    "8.) Drug Properties (physico-chemical properties)  \n",
    "9.) Enzymes, Transporters and Carriers  \n",
    "10.) Chemical_Gentic Perturbations (MsigDB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ATC \n",
    "Extract information about the anatomical as well as therapeutic group a drug is associated to using DrugBank as main source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  networkx as nx\n",
    "\n",
    "#The the ATC classification from drugbank (see python file: 2a_Create_DrugBank_Network.ipynb)\n",
    "DrugBankInfo = nx.read_gml('../data/Drug_Properties/Drugbank_2018-07-03_CLOUD_Only.gml')\n",
    "print 'DrugBank Network loaded'\n",
    "\n",
    "#Create output file\n",
    "fp_out = open('../results/Drug_Properties/CLOUD_to_ATC.csv','w')\n",
    "fp_out.write('CLOUD,DrugBankID,First_Level_ATCs,Second_Level_ATCs\\n')\n",
    "\n",
    "#Dictionary containing DrugBank to CLOUD identifier\n",
    "DrugBank_to_CLOUD = {}\n",
    "#parse through all CLOUD drugs and check for ATC code annotation in drugbank (Use first and second level; third level and below too specific)\n",
    "fp = open('../data/Drug_Properties/CLOUD_DrugBank_PubChem_Chembl.csv','r')\n",
    "fp.next()\n",
    "for line in fp:\n",
    "    tmp = line.strip().split(',')\n",
    "    DrugBank_to_CLOUD[tmp[1]] = tmp[0]\n",
    "    first_level = set()\n",
    "    fist_second_level = set()\n",
    "    if DrugBankInfo.has_node(tmp[1]):\n",
    "        if DrugBankInfo.node[tmp[1]].has_key('ATCcode'):\n",
    "            atc_codes =  DrugBankInfo.node[tmp[1]]['ATCcode'].split(',')\n",
    "            if '' in atc_codes:\n",
    "                atc_codes.remove('')\n",
    "\n",
    "            for atc in atc_codes:\n",
    "                atc = atc.strip()\n",
    "                first_level.add(atc[0])\n",
    "                fist_second_level.add(atc[0:3])\n",
    "\n",
    "    fp_out.write(tmp[0]+','+tmp[1]+','+';'.join(first_level)+','+';'.join(fist_second_level)+'\\n')\n",
    "\n",
    "fp.close()\n",
    "fp_out.close()\n",
    "\n",
    "print 'Finished ATC annotations'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. GO Annotations\n",
    "Extract GO annotations from GeneOntology for the targets of the individual drugs. Not only leaf but also upstream term information is collected for the three branches (i) Function, (ii) Component, (iii) Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use our inhouse database and the corresponding python file to create the upward ontology for every leaf GO term (all get included)\n",
    "#Download (http://www.geneontology.org/page/downloads)\n",
    "import gene2terms_addupstream as GO\n",
    "\n",
    "#Include all threee GO branches\n",
    "go_branches = ['Function','Process','Component']\n",
    "\n",
    "#Find all the targets for the individual cloud drugs\n",
    "cloud_targets = {}\n",
    "fp = open('../data/Drug_Properties/CLOUD_All_Targets.csv', 'r')\n",
    "fp.next()\n",
    "for line in fp:\n",
    "    tmp = line.strip().split(',')\n",
    "    cloud_targets[tmp[0]] = tmp[2].split(';')\n",
    "fp.close()\n",
    "\n",
    "#contain all CLOUD identifier\n",
    "all_clouds = cloud_targets.keys()\n",
    "all_clouds.sort()\n",
    "\n",
    "#Go throug the GO branches and find GO terms for a specific drug via: Drug --> Targets --> Associated GO-Terms\n",
    "drug_to_GO = {}\n",
    "for go_branch in go_branches:\n",
    "    print go_branch\n",
    "    drug_to_GO[go_branch] = {}\n",
    "    GO_Association_UP, GO_genes_annotation = GO.getAllGene_Annotation(go_branch)\n",
    "      \n",
    "    for drug in all_clouds:\n",
    "        drug_to_GO[go_branch][drug] = []\n",
    "        for target in cloud_targets[drug]:\n",
    "            drug_to_GO[go_branch][drug].extend(GO_Association_UP[target])\n",
    "        drug_to_GO[go_branch][drug] = list(set(drug_to_GO[go_branch][drug]))\n",
    "        \n",
    "#Save CLOUD drug to GO term annotations\n",
    "fp_out = open('../results/Drug_Properties/CLOUD_to_GOterms.csv','w')\n",
    "fp_out.write('CLOUD,GO_Function,GO_Process,GO_Component\\n')\n",
    "for cloud in all_clouds:\n",
    "    fp_out.write(cloud+','+';'.join(drug_to_GO['Function'][cloud])+','+';'.join(drug_to_GO['Process'][cloud])+','+';'.join(drug_to_GO['Component'][cloud])+'\\n')\n",
    "fp_out.close()\n",
    "\n",
    "print 'Finished GO'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Diseases\n",
    "Extract Disesase annotations from DiseaseOntology for the targets of the individual drugs. Not only leaf but also upstream term information is collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download from http://www.disgenet.org/web/DisGeNET/menu/downloads and http://disease-ontology.org/downloads/\n",
    "# Again use inhouse database (manually curated), and corresponding scripts \n",
    "\n",
    "# Get all cloud drug targets\n",
    "fp = open('../data/Drug_Properties/CLOUD_All_Targets.csv', 'r')\n",
    "fp.next()\n",
    "for line in fp:\n",
    "    tmp = line.strip().split(',')\n",
    "    cloud_targets[tmp[0]] = tmp[2].split(';')\n",
    "fp.close()\n",
    "\n",
    "all_clouds = cloud_targets.keys()\n",
    "all_clouds.sort()\n",
    "\n",
    "#Extrate the upward disease ontology (find all disease associated leaf plus upwards ontology terms for a specific gene)\n",
    "Disease_Association_UP,d_diseases_annotation = GO.getAllGene_Disease_Annotation()\n",
    "\n",
    "\n",
    "all_proteins = Disease_Association_UP.keys()\n",
    "all_proteins  = [int(x) for x in all_proteins]\n",
    "all_proteins.sort()\n",
    "\n",
    "fp_out = open('../results/Drug_Properties/Gene_to_Disease.csv','w')\n",
    "fp_out.write('Gene,Disease_ID\\n')\n",
    "for protein in all_proteins:\n",
    "    fp_out.write(str(protein)+','+';'.join(Disease_Association_UP[str(protein)])+'\\n')\n",
    "fp_out.close()\n",
    "\n",
    "\n",
    "\n",
    "break\n",
    "\n",
    "\n",
    "#associated drug with diseaes\n",
    "drug_to_Diseases = {}\n",
    "for drug in all_clouds:\n",
    "        drug_to_Diseases[drug] = []\n",
    "        for target in cloud_targets[drug]:\n",
    "            drug_to_Diseases[drug].extend(Disease_Association_UP[target])\n",
    "        drug_to_Diseases[drug] = list(set(drug_to_Diseases[drug]))\n",
    "        \n",
    "\n",
    "\n",
    "fp_out = open('../results/Drug_Properties/CLOUD_to_Disease.csv','w')\n",
    "fp_out.write('CLOUD,Disease_ID\\n')\n",
    "for cloud in all_clouds:\n",
    "    fp_out.write(cloud+','+';'.join(drug_to_Diseases[cloud])+'\\n')\n",
    "fp_out.close()\n",
    "\n",
    "print 'Finished Diseases'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. KeGG Pathways\n",
    "Extract information about pathways being annotated to (i) the drug itself, as well as (ii) pathways associated to the target of drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Extract direct drug <--> pathway annotations\n",
    "'''\n",
    "\n",
    "#Get KeGG pathways via the biopython.KEGG REST \n",
    "from Bio.KEGG import REST\n",
    "\n",
    "#Find the KeGG identifiers via the drugbank annotations\n",
    "DrugBankInfo = nx.read_gml('../data/Drug_Properties/Drugbank_2018-07-03_CLOUD_Only.gml')\n",
    "print 'DrugBank Network loaded'\n",
    "\n",
    "#parse through all CLOUD targets\n",
    "fp = open('../data/Drug_Properties/CLOUD_DrugBank_PubChem_Chembl.csv','r')\n",
    "fp.next()\n",
    "drug_to_pathways = {}\n",
    "all_targeted_Pathways = set()\n",
    "all_clouds = []\n",
    "kegg_IDs = {}\n",
    "\n",
    "#find the KeGG Drug page and find PATHWAY informations (direct drug to pathway)\n",
    "for line in fp:\n",
    "    tmp = line.strip().split(',')\n",
    "    \n",
    "    drug_to_pathways[tmp[0]] = []\n",
    "    \n",
    "    all_clouds.append(tmp[0])\n",
    "    \n",
    "    if DrugBankInfo.has_node(tmp[1]):\n",
    "        if DrugBankInfo.node[tmp[1]].has_key('KEGGDrug'):\n",
    "            kegg_ID = DrugBankInfo.node[tmp[1]]['KEGGDrug']\n",
    "            kegg_IDs[tmp[0]] = kegg_ID\n",
    "            drug_file = REST.kegg_get(kegg_ID).read()\n",
    "\n",
    "            for line in drug_file.rstrip().split(\"\\n\"):\n",
    "                section = line[:12].strip()  # section names are within 12 columns\n",
    "                if not section == \"\":\n",
    "                    current_section = section\n",
    "                if current_section == \"PATHWAY\":\n",
    "                    tmp2 =  line[12:].split('  ')\n",
    "                    pathwayID = tmp2[0].split('(')[0]\n",
    "                    drug_to_pathways[tmp[0]].append(pathwayID)\n",
    "                    all_targeted_Pathways.add(pathwayID)\n",
    "                    \n",
    "print 'Number of pathways directed targeted: %d' %len(all_targeted_Pathways)\n",
    "\n",
    "all_clouds.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Additonally to finding the direct annotations, also find drug <--> targets <--> pathways associated to those target annotations\n",
    "'''\n",
    "\n",
    "#Get all targets\n",
    "cloud_targets = {}\n",
    "fp = open('../data/Drug_Properties/CLOUD_All_Targets.csv', 'r')\n",
    "fp.next()\n",
    "for line in fp:\n",
    "    tmp = line.strip().split(',')\n",
    "    cloud_targets[tmp[0]] = tmp[2].split(';')\n",
    "fp.close()\n",
    "\n",
    "# find human pahtways\n",
    "human_pathways = REST.kegg_list(\"pathway\", \"hsa\").read()\n",
    "\n",
    "# get all human pathways, and add the dictionary\n",
    "pathways = {}\n",
    "for line in human_pathways.rstrip().split(\"\\n\"):\n",
    "    entry, description = line.split(\"\\t\")\n",
    "    pathways[entry] =  {'Description' :description, 'IDs':None,'Symbols':None}\n",
    "\n",
    "\n",
    "print len(pathways)\n",
    "# Get the genes for pathways and add them to a list\n",
    "\n",
    "for pathway in pathways.keys():\n",
    "    pathway_file = REST.kegg_get(pathway).read()  # query and read each pathway\n",
    "\n",
    "    # iterate through each KEGG pathway file, keeping track of which section\n",
    "    # of the file we're in, only read the gene in each pathway\n",
    "    current_section = None\n",
    "\n",
    "    genesSymbols =  []\n",
    "    genesIDs = []\n",
    "    for line in pathway_file.rstrip().split(\"\\n\"):\n",
    "        section = line[:12].strip()  # section names are within 12 columns\n",
    "        if not section == \"\":\n",
    "            current_section = section\n",
    "\n",
    "        if current_section == \"GENE\":\n",
    "            if ';' in line:\n",
    "                gene_identifiers, gene_description = line[12:].split(\"; \")\n",
    "                gene_id, gene_symbol = gene_identifiers.split()\n",
    "\n",
    "                if not gene_id in genesIDs:\n",
    "                    genesIDs.append(gene_id)\n",
    "                    genesSymbols.append(gene_symbol)\n",
    "\n",
    "    pathways[pathway] = genesIDs\n",
    "\n",
    "via_target_assigned_Pathways = {}\n",
    "second_assigned_pathways = set()\n",
    "for cloud in all_clouds:\n",
    "    via_target_assigned_Pathways[cloud] = [] \n",
    "    targets = cloud_targets[cloud]\n",
    "    for p in pathways:\n",
    "        if len(set(targets).intersection(set(pathways[p]))) > 0:\n",
    "            via_target_assigned_Pathways[cloud].append(p)\n",
    "            second_assigned_pathways.add(p)\n",
    "            \n",
    "print 'Number of pathways indirected targeted: %d' %len(second_assigned_pathways)\n",
    "\n",
    "fp_out = open('../results/Drug_Properties/CLOUD_to_KeGG_Pathways.csv','w')\n",
    "fp_out.write('CLOUD,KeGG_DrugID,KeGG_Assigned_Pathways,Via_Target_Assigned\\n')\n",
    "for cloud in all_clouds:\n",
    "    if kegg_IDs.has_key(cloud):\n",
    "        fp_out.write(cloud+','+kegg_IDs[cloud]+','+';'.join(drug_to_pathways[cloud])+','+';'.join(via_target_assigned_Pathways[cloud])+'\\n')\n",
    "    else:\n",
    "        fp_out.write(cloud+',,'+';'.join(drug_to_pathways[cloud])+','+';'.join(via_target_assigned_Pathways[cloud])+'\\n')\n",
    "        \n",
    "fp_out.close()\n",
    "\n",
    "print 'Finished Pathways'        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. SIDER\n",
    "Extract information about known adverse reaction of drugs using the Sider database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ATC_To_PubChem(isOffsides = 'None'):\n",
    "    '''\n",
    "    Sider offerst a direct conversion from ATC code to the internally used PubChem ID.\n",
    "    Offers a better coverage. \n",
    "    \n",
    "    Download: http://sideeffects.embl.de/download/ [Nov. 2018] drug_atc.tsv file\n",
    "    (here named: Pubchem_To_ATC)\n",
    "    '''\n",
    "\n",
    "    dic_ATc_To_Pubchem = {}\n",
    "    fp = open('../data/Drug_Properties/Pubchem_To_ATC.tsv')\n",
    "    for line in fp:\n",
    "        tmp =  line.strip().split('\\t')\n",
    "        dic_ATc_To_Pubchem[tmp[1]] = tmp[0]\n",
    "\n",
    "    cloud_drugs = nx.read_gml('../data/Drug_Properties/Drugbank_2018-07-03_CLOUD_Only.gml')\n",
    "    \n",
    "    \n",
    "    #find pubchem identifiers via ATC identifiers (as pubchem identifiers sometimes not unique neithers SID nor CID)\n",
    "    cloud_to_Pubchem = {}\n",
    "    PubChem_to_cloud = {}\n",
    "    found_PubChems = []\n",
    "    for drugBankID in cloud_drugs.nodes():\n",
    "        if cloud_drugs.node[drugBankID].has_key('ATCcode'):\n",
    "            all_codes = [x.strip() for x in cloud_drugs.node[drugBankID]['ATCcode'].split(',') if x != '']\n",
    "            for code in all_codes:\n",
    "                if dic_ATc_To_Pubchem.has_key(code):\n",
    "                    pubChemID = dic_ATc_To_Pubchem[code][3:]\n",
    "                    if isOffsides == 'offsides':\n",
    "                        tmp = list(pubChemID)\n",
    "                        tmp[0] = '0'\n",
    "                        pubChemID = ''.join(tmp)\n",
    "\n",
    "                    cloud_to_Pubchem[drugBankID] = pubChemID\n",
    "                    PubChem_to_cloud[pubChemID] = drugBankID\n",
    "                    found_PubChems.append(pubChemID)\n",
    "\n",
    "\n",
    "    return cloud_to_Pubchem, PubChem_to_cloud,found_PubChems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Download SIDER.tsv from http://sideeffects.embl.de/download/ [Nov. 2018] \n",
    "'''\n",
    "\n",
    "#get the different identifiers of a drug\n",
    "DrugBank_To_CLOUD = {}\n",
    "CLOUD_To_DrugBank = {}\n",
    "fp = open('../data/Drug_Properties/CLOUD_DrugBank_PubChem_Chembl.csv')\n",
    "fp.next()\n",
    "all_clouds = []\n",
    "for line in fp:\n",
    "    tmp = line.strip().split(',')\n",
    "    all_clouds.append(tmp[0])\n",
    "    DrugBank_To_CLOUD[tmp[1]] = tmp[0]\n",
    "    CLOUD_To_DrugBank[tmp[0]] = tmp[1]\n",
    "fp.close()\n",
    "\n",
    "all_clouds.sort()\n",
    "\n",
    "#extract pubchem identifier via ATC codes\n",
    "DrugBank_to_Pubchem_viaATC, PubChem_to_cloud_viaATC,found_PubChems_viaATC = ATC_To_PubChem()\n",
    "\n",
    "#further use drugbank to find additional pubchem identifiers for the cloud drugs\n",
    "cloud_drugs = nx.read_gml('../data/Drug_Properties/Drugbank_2018-07-03_CLOUD_Only.gml')\n",
    "\n",
    "#associate cloud with the different pubchem identifiers\n",
    "pubchemCompound_To_DrugBank = {}\n",
    "DrugBank_to_PubChem = {}\n",
    "pubchemCompound = []\n",
    "pubchemSubstance = []\n",
    "for node in cloud_drugs.nodes():\n",
    "    if cloud_drugs.node[node].has_key('PubChemCompound'):\n",
    "        pubchemCompound.append(cloud_drugs.node[node]['PubChemCompound'])\n",
    "        pubchemCompound_To_DrugBank[cloud_drugs.node[node]['PubChemCompound']] = node\n",
    "        DrugBank_to_PubChem[node] = cloud_drugs.node[node]['PubChemCompound']\n",
    "\n",
    "#Combine both dictionaries together\n",
    "for key in DrugBank_to_Pubchem_viaATC:\n",
    "    DrugBank_to_PubChem[key] = DrugBank_to_Pubchem_viaATC[key]\n",
    "\n",
    "\n",
    "\n",
    "#check the SIDER database for given sideeffect of a given drug (once via the ATC to pubchem identfiers; once via drugbank to pubchem)\n",
    "compund_sideEffect = {}\n",
    "fp = open('../data/Drug_Properties/SIDER.tsv','r')\n",
    "for line in fp:\n",
    "    tmp = line.strip().split('\\t')\n",
    "    id1 = tmp[1][3:]\n",
    "    id2 = tmp[2][3:]\n",
    "\n",
    "    if id1 in found_PubChems_viaATC:\n",
    "        if compund_sideEffect.has_key(PubChem_to_cloud_viaATC[id1]):\n",
    "            compund_sideEffect[PubChem_to_cloud_viaATC[id1]].append(tmp[3])\n",
    "        else:\n",
    "            compund_sideEffect[PubChem_to_cloud_viaATC[id1]] = [tmp[3]]\n",
    "\n",
    "    if id1 in pubchemCompound:\n",
    "        if compund_sideEffect.has_key(pubchemCompound_To_DrugBank[id1]):\n",
    "            compund_sideEffect[pubchemCompound_To_DrugBank[id1]].append(tmp[3])\n",
    "        else:\n",
    "            compund_sideEffect[pubchemCompound_To_DrugBank[id1]] = [tmp[3]]\n",
    "\n",
    "\n",
    "\n",
    "    if id2 in found_PubChems_viaATC:\n",
    "        if compund_sideEffect.has_key(PubChem_to_cloud_viaATC[id2]):\n",
    "            compund_sideEffect[PubChem_to_cloud_viaATC[id2]].append(tmp[3])\n",
    "        else:\n",
    "            compund_sideEffect[PubChem_to_cloud_viaATC[id2]] = [tmp[3]]\n",
    "\n",
    "    if id2 in pubchemCompound:\n",
    "        if compund_sideEffect.has_key(pubchemCompound_To_DrugBank[id2]):\n",
    "            compund_sideEffect[pubchemCompound_To_DrugBank[id2]].append(tmp[3])\n",
    "        else:\n",
    "            compund_sideEffect[pubchemCompound_To_DrugBank[id2]] = [tmp[3]]\n",
    "\n",
    "##\n",
    "# Save results\n",
    "##\n",
    "\n",
    "\n",
    "fp = open('../results/Drug_Properties/CLOUD_to_SIDER.csv','w')\n",
    "fp.write('CLOUD,PubChem,SIDER_Ids\\n')\n",
    "for key in all_clouds:\n",
    "    if compund_sideEffect.has_key(CLOUD_To_DrugBank[key]):\n",
    "        fp.write(key +','+DrugBank_to_PubChem[CLOUD_To_DrugBank[key]]+','+';'.join(list(set(compund_sideEffect[CLOUD_To_DrugBank[key]])))+'\\n')\n",
    "    elif DrugBank_to_PubChem.has_key(CLOUD_To_DrugBank[key]):\n",
    "        fp.write(key  +','+DrugBank_to_PubChem[CLOUD_To_DrugBank[key]]+',' + '\\n')\n",
    "    else:\n",
    "        fp.write(key + ',,\\n')\n",
    "fp.close()\n",
    "\n",
    "print 'Finish with SIDER'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Offsides\n",
    "Extract information about known adverse reaction of drugs using the Offside database (Tantonetti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Download Offsides.tsv from http://tatonettilab.org/resources/tatonetti-stm.html [Nov. 2018] \n",
    "'''\n",
    "#get the different identifiers of a drug\n",
    "DrugBank_To_CLOUD = {}\n",
    "CLOUD_To_DrugBank = {}\n",
    "fp = open('../data/Drug_Properties/CLOUD_DrugBank_PubChem_Chembl.csv')\n",
    "fp.next()\n",
    "for line in fp:\n",
    "    tmp = line.strip().split(',')\n",
    "    DrugBank_To_CLOUD[tmp[1]] = tmp[0]\n",
    "    CLOUD_To_DrugBank[tmp[0]] = tmp[1]\n",
    "fp.close()\n",
    "\n",
    "#extract pubchem identifier via ATC codes\n",
    "DrugBank_to_Pubchem_viaATC, PubChem_to_cloud_viaATC, found_PubChems_viaATC = ATC_To_PubChem('offsides')\n",
    "\n",
    "#further use drugbank to find additional pubchem identifiers for the cloud drugs\n",
    "cloud_drugs = nx.read_gml('../data/Drug_Properties/Drugbank_2018-07-03_CLOUD_Only.gml')\n",
    "\n",
    "#associate cloud with the different pubchem identifiers\n",
    "pubchemCompound_To_DrugBank = {}\n",
    "DrugBank_to_PubChem = {}\n",
    "pubchemCompound = []\n",
    "pubchemSubstance = []\n",
    "for node in cloud_drugs.nodes():\n",
    "    if cloud_drugs.node[node].has_key('PubChemCompound'):\n",
    "        pubchemCompound.append(cloud_drugs.node[node]['PubChemCompound'].zfill(9))\n",
    "        pubchemCompound_To_DrugBank[cloud_drugs.node[node]['PubChemCompound'].zfill(9)] = node\n",
    "        DrugBank_to_PubChem[node] = cloud_drugs.node[node]['PubChemCompound'].zfill(9)\n",
    "\n",
    "# Combine both dictionaries together\n",
    "for key in DrugBank_to_Pubchem_viaATC:\n",
    "    DrugBank_to_PubChem[key] = DrugBank_to_Pubchem_viaATC[key]\n",
    "\n",
    "\n",
    "#check the OFFSIDES database for given sideeffect of a given drug (once via the ATC to pubchem identfiers; once via drugbank to pubchem)\n",
    "compund_sideEffect = {}\n",
    "fp = open('../data/Drug_Properties/Offsides.tsv', 'r')\n",
    "fp.next()\n",
    "for line in fp:\n",
    "    tmp = line.strip().split('\\t')\n",
    "\n",
    "\n",
    "    id1 = tmp[0].replace('\"','')[3:]\n",
    "    sideEffect = tmp[2].replace('\"','')\n",
    "\n",
    "    #print id1\n",
    "\n",
    "    if id1 in found_PubChems_viaATC:\n",
    "        if compund_sideEffect.has_key(PubChem_to_cloud_viaATC[id1]):\n",
    "            compund_sideEffect[PubChem_to_cloud_viaATC[id1]].append(sideEffect)\n",
    "        else:\n",
    "            compund_sideEffect[PubChem_to_cloud_viaATC[id1]] = [sideEffect]\n",
    "            print len(compund_sideEffect.keys())\n",
    "            # print compund_sideEffect.keys()\n",
    "\n",
    "    if id1 in pubchemCompound:\n",
    "        if compund_sideEffect.has_key(pubchemCompound_To_DrugBank[id1]):\n",
    "            compund_sideEffect[pubchemCompound_To_DrugBank[id1]].append(sideEffect)\n",
    "        else:\n",
    "            compund_sideEffect[pubchemCompound_To_DrugBank[id1]] = [sideEffect]\n",
    "            print len(compund_sideEffect.keys())\n",
    "            # print compund_sideEffect.keys()\n",
    "\n",
    "fp = open('../results/Drug_Properties/CLOUD_to_Offsides.csv', 'w')\n",
    "fp.write('CLOUD,PubChem,OFFSIDE_Ids\\n')\n",
    "for key in all_clouds:\n",
    "    if compund_sideEffect.has_key(CLOUD_To_DrugBank[key]):\n",
    "        fp.write(key  +','+DrugBank_to_PubChem[CLOUD_To_DrugBank[key]]+','+';'.join(list(set(compund_sideEffect[CLOUD_To_DrugBank[key]])))+'\\n')\n",
    "    elif DrugBank_to_PubChem.has_key(CLOUD_To_DrugBank[key]):\n",
    "        fp.write(key + ',' +DrugBank_to_PubChem[CLOUD_To_DrugBank[key]]+',' + '\\n')\n",
    "    else:\n",
    "        fp.write(key + ',,\\n')\n",
    "fp.close()\n",
    "\n",
    "print 'Finish with OFFSIDES'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. TwoSides\n",
    "Extract information about side effects for drug combinations using TwoSide (Tantonetti))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Download Offsides.tsv from http://tatonettilab.org/resources/tatonetti-stm.html [Nov. 2018] \n",
    "'''\n",
    "#get the different identifiers of a drug\n",
    "DrugBank_To_CLOUD = {}\n",
    "CLOUD_To_DrugBank = {}\n",
    "fp = open('../data/Drug_Properties/CLOUD_DrugBank_PubChem_Chembl.csv')\n",
    "fp.next()\n",
    "for line in fp:\n",
    "    tmp = line.strip().split(',')\n",
    "    DrugBank_To_CLOUD[tmp[1]] = tmp[0]\n",
    "    CLOUD_To_DrugBank[tmp[0]] = tmp[1]\n",
    "fp.close()\n",
    "\n",
    "#extract pubchem identifier via ATC codes\n",
    "DrugBank_to_Pubchem_viaATC, PubChem_to_cloud_viaATC, found_PubChems_viaATC = ATC_To_PubChem('offsides')\n",
    "\n",
    "#further use drugbank to find additional pubchem identifiers for the cloud drugs\n",
    "cloud_drugs = nx.read_gml('../data/Drug_Properties/Drugbank_2018-07-03_CLOUD_Only.gml')\n",
    "\n",
    "pubchemCompound_To_DrugBank = {}\n",
    "DrugBank_to_PubChem = {}\n",
    "pubchemCompound = []\n",
    "pubchemSubstance = []\n",
    "for node in cloud_drugs.nodes():\n",
    "    if cloud_drugs.node[node].has_key('PubChemCompound'):\n",
    "        pubchemCompound.append(cloud_drugs.node[node]['PubChemCompound'].zfill(9))\n",
    "        pubchemCompound_To_DrugBank[cloud_drugs.node[node]['PubChemCompound'].zfill(9)] = node\n",
    "        DrugBank_to_PubChem[node] = cloud_drugs.node[node]['PubChemCompound'].zfill(9)\n",
    "\n",
    "# Combine both dictionaries together\n",
    "for key in DrugBank_to_Pubchem_viaATC:\n",
    "    DrugBank_to_PubChem[key] = DrugBank_to_Pubchem_viaATC[key]\n",
    "    \n",
    "    \n",
    "#check the SIDER database for given sideeffect of a given drug (once via the ATC to pubchem identfiers; once via drugbank to pubchem)\n",
    "TwoSide_Network = nx.Graph()\n",
    "fp = open('../data/Drug_Properties/TwoSides.tsv', 'r')\n",
    "fp.next()\n",
    "for line in fp:\n",
    "    tmp = line.strip().split('\\t')\n",
    "\n",
    "\n",
    "    id1 = tmp[0][3:]\n",
    "    id2 = tmp[1][3:]\n",
    "    sideEffect = tmp[4]\n",
    "\n",
    "    #print id1\n",
    "    found_id1 = None\n",
    "    found_id2 = None\n",
    "    \n",
    "    if id1 in found_PubChems_viaATC: \n",
    "        found_id1 = PubChem_to_cloud_viaATC[id1]\n",
    "    elif id1 in pubchemCompound: \n",
    "        found_id1 = pubchemCompound_To_DrugBank[id1]\n",
    "        \n",
    "    if found_id1 != None:\n",
    "        if id2 in found_PubChems_viaATC: \n",
    "            found_id2 = PubChem_to_cloud_viaATC[id2]\n",
    "        elif id2 in pubchemCompound: \n",
    "            found_id2 = pubchemCompound_To_DrugBank[id2]\n",
    "        \n",
    "        \n",
    "        if found_id2 != None:\n",
    "            if TwoSide_Network.has_edge(found_id1,found_id2) == False:\n",
    "                TwoSide_Network.add_edge(found_id1,found_id2)\n",
    "                TwoSide_Network[found_id1][found_id2]['SideEffect'] = sideEffect\n",
    "            else:\n",
    "                 TwoSide_Network[found_id1][found_id2]['SideEffect'] =  TwoSide_Network[found_id1][found_id2]['SideEffect']  +',' + sideEffect\n",
    "        \n",
    "        \n",
    "nx.write_gml(TwoSide_Network,'../results/Drug_Properties/TwoSide_CLOUDs.gml')\n",
    "\n",
    "print 'Finish with TwoSides'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Drug Properties\n",
    "Extract Physicochemical properties of the drugs e.g. Lipinski Rule of 5, LogS, LogP etc. Use DrugBank as main source of information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Physicochemical properties (calculated) offered by DrugBank\n",
    "'''\n",
    "\n",
    "#List of interesting physicochemical properties (continues)\n",
    "Continuesfeatures = ['Polarizability','logS','logP','NumberofRings','PhysiologicalCharge',\n",
    "            'PolarSurfaceAreaPSA','pKastrongestbasic','pKastrongestacidic',\n",
    "            'Refractivity','MonoisotopicWeight','HBondDonorCount',\n",
    "            'RotatableBondCount','WaterSolubility']\n",
    "\n",
    "##List of interesting physicochemical properties (discrete)\n",
    "discreteFeatures = ['DrugSubClass','DrugClass','Family']\n",
    "\n",
    "#Drugbank file\n",
    "DrugBankInfo = nx.read_gml('../data/Drug_Properties/Drugbank_2018-07-03_CLOUD_Only.gml')\n",
    "print 'DrugBank Network loaded'\n",
    "\n",
    "#output file\n",
    "fp = open('../data/Drug_Properties/CLOUD_DrugBank_PubChem_Chembl.csv','r')\n",
    "fp.next()\n",
    "\n",
    "\n",
    "#parse through all cloud drugs and find physicochemical propterties\n",
    "CLOUD_Chemical_properties = {}\n",
    "all_clouds = []\n",
    "kegg_IDs = {}\n",
    "for line in fp:\n",
    "    tmp = line.strip().split(',')\n",
    "    \n",
    "    all_clouds.append(tmp[0])\n",
    "    CLOUD_Chemical_properties[tmp[0]] = {}\n",
    "    \n",
    "    \n",
    "    if DrugBankInfo.has_node(tmp[1]):\n",
    "        CLOUD_Chemical_properties[tmp[0]]['DrugBankID'] = tmp[1]\n",
    "        \n",
    "        for c in Continuesfeatures:\n",
    "            if  DrugBankInfo.node[tmp[1]].has_key(c):\n",
    "                CLOUD_Chemical_properties[tmp[0]][c] = str(DrugBankInfo.node[tmp[1]][c])\n",
    "            else:\n",
    "                CLOUD_Chemical_properties[tmp[0]][c] = 'None'\n",
    "                \n",
    "        \n",
    "        for d in discreteFeatures:\n",
    "            if  DrugBankInfo.node[tmp[1]].has_key(d):\n",
    "                CLOUD_Chemical_properties[tmp[0]][d] = str(DrugBankInfo.node[tmp[1]][d])\n",
    "            else:\n",
    "                CLOUD_Chemical_properties[tmp[0]][d] = 'None'\n",
    "        \n",
    "    else:\n",
    "        CLOUD_Chemical_properties[tmp[0]]['DrugBankID'] = 'None'\n",
    "        \n",
    "        for c in Continuesfeatures:\n",
    "            CLOUD_Chemical_properties[tmp[0]][c] = 'None'\n",
    "            \n",
    "        for d in discreteFeatures:\n",
    "            CLOUD_Chemical_properties[tmp[0]][d] = 'None'\n",
    "            \n",
    "##\n",
    "# Save results\n",
    "##\n",
    "        \n",
    "fp = open('../results/Drug_Properties/CLOUD_to_ChemicalProperties.tsv', 'w')\n",
    "fp.write('CLOUD\\tDrugBankID\\t')\n",
    "fp.write('\\t'.join(Continuesfeatures)+'\\t'+'\\t'.join(discreteFeatures)+'\\n')        \n",
    "         \n",
    "for cloud in all_clouds:\n",
    "        fp.write(cloud+'\\t'+CLOUD_Chemical_properties[cloud]['DrugBankID'])\n",
    "        for c in Continuesfeatures:\n",
    "             fp.write('\\t'+CLOUD_Chemical_properties[cloud][c])\n",
    "        for d in discreteFeatures:\n",
    "             fp.write('\\t'+CLOUD_Chemical_properties[cloud][d])\n",
    "        fp.write('\\n')\n",
    "fp.close()\n",
    "\n",
    "print 'Finish with Chemical Properties'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Targets, Enzymes, Transporters and Carriers\n",
    "Split the full lust of targets into targets, enzymes, transporters and carriers\n",
    "Therefore use the DrugBank annotations of what a target, transporter, carrier and enzyme is. Go trough all drugbank targets and take the corresponding annotations.\n",
    "Then go trough the CLOUD targets and assign the targets accordingly. If drugbank does not show any annotation the gene is assumed to be a target.\n",
    "\n",
    "Enzymes: e.g. CYP3A1  \n",
    "Transporter: e.g. MDR5  \n",
    "Carriers: e.g. ALB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DrugBankInfo = nx.read_gml('../data/Drug_Properties/Drugbank_2018-07-03.gml')\n",
    "print 'Full DrugBank Network loaded'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_enzyme_symbols = set()\n",
    "annotated_transporters_symbols = set()\n",
    "annotated_carriers_symbols = set()\n",
    "\n",
    "#Go through all drugs in drugbank and extract target information; bin it correctly into one of the three classes\n",
    "for drug in list(DrugBankInfo.nodes()):\n",
    "    \n",
    "    if DrugBankInfo.node[drug].has_key('Enzymes'):\n",
    "        enzymes = [x for x in DrugBankInfo.node[drug]['Enzymes'].strip().split(',') if x != '']\n",
    "        for e in enzymes:\n",
    "            annotated_enzyme_symbols.add(e.split('_')[0])\n",
    "    if DrugBankInfo.node[drug].has_key('Transporters'):\n",
    "        transporters = [x for x in DrugBankInfo.node[drug]['Transporters'].strip().split(',') if x != '']\n",
    "        for t in transporters:\n",
    "            annotated_transporters_symbols.add(t.split('_')[0])\n",
    "        \n",
    "    if DrugBankInfo.node[drug].has_key('Carriers'):\n",
    "        carriers = [x for x in DrugBankInfo.node[drug]['Carriers'].strip().split(',') if x != '']\n",
    "        for c in carriers:\n",
    "            annotated_carriers_symbols.add(c.split('_')[0])\n",
    "\n",
    "#Plot the number of found Enzymes, Transporters, Carriers\n",
    "print len(annotated_enzyme_symbols)\n",
    "print len(annotated_transporters_symbols)\n",
    "print len(annotated_carriers_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Parse the enzyme, carriers and transporter SYMBOLS to EntrezIDs using mygeneinfo\n",
    "'''\n",
    "\n",
    "import mygene\n",
    "mg = mygene.MyGeneInfo()\n",
    "\n",
    "#Enzymes\n",
    "query = mg.querymany(annotated_enzyme_symbols, scope='symbol', species='human',verbose=False)\n",
    "final_annotated_enzyme_symbols = []\n",
    "final_annotated_enzyme_IDs = []\n",
    "for result in query:\n",
    "    if result.has_key('entrezgene'):\n",
    "        final_annotated_enzyme_symbols.append(result['symbol'])\n",
    "        final_annotated_enzyme_IDs.append(str(result['_id']))\n",
    "\n",
    "#Transporters\n",
    "query = mg.querymany(annotated_transporters_symbols, scope='symbol', species='human',verbose=False)\n",
    "final_annotated_transporters_symbols = []\n",
    "final_annotated_transporters_IDs = []\n",
    "for result in query:\n",
    "    if result.has_key('entrezgene'):\n",
    "        final_annotated_transporters_symbols.append(result['symbol'])\n",
    "        final_annotated_transporters_IDs.append(str(result['_id']))\n",
    "\n",
    "#Carriers\n",
    "query = mg.querymany(annotated_carriers_symbols, scope='symbol', species='human',verbose=False)\n",
    "final_annotated_carriers_symbols = []\n",
    "final_annotated_carriers_IDs = []\n",
    "for result in query:\n",
    "    if result.has_key('entrezgene'):\n",
    "        final_annotated_carriers_symbols.append(result['symbol'])\n",
    "        final_annotated_carriers_IDs.append(str(result['_id']))\n",
    "        \n",
    "\n",
    "print len(final_annotated_enzyme_IDs)\n",
    "print len(final_annotated_transporters_IDs)\n",
    "print len(final_annotated_carriers_IDs)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create an output file with the various transporters/enzymes/targets etc. being split.\n",
    "'''\n",
    "\n",
    "#Get the DrugBank targets\n",
    "cloud_DrugBanktargets = {}\n",
    "fp = open('../data/Drug_Properties/CLOUD_DrugBank_Targets_ONLY.csv', 'r')\n",
    "fp.next()\n",
    "for line in fp:\n",
    "    tmp = line.strip().split(',')\n",
    "    cloud_DrugBanktargets[tmp[0]] = tmp[2].split(';')\n",
    "fp.close()\n",
    "\n",
    "#Get all targets accociated to the individual CLOUDS (including CYP etc.)\n",
    "cloud_targets = {}\n",
    "fp = open('../data/Drug_Properties/CLOUD_All_Targets.csv', 'r')\n",
    "fp.next()\n",
    "for line in fp:\n",
    "    tmp = line.strip().split(',')\n",
    "    cloud_targets[tmp[0]] = tmp[2].split(';')\n",
    "fp.close()\n",
    "\n",
    "#List containing all CLOUD identifiers\n",
    "all_clouds = cloud_targets.keys()\n",
    "all_clouds.sort()\n",
    "\n",
    "#Create output file\n",
    "fp_out = open('../results/Drug_Properties/CLOUD_to_TargetsSplit.csv', 'w')\n",
    "fp_out.write('CLOUD,Targets,Transporters,Enzymes,Carriers\\n')\n",
    "\n",
    "#save the per drug annotations of CLOUD drugs\n",
    "targets_number = []\n",
    "enzymes_number = []\n",
    "transporters_number = []\n",
    "carriers_number = []\n",
    "\n",
    "#save total amount of distinct targets, enzymes etc. targeted by CLOUD\n",
    "different_targets = set()\n",
    "different_enzymes = set()\n",
    "different_transporters = set()\n",
    "different_carriers = set()\n",
    "\n",
    "#save total amount of targets found\n",
    "all_targets = 0\n",
    "\n",
    "#Go through all CLOUDS\n",
    "for cloud in all_clouds:\n",
    "    \n",
    "    targets = []\n",
    "    enzymes = []\n",
    "    carriers = []\n",
    "    transporters = []\n",
    "    \n",
    "    for target in cloud_targets[cloud]:\n",
    "    \n",
    "    \n",
    "        #First check if the target is annoated in DrugBank to be a target of this drug! (sometimes CYP or other can be main targets)\n",
    "        if target in cloud_DrugBanktargets[cloud]:\n",
    "            targets.append(target)\n",
    "        else:\n",
    "            #If it is not the main target of this drug bin it correctly according to drugbank standards\n",
    "            not_associated = False\n",
    "            if target in final_annotated_enzyme_IDs:\n",
    "                enzymes.append(target)\n",
    "                not_associated = True\n",
    "            if target in final_annotated_transporters_IDs:\n",
    "                transporters.append(target)\n",
    "                not_associated = True\n",
    "            if target in final_annotated_carriers_IDs:\n",
    "                carriers.append(target)\n",
    "                not_associated = True\n",
    "\n",
    "            if not_associated == False:\n",
    "                targets.append(target)\n",
    "    fp_out.write(cloud+','+';'.join(targets)+','+';'.join(transporters)+','+';'.join(enzymes)+','+';'.join(carriers)+'\\n')\n",
    "    \n",
    "    #Save the results\n",
    "    all_targets += len(targets)\n",
    "    targets_number.append(len(targets))\n",
    "    enzymes_number.append(len(enzymes))\n",
    "    transporters_number.append(len(transporters))\n",
    "    carriers_number.append(len(carriers))\n",
    "    \n",
    "    different_targets = different_targets.union(set(targets))\n",
    "    different_enzymes = different_enzymes.union(set(enzymes))\n",
    "    different_transporters = different_transporters.union(set(transporters))\n",
    "    different_carriers = different_carriers.union(set(carriers))\n",
    "    \n",
    "    \n",
    "    \n",
    "fp_out.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "CREATE OUTPUT OVERVIEW OVER DRUG TARGETS/ANNOTATIONS\n",
    "'''\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pylab as plt\n",
    "\n",
    "\n",
    "print'Mean number of targets: %.2f' %np.mean(targets_number)\n",
    "print'Median number of targets: %.2f' %np.median(targets_number)\n",
    "print'Mean number of enzymes: %.2f' %np.mean(enzymes_number)\n",
    "print'Mean number of carriers: %.2f' %np.mean(carriers_number)\n",
    "print'Mean number of transporters: %.2f' %np.mean(transporters_number)\n",
    "\n",
    "print 'Total number of targets: %d' %all_targets\n",
    "print 'Number of distinct targets: %d' %len(different_targets)\n",
    "print'Number of distinct  enzymes: %d' %len(different_enzymes)\n",
    "print'Number of distinct  carriers: %d' %len(different_carriers)\n",
    "print'Number of distinct  transporters: %d' %len(different_transporters)\n",
    "\n",
    "\n",
    "plt.hist(targets_number,bins=22, color='#40B9D4')\n",
    "plt.axvline(np.mean(targets_number),ls='--', color='grey')\n",
    "plt.savefig('../results/Drug_Properties/CLOUD_TargetsFiltered.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Chemical Genetic perturbations\n",
    "Use the msigDB Chemical_Genetic_Perturbations set to annotate the CLOUD target respetively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Download from http://software.broadinstitute.org/gsea/msigdb/collections.jsp#C5 [December 17. 2018]\n",
    "'''\n",
    "\n",
    "#Get all CLOUD targets\n",
    "cloud_targets = {}\n",
    "fp = open('../data/Drug_Properties/CLOUD_All_Targets.csv', 'r')\n",
    "fp.next()\n",
    "for line in fp:\n",
    "    tmp = line.strip().split(',')\n",
    "    cloud_targets[tmp[0]] = tmp[2].split(';')\n",
    "fp.close()\n",
    "\n",
    "#Find the gene to perturbation associated (one gene can have various associated perturbations)\n",
    "fp = open('../data/Drug_Properties/Msig_ChemGen_Perturbation.gmt','r')\n",
    "gene_to_perturbation = {}\n",
    "for line in fp:\n",
    "    tmp = line.strip().split('\\t')\n",
    "    for gene in tmp[2:]:\n",
    "        if gene_to_perturbation.has_key(gene):\n",
    "            gene_to_perturbation[gene].append(tmp[0])\n",
    "        else:\n",
    "            gene_to_perturbation[gene] = [tmp[0]]\n",
    "fp.close()\n",
    "\n",
    "\n",
    "#find cloud associations via CLOUD --> Targets ===> Perturbations associated with certain targets\n",
    "fp_out = open('../results/Drug_Properties/CLOUD_to_Perturbations.csv', 'w')\n",
    "fp_out.write('CLOUD,Perturbations\\n')\n",
    "for cloud in all_clouds:\n",
    "\n",
    "    perturbations = []\n",
    "    for gene in cloud_targets[cloud]:\n",
    "        if gene_to_perturbation.has_key(gene):\n",
    "            perturbations.extend(gene_to_perturbation[gene])\n",
    "    fp_out.write(cloud+','+';'.join(perturbations)+'\\n')\n",
    "fp_out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Molecular Determinants\n",
    "Instead of focusing on the crude raw data use bootstrapping to emphasize the real differences between increasing/decreasing and emergent. Given that drug perturbation range from a broad range of perturbation e.g. when looking at the feature chemical similarity almost the whole spectrum of similarities is covered but by using bootstrap one can focus on the mean differences and the variation of the mean.\n",
    "\n",
    "1.) Load all features  \n",
    "2.) perform bootstrap analysis  \n",
    "3.) save results (+ plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all important python modules\n",
    "import numpy as np\n",
    "from matplotlib import pylab as plt\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import mannwhitneyu as mu\n",
    "import seaborn as sns\n",
    "import os\n",
    "from math import pi\n",
    "import math\n",
    "from sympy import Symbol, solve, sqrt\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load features per drug pair e.g. if two drugs share a common transporter, mean PPI distance between their drug targets etc.\n",
    "fp = open('../data/Molecular_Determinants/DrugPair_Feature_Overview.csv','r')\n",
    "features = fp.readline().strip().split(',')[4:]\n",
    "print ('Number of features: %d' %len(features))\n",
    "\n",
    "#Define interaction types as well as colors for the final plots (uniform with previous color coding)\n",
    "interactionTypes = ['NoInteraction','Interaction','Increasing','Decreasing','Emergent']\n",
    "interaction_colors = {'Increasing':'#ACD900','Decreasing':'#F70020','Emergent':'#0096FF','Interaction':'#F8B301','NoInteraction':'grey'}\n",
    "\n",
    "#Create a dictionary where the individual results per feature can be split into the 5 types of interactions e.g. ChemicalSimilarity: {Increasing:[], Decreasing: [] ... }\n",
    "dic_feature_results = {}\n",
    "for f in features:\n",
    "    dic_feature_results[f] = {}\n",
    "    for iT in interactionTypes:\n",
    "        dic_feature_results[f][iT] = []\n",
    "\n",
    "#Go through the results of the drug pair feature file\n",
    "for line in fp:\n",
    "    tmp = line.strip().split(',')\n",
    "    interactionType = tmp[3]\n",
    "    \n",
    "    #add the results to the corresponding list \n",
    "    for f,i in zip(features, range(4,len(tmp))):\n",
    "        val = tmp[i]\n",
    "        #if the val is 'nan' ignore this row\n",
    "        if val != 'nan':\n",
    "            val = float(val)\n",
    "            #if interaction type == None, then NoInteraction\n",
    "            if interactionType == 'None':\n",
    "                dic_feature_results[f]['NoInteraction'].append(val)\n",
    "            #Else split into one of the posible other interaction types, keep only pure row e.g. only increasing/decreasing\n",
    "            else:\n",
    "                if  interactionType ==  'Increasing' or interactionType ==  'Increasing;Increasing':\n",
    "                    dic_feature_results[f]['Increasing'].append(val)\n",
    "                    dic_feature_results[f]['Interaction'].append(val)\n",
    "                if  interactionType == 'Decreasing' or interactionType ==  'Decreasing;Decreasing':\n",
    "                    dic_feature_results[f]['Decreasing'].append(val)\n",
    "                    dic_feature_results[f]['Interaction'].append(val)\n",
    "                if  interactionType == 'Emergent':\n",
    "                    dic_feature_results[f]['Emergent'].append(val)\n",
    "                    dic_feature_results[f]['Interaction'].append(val)\n",
    "print ('Done loading data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Perform Statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Define functions for calculating bootstrapping and effect size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrapping(data, number_iterations=10000, bootstrap_sample_size = None):\n",
    "    '''\n",
    "    Function for bootstrapping\n",
    "    data = Data that needs to be bootsraped\n",
    "    number_iteration = how often should bootstrapping be perfomred\n",
    "    bootstrap_sample_size = sample size to draw for, if None then sample size = len(data) which is the typical procedure for bootstrapping\n",
    "    '''\n",
    "\n",
    "    #Define the bootstrap sample size\n",
    "    if bootstrap_sample_size == None:\n",
    "        bootstrap_sample_size = len(data)\n",
    "    \n",
    "    #draw randomly from data to get an estimation of it's variation. Save both the mean per bootstrap run as well as the calculated std\n",
    "    bootstrap_samples_means = []\n",
    "    bootstrap_samples_stds = []\n",
    "    for i in range(0,number_iterations):\n",
    "        bootstrap_sample = np.random.choice(data,bootstrap_sample_size,replace=True)    \n",
    "        bootstrap_samples_means.append(np.mean(bootstrap_sample))\n",
    "        bootstrap_samples_stds.append(np.std(bootstrap_sample))\n",
    "    \n",
    "    #return the results\n",
    "    return bootstrap_samples_means, bootstrap_samples_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohen_d(x, y):\n",
    "    '''\n",
    "    Cohen's D is a typical meassure of effect size including the standard deviation of both samples (compared to ZScore which only uses one)\n",
    "    '''\n",
    "    \n",
    "    #Get length of the two samples\n",
    "    nx = len(x)\n",
    "    ny = len(y)\n",
    "    \n",
    "    #Define degrees of freedom\n",
    "    dof = nx + ny - 2\n",
    "    \n",
    "    #Calculate Cohen's D and return\n",
    "    return (np.mean(x) - np.mean(y)) / np.sqrt(\n",
    "        ((nx - 1) * np.std(x, ddof=1) ** 2 + (ny - 1) * np.std(y, ddof=1) ** 2) / dof)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Calculate Statistics for each feature\n",
    "1. Binary features e.g. have overlap/no overlap use Fisher Exact test\n",
    "2. Continues features e.g. PPI distance, use Mann Whitney U test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a significance threshold\n",
    "alpha = 0.05\n",
    "\n",
    "#define the output file (shows the results for all features)\n",
    "fp_out = open('../results/Molecular_Determinants/ResultsOverview.csv','w')\n",
    "fp_out.write('Feature,InteractionType1,InteractionType2,Mean1,Mean2,FisherTest,PVal,PercentChange/OddsRatio,CohenD,BootstrapSign\\n')\n",
    "\n",
    "#Go thorugh each feature\n",
    "for f in features:\n",
    "    print f\n",
    "    \n",
    "    #check if all values of the given features are either 1 or 0 => then use Fisher Exact test to determine significance\n",
    "    make_Fisher = False\n",
    "    if all(v == 0 or v ==1 for v in dic_feature_results[f].values()[0]):\n",
    "        make_Fisher = True\n",
    "    \n",
    "    #Define and create the output folder for the Bootstrapping plots (if doesnt exist)\n",
    "    directory = os.path.dirname('../results/Molecular_Determinants/Bootstrapping/' + f + '/')\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    \n",
    "    ####\n",
    "    # CREATE a standard boxplot for the features (only rly makes sense for continues values - make for binary features still though)\n",
    "    bplot = sns.boxplot(data=[dic_feature_results[f]['NoInteraction'],dic_feature_results[f]['Interaction'],dic_feature_results[f]['Increasing'],dic_feature_results[f]['Decreasing'],dic_feature_results[f]['Emergent']],orient='h',showmeans = True, showfliers = False)\n",
    "\n",
    "    #Define labels and colors\n",
    "    interaction_types_2 = ['NoInteraction','Interaction','Increasing','Decreasing','Emergent']\n",
    "    interaction_colors_2 = ['grey','#F8B301','#ACD900','#F70020','#0096FF']\n",
    "    color_dict = dict(zip(interaction_types_2, interaction_colors_2))\n",
    "    for i in range(0,5):\n",
    "        mybox = bplot.artists[i]\n",
    "        mybox.set_facecolor(color_dict[interaction_types_2[i]])\n",
    "\n",
    "    #Add title and proper ticks\n",
    "    plt.title(f)\n",
    "    plt.yticks(range(0,5),['NoInteraction','NoInteraction','Increasing','Decreasing','Emergent'])\n",
    "    plt.ylabel('Interaction Type')\n",
    "    plt.tick_params(axis = 'y', which = 'major', labelsize = 5)\n",
    "    plt.xlabel('Amount')\n",
    "    plt.savefig(directory+'/Boxplot.pdf')\n",
    "    plt.close()\n",
    "    # END creating standard boxplot\n",
    "    #########\n",
    "    \n",
    "    \n",
    "    #####\n",
    "    # CREATE Bootstrap plot (histogram showing the results for the 5 interaction types)\n",
    "    #save the temporary bootstrap results for each interaction thype separately\n",
    "    bootstrap_results = {}\n",
    "    #Calculate bootstrap results for the 5 interaction types\n",
    "    for iT in interactionTypes:\n",
    "        #save mean and std as results\n",
    "        bootstrap_results[iT] = {'b_mean':[],'b_std':[]}\n",
    "        #get the actual data\n",
    "        data = dic_feature_results[f][iT]\n",
    "        #perform bootstrapping with standard bootstrapping rules\n",
    "        b_means, b_stds = bootstrapping(data,number_iterations=10000, bootstrap_sample_size=None)\n",
    "        \n",
    "        #Save results\n",
    "        bootstrap_results[iT]['b_mean'] = b_means\n",
    "        bootstrap_results[iT]['b_std'] = b_stds\n",
    "        \n",
    "        #Xreate a histogram\n",
    "        plt.hist(b_means,bins='auto', color = interaction_colors[iT], alpha=0.4)\n",
    "        plt.savefig(directory+'/BootstrapOVerview.pdf')\n",
    "\n",
    "    plt.close()\n",
    "    # END creating Bootsrap plot\n",
    "    #########\n",
    "    \n",
    "    \n",
    "    #####\n",
    "    # Comparison of mean results per interaction types (Interacting, Increasing, Decrasing, Emergent) compared to NO_INTERACTION\n",
    "    # Create a Histogram for NoInteraction and compare to 4 individual points (represented as lines)\n",
    "    plt.hist(bootstrap_results['NoInteraction']['b_mean'],bins='auto')\n",
    "    plt.axvline(np.mean(dic_feature_results[f]['Interaction']),color=interaction_colors['Interaction'])\n",
    "    plt.axvline(np.mean(dic_feature_results[f]['Increasing']),color=interaction_colors['Increasing'])\n",
    "    plt.axvline(np.mean(dic_feature_results[f]['Decreasing']),color=interaction_colors['Decreasing'])\n",
    "    plt.axvline(np.mean(dic_feature_results[f]['Emergent']),color=interaction_colors['Emergent'])\n",
    "    plt.savefig(directory+'/OldBootstrapPlot.pdf')\n",
    "    plt.close()\n",
    "    # END creating NoInteraction comparison plot\n",
    "    ######\n",
    "    \n",
    "    ###\n",
    "    # COMPARE the bootstrap results between two interaction types to see if they are significantly different\n",
    "    # Go through all different pairs\n",
    "    for iT1 in interactionTypes:\n",
    "        for iT2 in interactionTypes:\n",
    "            if iT1 > iT2:\n",
    "                \n",
    "                #Extract data\n",
    "                data1 = np.array(bootstrap_results[iT1]['b_mean'])\n",
    "                data2 = np.array(bootstrap_results[iT2]['b_mean'])\n",
    "\n",
    "                # Create a new distribution by substracting all the bootstrap results from each other\n",
    "                # If 0 is completely outside this distribution (outside 95 percentile) then significant difference\n",
    "                bootstrap_mean_diff =  list(data1 - data2)\n",
    "                CI = (np.percentile(bootstrap_mean_diff,2.5), np.percentile(bootstrap_mean_diff,97.5))\n",
    "                bootstrapSign = (0 > CI[0] and 0 > CI[1]) or (0 < CI[0] and 0 < CI[1])\n",
    "                \n",
    "                # Calculate corresponding Cohen's D\n",
    "                c_d = cohen_d(data1,data2)\n",
    "                \n",
    "                # Calculate if two groups are significant different according to Fisher test (if binary data)\n",
    "                if make_Fisher:\n",
    "                    group1_Overlap = sum(dic_feature_results[f][iT1])\n",
    "                    group1_NonOverlap = len(dic_feature_results[f][iT1]) - group1_Overlap\n",
    "\n",
    "                    group2_Overlap = sum(dic_feature_results[f][iT2])\n",
    "                    group2_NonOverlap = len(dic_feature_results[f][iT2]) - group2_Overlap\n",
    "\n",
    "                    effect, pval = stats.fisher_exact([[group1_Overlap, group1_NonOverlap], [group2_Overlap, group2_NonOverlap]])\n",
    "                # Else calulate according to Mann Whitney U\n",
    "                else:\n",
    "                    pval = mu(dic_feature_results[f][iT1],dic_feature_results[f][iT2])[1]\n",
    "                    effect = (np.mean(data1) - np.mean(data2))/np.mean(data2) * 100\n",
    "                \n",
    "                # Create the difference bootstrap plot, with percentile and zero as markers; Add significance calculation to the title\n",
    "                plt.hist(bootstrap_mean_diff,bins='auto', color='grey')\n",
    "                plt.title(iT1 +'_' +iT2+': %.2f' %pval)\n",
    "                plt.axvline(CI[0])\n",
    "                plt.axvline(CI[1])\n",
    "                plt.axvline(0,c='red',ls='--')\n",
    "                #plt.show()\n",
    "                plt.savefig(directory+'/Bootstrap_'+iT1 +'_' +iT2+'.pdf')\n",
    "                plt.close()\n",
    "\n",
    "                # Save the results to the overview file\n",
    "                fp_out.write(f+','+iT1+','+iT2+','+str(np.mean(dic_feature_results[f][iT1]))+','+str(np.mean(dic_feature_results[f][iT2]))+','+str(make_Fisher)+','+str(pval)+','+str(effect)+','+str(c_d)+','+str(bootstrapSign)+'\\n')\n",
    "fp_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Radar plots\n",
    "Additionally also create per feature radar plots, that are capable showing the disticnt moleular properties per interaction type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Define functions for the creation of radar plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radiusAngle_ToCoordinates(r, phi):\n",
    "    '''\n",
    "    Transform the radius and angle into x and y coordinates. Depending on the quadrant in, the sin gives either the x\n",
    "    or y coordinate (and cos the other). As the angle is given between zero and 2pi, depending on the quadrant\n",
    "    adjusted so we can create triangles\n",
    "\n",
    "    :param r: radius of the point\n",
    "    :param phi: angle between 0 and 2pi\n",
    "    :return: x and y coordinate\n",
    "    '''\n",
    "\n",
    "    if phi <= pi / 2:\n",
    "        #print 'Upper Right'\n",
    "        x = math.sin(phi) * r\n",
    "        y = math.cos(phi) * r\n",
    "        quadr = 'UR'\n",
    "    elif phi <= pi:\n",
    "        #print 'Below Right'\n",
    "        phi = phi - (pi / 2)\n",
    "        x = math.cos(phi) * r\n",
    "        y = math.sin(phi) * r * (-1)\n",
    "        quadr = 'BR'\n",
    "    elif phi <= (3 * pi) / 2:\n",
    "        #print 'Below Left'\n",
    "        phi = phi - (pi)\n",
    "        x = math.sin(phi) * r * (-1)\n",
    "        y = math.cos(phi) * r * (-1)\n",
    "        quadr = 'BL'\n",
    "    else:\n",
    "        #print 'Upper Left'\n",
    "        phi = phi - (3 * pi / 2)\n",
    "        x = math.cos(phi) * r * (-1)\n",
    "        y = math.sin(phi) * r\n",
    "        quadr = 'UL'\n",
    "\n",
    "    return x, y, quadr\n",
    "\n",
    "def Find_Intersection(rc, phi1, r1, phi2, r2):\n",
    "    '''\n",
    "    Find the intersection of a line drawn between two points (given by their radius and angle) with a circle centered\n",
    "    around zero and a given radius\n",
    "\n",
    "    :param rc: radius of the circle\n",
    "    :param phi1: first angle\n",
    "    :param r1:   first radius\n",
    "    :param phi2: second angle\n",
    "    :param r2:   second radius\n",
    "    :return: angle of the intersection (as radius has to be rc)\n",
    "    '''\n",
    "\n",
    "    # transform radius and angle into x and y coordinates (using sin/cos)\n",
    "    x1, y1, quadr1 = radiusAngle_ToCoordinates(r1, phi1)\n",
    "    x2, y2, quadr2 = radiusAngle_ToCoordinates(r2, phi2)\n",
    "\n",
    "    # Create Function to plot\n",
    "    # factor = (y2-y1)/(x2-x1)\n",
    "    # print 'y = %.3fx + %.3f' %(factor,-(factor*x1) + y1)\n",
    "\n",
    "\n",
    "    # Define the symbol to solve for\n",
    "    x = Symbol(\"x\")\n",
    "    # Intersect the line with the circle\n",
    "    x_intersect = solve(((y2 - y1) * (x - x1)) / (x2 - x1) + y1 - sqrt(\n",
    "        rc * rc - x * x))  # take positive values of circle results (minus times plus = minus) // gives you all result for the positive circle (> 0)\n",
    "\n",
    "    # Go thre all POSITIVE VALUES (check if one of the angles is between the two original angles; intersection net to be between)\n",
    "    for x in x_intersect:\n",
    "\n",
    "        # Get the corresponding y coordinate\n",
    "        y_intersect = ((y2 - y1) * (x - x1)) / (x2 - x1) + y1\n",
    "\n",
    "        # calculate Phi\n",
    "        result_phi = math.acos(abs(x) / rc)\n",
    "\n",
    "        # Again adjust to quadrant\n",
    "        if x >= 0 and y_intersect >= 0:\n",
    "            #print 'Upper Right'\n",
    "            result = (pi / 2 - result_phi)\n",
    "        elif x >= 0 and y_intersect <= 0:\n",
    "            #print 'Lower Right'\n",
    "            result = (pi / 2 + result_phi)\n",
    "        elif x <= 0 and y_intersect <= 0:\n",
    "            #print 'Lower Left'\n",
    "            result = (((3 * pi) / 2) - result_phi)\n",
    "        else:\n",
    "            #print 'Upper Left'\n",
    "            result = (((3 * pi) / 2) + result_phi)\n",
    "\n",
    "        # if proper angle found return\n",
    "        if result > phi1 and result < phi2:\n",
    "            return result\n",
    "\n",
    "    # Define the symbol to solve for\n",
    "    x = Symbol(\"x\")\n",
    "    # Intersect the line with the circle\n",
    "    x_intersect = solve(((y2 - y1) * (x - x1)) / (x2 - x1) + y1 + sqrt(\n",
    "        rc * rc - x * x))  # take negative values of circle results (minus times plus = minus)// gives you all result for the negative circle (< 0)\n",
    "\n",
    "    # Go thre all NEGATIVE VALUES (check if one of the angles is between the two original angles; intersection net to be between)\n",
    "    for x in x_intersect:\n",
    "\n",
    "        # Get the corresponding y coordinate\n",
    "        y_intersect = ((y2 - y1) * (x - x1)) / (x2 - x1) + y1\n",
    "\n",
    "        # calculate Phi\n",
    "        result_phi = math.acos(abs(x) / rc)\n",
    "\n",
    "        # Again adjust to quadrant\n",
    "        if x >= 0 and y_intersect >= 0:\n",
    "            #print 'Upper Right'\n",
    "            result = (pi / 2 - result_phi)\n",
    "        elif x >= 0 and y_intersect <= 0:\n",
    "            #print 'Lower Right'\n",
    "            result = (pi / 2 + result_phi)\n",
    "        elif x <= 0 and y_intersect <= 0:\n",
    "            #print 'Lower Left'\n",
    "            result = (((3 * pi) / 2) - result_phi)\n",
    "        else:\n",
    "            #print 'Upper Left'\n",
    "            result = (((3 * pi) / 2) + result_phi)\n",
    "\n",
    "        # if proper angle found return\n",
    "        if result > phi1 and result < phi2:\n",
    "            return result\n",
    "\n",
    "    return 'Nothing Found'\n",
    "\n",
    "def my_SpiderPlot(categories, values, color, title,num='None', toNormalizeSmallest='None', toNormalizeBiggest=\"None\"):\n",
    "    '''\n",
    "    Create a Spider Plot\n",
    "\n",
    "    :param categories: categories of the spiderplots (the individual factors)\n",
    "    :param values: actual values\n",
    "    :param color:  the colorscheme (e.g. deactivating = red)\n",
    "    :param title:  name of the spiederplot\n",
    "    :param num:    in case of overlay (else just None for individual Spiderplots)\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    if toNormalizeSmallest !=\"None\":\n",
    "        #Normalize all values to a pre given value\n",
    "        nullValue = int(toNormalizeSmallest) - 3\n",
    "\n",
    "        newValues = [x + abs(toNormalizeSmallest) + 3 for x in values]\n",
    "\n",
    "        max_yticks = int(toNormalizeBiggest) + 1\n",
    "    else:\n",
    "        #Get the lowest value (e.g . -10), for ploting this will be zero; add three so the lowest value is NOT in the middle but a bit away\n",
    "        nullValue =  int(min(values)) - 3\n",
    "\n",
    "        #Normalize all values, e.g. the -10 to zero, whereas the zero will be 10 in the plot\n",
    "        newValues = [x+abs(min(values))+3 for x in values]\n",
    "\n",
    "        #Define the max tick as max value plus one (for aesthetics)\n",
    "        max_yticks = int(max(values))+3\n",
    "\n",
    "    #get the negative ticks and positive ticks\n",
    "    negative_ticks = [str(x) for x in range(nullValue,0,1)]\n",
    "    positive_ticks = [str(x) for x in range(0,max_yticks+1,1)]\n",
    "    negative_ticks.extend(positive_ticks)\n",
    "\n",
    "    #print negative_ticks\n",
    "    #exit()\n",
    "    #Take only 8 tick marks\n",
    "    to_take = len(negative_ticks)/8\n",
    "    chosen_ticks = [negative_ticks[x] for x in range(0,len(negative_ticks),to_take)]\n",
    "\n",
    "    #take the normalized values to plot (i.e. the values where the -10 became the zero\n",
    "    values = newValues\n",
    "\n",
    "    #Find number of categories\n",
    "    N = len(categories)\n",
    "\n",
    "    # What will be the angle of each axis in the plot? (we divide the plot / number of variable)\n",
    "    # The total of 2pi (around 6.2) is divided into the amount of categories; In final plot it will be just from 0 till 2 in pi (factor 3.1415 is missing)\n",
    "    angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "    angles += angles[:1]\n",
    "\n",
    "\n",
    "    # Initialise the spider plot\n",
    "    if num != 'None':\n",
    "        ax = plt.subplot(1, 3, num+ 1, polar=True, )\n",
    "    else:\n",
    "        ax = plt.subplot(1, 1, 1, polar=True, )\n",
    "\n",
    "    # If you want the first axis to be on top:\n",
    "    ax.set_theta_offset(pi / 2)\n",
    "    ax.set_theta_direction(-1)\n",
    "\n",
    "    # Draw one axe per variable + add labels labels yet\n",
    "    #categories = [x.split('AllRandom')[0] for x in categories]\n",
    "    plt.xticks(angles[:-1], categories, color='grey', size=8)\n",
    "\n",
    "    # Draw ylabels\n",
    "    ax.set_rlabel_position(0)\n",
    "\n",
    "    #add last value, to close the circle\n",
    "    values.append(values[0])\n",
    "\n",
    "    #plot the line\n",
    "    ax.plot(angles, values, color=color, linewidth=2, linestyle='solid')\n",
    "\n",
    "    #ax.fill(angles, values, color=color, alpha=0.4)\n",
    "\n",
    "\n",
    "    #Go threw all the points, whenever there is a switch between a positive and a negative ZScore, the line\n",
    "    #intersects with the zero line, hence new color; use the find_intersection function to find probper intersection\n",
    "    i_was = 'Nowhere'\n",
    "    tmp = []\n",
    "    tmp_angles = []\n",
    "    to_save = []\n",
    "    prev_val = 0\n",
    "    prev_ang = 0\n",
    "\n",
    "    angles_to_save_cut = []\n",
    "    normal_angles = []\n",
    "\n",
    "    #Go thre all values and angles\n",
    "    for val,ang in zip(newValues,angles):\n",
    "\n",
    "        #Check if value is positive or negative\n",
    "        if val > abs(nullValue):\n",
    "            i_am = 'Positive'\n",
    "        else:\n",
    "            i_am = 'Negative'\n",
    "\n",
    "        #Check if there is a switch between positive and negative\n",
    "        if i_was != i_am and i_was != 'Nowhere':\n",
    "\n",
    "            #Define the radius of the circle (=y)\n",
    "            y = abs(nullValue)\n",
    "\n",
    "            #if the last line is between 3 quadrant and the origin (change 0.0 to 6.2831 = 2pi = full circle)\n",
    "            if prev_ang > 3.15 and ang == 0.0:\n",
    "                ang = 6.2831\n",
    "\n",
    "            #Find the actual intersection\n",
    "            result = Find_Intersection(y,prev_ang,prev_val,ang,val)\n",
    "            angles_to_save_cut.append(result)\n",
    "\n",
    "            #if more than one angle belongs to one section, before creating new tmp, add current to save\n",
    "            if len(tmp) >0:\n",
    "                to_save.append(tmp)\n",
    "                normal_angles.append(tmp_angles)\n",
    "\n",
    "            #start new tmp (= section of color)\n",
    "            tmp = [val]\n",
    "            tmp_angles = [ang]\n",
    "        #if still in same section just add angle and value\n",
    "        else:\n",
    "            tmp.append(val)\n",
    "            tmp_angles.append(ang)\n",
    "\n",
    "        #Remember previous location\n",
    "        i_was = i_am\n",
    "        prev_val = val\n",
    "        prev_ang = ang\n",
    "\n",
    "    #Final results of intersection parts (angles and values)\n",
    "    to_save.append(tmp)\n",
    "    normal_angles.append(tmp_angles)\n",
    "\n",
    "    #make a fine grained amount of angles (361 individual degrees), and close circle again\n",
    "    angles2 = [n / float(360) * 2 * pi for n in range(360)]\n",
    "    angles2 += angles2[:1]\n",
    "\n",
    "    #Define color scheme\n",
    "    '''\n",
    "    colorscheme = {'green':{0:'#acd900',1:'#a6c143',2:'#648a58',3:'#5c5e4c',4:'#acd900',5:'#a6c143',6:'#648a58',7:'#5c5e4c'},\n",
    "                   'red': {0: '#f70020', 1: '#e66a22', 2: '#e79935', 3: '#dcb471', 4: '#f70020',5:'#e66a22',6:'#e79935',7:'#dcb471'},\n",
    "                   'blue':{0: '#0096ff', 1: '#2bbfb8', 2: '#29a2ac', 3: '#4c7584', 4: '#0096ff', 5: '#2bbfb8',6:'#29a2ac',7:'#4c7584'},\n",
    "                   'grey':{0:'#252525',1:'#636363',2:'#969696',3:'#cccccc',4:'#f7f7f7'}\n",
    "\n",
    "                   }\n",
    "    '''\n",
    "    '''\n",
    "    colorscheme = {'green':{0:'#acd900',1:'#acd900',2:'#acd900',3:'#acd900',4:'#acd900',5:'#acd900',6:'#acd900',7:'#acd900'},\n",
    "                   'red': {0: '#f70020', 1: '#f70020', 2: '#f70020', 3: '#f70020', 4: '#f70020',5:'#f70020',6:'#f70020',7:'#f70020'},\n",
    "                   'blue':{0: '#0096ff', 1: '#0096ff', 2: '#0096ff', 3: '#0096ff', 4: '#0096ff', 5: '#0096ff',6:'#0096ff',7:'#0096ff'},\n",
    "                   'grey':{0:'#252525',1:'#252525',2:'#252525',3:'#252525',4:'#252525'}\n",
    "\n",
    "    }\n",
    "    '''\n",
    "    colorscheme = {'green':{0:'#acd900',1:'#a6c143',2:'#acd900',3:'#a6c143',4:'#acd900',5:'#a6c143',6:'#acd900',7:'#a6c143'},\n",
    "                   'red': {0: '#f70020', 1: '#e66a22', 2: '#f70020', 3: '#e66a22', 4: '#f70020',5:'#e66a22',6:'#f70020',7:'#e66a22'},\n",
    "                   'blue':{0: '#0096ff', 1: '#2bbfb8', 2: '#0096ff', 3: '#2bbfb8', 4: '#0096ff', 5: '#2bbfb8',6:'#0096ff',7:'#2bbfb8'},\n",
    "                   'grey':{0:'#252525',1:'#636363',2:'#252525',3:'#636363',4:'#252525'}\n",
    "\n",
    "    }\n",
    "\n",
    "\n",
    "    #If the first section is bigger than one immedieatly\n",
    "    nofirstcut = False\n",
    "    if len(to_save[0]) > 0:\n",
    "        angles_to_save_cut.insert(0,0)\n",
    "        nofirstcut = True\n",
    "    angles_to_save_cut += angles_to_save_cut[:1]\n",
    "\n",
    "\n",
    "    #fill the individual parts\n",
    "    for i in range(0,len(to_save)):\n",
    "\n",
    "        #save_cut[i] to savecut[i+1] define the whole area, + add all the angles between these two\n",
    "        to_fill_angles = [angles_to_save_cut[i]]\n",
    "        to_fill_Values = [abs(nullValue)]\n",
    "\n",
    "        to_fill_Values.extend(to_save[i])\n",
    "        to_fill_angles.extend(normal_angles[i])\n",
    "\n",
    "        to_fill_angles.append(angles_to_save_cut[i+1])\n",
    "        to_fill_Values.append(abs(nullValue))\n",
    "\n",
    "\n",
    "        #This part followes the zero line back to define where things should be filled\n",
    "        if angles_to_save_cut[i+1] > angles_to_save_cut[i]:\n",
    "            go_back = [x for x in angles2 if x < angles_to_save_cut[i+1] and x > angles_to_save_cut[i]]\n",
    "            go_back = go_back[::-1]\n",
    "            go_back.pop(0)\n",
    "\n",
    "        else:\n",
    "            go_back = [x for x in angles2 if  x < angles_to_save_cut[i+1]]\n",
    "            go_back2 = [x for x in angles2 if x > angles_to_save_cut[i]]\n",
    "\n",
    "            go_back = go_back[::-1]\n",
    "            if 0 in go_back:\n",
    "                go_back.pop(0)\n",
    "\n",
    "            go_back2 = go_back2[::-1]\n",
    "\n",
    "            go_back.extend(go_back2)\n",
    "\n",
    "        #add here the previously go back angles and values (values is always the radius of the zero line)\n",
    "        to_fill_angles.extend(go_back)\n",
    "        to_fill_Values.extend([abs(nullValue)] * len(go_back))\n",
    "\n",
    "        #in case there is a not directly a first cut adjust color\n",
    "        if nofirstcut == True and i == len(to_save)-1:\n",
    "\n",
    "            ax.fill(to_fill_angles, to_fill_Values, color=colorscheme[color][0])\n",
    "\n",
    "        else:\n",
    "            ax.fill(to_fill_angles, to_fill_Values, color=colorscheme[color][i])\n",
    "\n",
    "\n",
    "    #Plot the zero zScore line plus and minus 2 (significance\n",
    "    plt.plot(angles2,[abs(nullValue)]*361, color = 'black')\n",
    "    plt.yticks(range(0,len(negative_ticks),to_take),chosen_ticks)\n",
    "    # Add a title\n",
    "    plt.title(title, size=11, color=color, y=1.1)\n",
    "    plt.setp( ax.get_yticklabels(), visible=False)\n",
    "    plt.setp( ax.get_xticklabels(), visible=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Create actual radar plots\n",
    "Go through the results of the indivdiual interactions types and create radar plots. The radar plots show Cohen's D (effect size) difference between the individual interaction results e.g. Increasing, Decreasing, Emergent compared to the overall interaction results. In case all 3 interaction types have very similar results, then also all 3 interactions types result in Cohen's D close to zero. High Cohen's D indicate big variability between interaction types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interaction types\n",
    "selected_results = {'Increasing':{},'Decreasing':{},'Emergent':{},'Interaction':{}}\n",
    "\n",
    "# Define what to compare the results to, here choosen overall interaction results\n",
    "compare_to = 'Interaction'\n",
    "\n",
    "# The 12 representative features chosen to cover all feature classes\n",
    "selected_features = ['ChemicalSimilarity','Enzymes_Overlap','Transporters_Overlap','PPI_Mean_AB_All_Filtered',\n",
    "                     'KeGG_Indirect_Overlap','GO_Component','GO_Function','GO_Process','Msig_ChemGen_Perturbation_Overlap',\n",
    "                     'SideEffects_CLOUD_to_Offsides_Overlap','SideEffects_TwoSide_CLOUDs','Disease']\n",
    "\n",
    "# Read the result file and save the corresponding results\n",
    "fp = open('../results/Molecular_Determinants/ResultsOverview.csv','r')\n",
    "fp.next()\n",
    "for line in fp:\n",
    "    tmp = line.strip().split(',')\n",
    "    \n",
    "    if tmp[0] in selected_features:\n",
    "        if tmp[1] == compare_to:\n",
    "            selected_results[tmp[2]][tmp[0]] = float(tmp[8]) * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define colors\n",
    "interaction_colors = {'Increasing':'green','Decreasing':'red','Emergent':'blue','Interaction':'grey'}\n",
    "\n",
    "# Create a spider plot for each interaction type separately\n",
    "for key in ['Increasing','Decreasing','Emergent']:\n",
    "    part =  key\n",
    "    categories = []\n",
    "    values = []\n",
    "    for f in selected_features:\n",
    "        categories.append(f)\n",
    "        values.append(selected_results[key][f])\n",
    "        \n",
    "    my_SpiderPlot(categories, values, interaction_colors[part], part,'None',-1,2) #-1 and 2 for compare to Interaction, or -11 and 6\n",
    "    plt.savefig('../results/Molecular_Determinants/SpiderPlots/'+part+'.pdf',format='pdf')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# Create one spider plot for all 3 interaction types together \n",
    "for key in ['Increasing','Decreasing','Emergent']:\n",
    "    part =  key\n",
    "    categories = []\n",
    "    values = []\n",
    "    for f in selected_features:\n",
    "        categories.append(f)\n",
    "        values.append(selected_results[key][f])\n",
    "        \n",
    "    my_SpiderPlot(categories, values, interaction_colors[part], part,'None',-1,2) #-1 and 2 for compare to Interaction, or -11 and 6\n",
    "#plt.show()\n",
    "plt.savefig('../results/Molecular_Determinants/SpiderPlots/Combined.pdf',format='pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Create final overview plot\n",
    "Create a final overview plot that visualizes which feature, in which network compartment (e.g. Core, Periphery ...) for which interaction type (increasing, decreasing ...) significant is. Therefor calculate depending on the type of interaction the signficance as well as a foldchange/oddsRation to get an idea wheter the feature is rather depleeted or enriched. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Create binned results (per network layer)\n",
    "Similar as in previous parts here, split the results accordingly into the various parts. Add here the network layer so that each result is properly sorted for each network layer as well as interaction type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 12 representative features chosen to cover all feature classes\n",
    "selected_features = ['ChemicalSimilarity','Enzymes_Overlap','Transporters_Overlap','PPI_Mean_AB_All_Filtered',\n",
    "                     'KeGG_Indirect_Overlap','GO_Component','GO_Function','GO_Process','Msig_ChemGen_Perturbation_Overlap',\n",
    "                     'SideEffects_CLOUD_to_Offsides_Overlap','SideEffects_TwoSide_CLOUDs','Disease']\n",
    "\n",
    "# Define size and colors for the final plot\n",
    "interaction_colors = {'Increasing':'#ACD900','Decreasing':'#F70020','Emergent':'#0096FF','All':'black'}\n",
    "interaction_sizes = {'Increasing':200,'Decreasing':200,'Emergent':200,'All':2000}\n",
    "network_parts = ['Complete','Core','CoreToPeriphery','Periphery']\n",
    "\n",
    "# Get the result file\n",
    "fp = open('../data/Molecular_Determinants/DrugPair_Feature_Overview.csv','r')\n",
    "\n",
    "# Dictionary that will contain the information which interactions belong to which network layer\n",
    "network_part_interactions = {}\n",
    "\n",
    "# add the individual network parts to the network_part_interactions (result dictionary)\n",
    "for part in network_parts:\n",
    "    network_part_interactions[part] = []        \n",
    "    network_part = nx.read_gml('../data/Molecular_Determinants/Networks/DPI_Network_'+part+'.gml')\n",
    "    network_part_interactions[part] = network_part\n",
    "\n",
    "# List containing all features (i.e. features in DrugPair_Feature_Overview.csv = all investigated features )\n",
    "features = fp.readline().strip().split(',')[4:]\n",
    "\n",
    "# Dictionary that will contain the individual results, split for network layers as well as interaction types\n",
    "network_part_values = {}\n",
    "\n",
    "# go through all features\n",
    "for f in range(0,len(features)):\n",
    "    # always start at row one (first row containing results, zero row = header)\n",
    "    fp.seek(0)\n",
    "    fp.next()\n",
    "\n",
    "    # only continue if the feature is one of the representative features\n",
    "    if features[f] not in selected_features:\n",
    "        continue\n",
    "\n",
    "    print features[f]\n",
    "    # add section for this feature to the result dictionary:  network_part_values\n",
    "    network_part_values[features[f]] = {}\n",
    "    \n",
    "    # as next level add the individual network parts as well as interaction types\n",
    "    for part in network_parts:\n",
    "        network_part_values[features[f]][part] = {'Increasing':[],'Decreasing':[],'Emergent':[]}\n",
    "    network_part_values[features[f]]['AllCLOUDS'] = []\n",
    "    network_part_values[features[f]]['NonInteracting'] = []\n",
    "\n",
    "    # now go through all results and add every feature result into the correct bin\n",
    "    for line in fp:\n",
    "        tmp = line.strip().split(',')\n",
    "\n",
    "        # do not include 'nan' values (e.g. if one drug has no targets then PPI mean distance = nan)\n",
    "        if tmp[f+4] == 'nan':\n",
    "            continue\n",
    "\n",
    "        interaction_found = False\n",
    "        \n",
    "        #only include pure single edges e.g. do not include increasing/decreasing interactions\n",
    "        if tmp[3] == 'Increasing' or  tmp[3] == 'Decreasing' or  tmp[3] == 'Emergent' or tmp[3] == 'None':\n",
    "\n",
    "            # AllCLOUDs = all pairs (is always added)\n",
    "            network_part_values[features[f]]['AllCLOUDS'].append(float(tmp[f+4]))\n",
    "\n",
    "            ######\n",
    "            # Add the result accordingly (which interaction type or network layer it belongs)\n",
    "            # This creates the actual final network_part_values dictionary that will be used in the next step to create the overview plot\n",
    "            for part in network_parts:\n",
    "                if  network_part_interactions[part].has_edge(tmp[0],tmp[1]):\n",
    "                    interaction_found = True\n",
    "                    for key in network_part_interactions[part][tmp[0]][tmp[1]]:\n",
    "                        network_part_values[features[f]][part][network_part_interactions[part][tmp[0]][tmp[1]][key]['Type']].append(float(tmp[f+4]))\n",
    "\n",
    "                if  network_part_interactions[part].has_edge(tmp[1],tmp[0]):\n",
    "                    interaction_found = True\n",
    "                    for key in network_part_interactions[part][tmp[1]][tmp[0]]:\n",
    "                        network_part_values[features[f]][part][network_part_interactions[part][tmp[1]][tmp[0]][key]['Type']].append(float(tmp[f+4]))\n",
    "\n",
    "            if interaction_found == False:\n",
    "                network_part_values[features[f]]['NonInteracting'].append(float(tmp[f+4]))\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Create actual overview plot\n",
    "Use the results stored in network_part_values to create an easy overview plot. Split the result into the individual network layers (= rows) and features (=columns). Each cell (row X column) will have 4 triangles: one black big triangle = All interaction types, and 3 smaller ones indicating the individual interaction type results (emergent, increasing and decreasing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create overview plot for SELECTED features\n",
    "all_Features = selected_features\n",
    "\n",
    "# Create overview plot for ALL features\n",
    "#all_Features = features\n",
    "\n",
    "# Get number of features\n",
    "number_features = len(all_Features)\n",
    "\n",
    "# Change size of the final plot accordingly to the number of features (more features = larger plot)\n",
    "plt.figure(figsize=(number_features,4))\n",
    "#plt.tight_layout()\n",
    "feature_names = []\n",
    "\n",
    "# position to start adding entries, with each features will be increased by 0.2\n",
    "current_x = 0.8\n",
    "\n",
    "# Go through all features\n",
    "for f in  all_Features:\n",
    "    print f\n",
    "\n",
    "    #add the feature name\n",
    "    feature_names.append(f)\n",
    "\n",
    "    #save NoInteraction values\n",
    "    no_interaction_values = network_part_values[f]['NonInteracting']\n",
    "\n",
    "    # similar as current_x, defines where to put the results on the y axis\n",
    "    y = 4.2\n",
    "\n",
    "\n",
    "    #Go through all network parts\n",
    "    for part in network_parts:\n",
    "\n",
    "\n",
    "        # AllInteractions is simply the union of the 3 different interaction types\n",
    "        AllInteractions = network_part_values[f][part]['Increasing']  + network_part_values[f][part]['Decreasing'] + network_part_values[f][part]['Emergent']\n",
    "     \n",
    "        # Things to test include AllInteraction, Increasing, Decreasing and Emergent\n",
    "        things_to_test = {'All':AllInteractions,'Increasing':network_part_values[f][part]['Increasing'],'Decreasing':network_part_values[f][part]['Decreasing'],'Emergent':network_part_values[f][part]['Emergent']}\n",
    "\n",
    "\n",
    "        # Check wheter the feature is a continues feature (Mann Whitney U) or a binary feature (Fisher Exact test) \n",
    "        continues_features = True\n",
    "        if all(v == 0 or v ==1 for v in no_interaction_values):\n",
    "            continues_features = False\n",
    "\n",
    "        x = current_x\n",
    "        # Calculate the signficance accordingly\n",
    "        for subset in ['All','Increasing','Decreasing','Emergent']:\n",
    "               \n",
    "            # If continues feature calculate significance according to Mann Whitney U\n",
    "            if  continues_features:\n",
    "                direction = np.mean(things_to_test[subset]) > np.mean(no_interaction_values)\n",
    "                sign =  mu(things_to_test[subset],no_interaction_values)[1] < 0.05\n",
    "            # If binary feature calculate significance according to Fisher Exact test\n",
    "            else:\n",
    "                real_Overlap = sum(things_to_test[subset])\n",
    "                real_NonOverlap = len(things_to_test[subset]) - real_Overlap\n",
    "\n",
    "                non_Interactions_Overlap = sum(no_interaction_values)\n",
    "                non_Interactions_NonOverlap = len(no_interaction_values) - sum(no_interaction_values)\n",
    "\n",
    "                oddsratio, pvalue = stats.fisher_exact([[real_Overlap, real_NonOverlap], [non_Interactions_Overlap, non_Interactions_NonOverlap]])\n",
    "\n",
    "                sign = pvalue < 0.05\n",
    "                direction = oddsratio > 1\n",
    "\n",
    "            # Depending on the fold change/ oddsRation define if the feature is rather depleeted or enriched (arrow down or arrow up)\n",
    "            if direction:\n",
    "                symbol = '^'\n",
    "            else:\n",
    "                symbol = 'v'\n",
    "\n",
    "            if sign:\n",
    "                color = interaction_colors[subset]\n",
    "            else:\n",
    "                color = 'grey'\n",
    "            \n",
    "            # add the cell entry accordingly (color if significant, arrow according to depleetion or emergence)\n",
    "            x = x + 0.2\n",
    "            plt.scatter([x],[y],marker=symbol, s=interaction_sizes[subset], color=color)\n",
    "        y = y - 1\n",
    "    current_x = current_x + 1\n",
    "\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "directory = os.path.dirname('../results/Molecular_Determinants/')\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Create the final output (overview plot)\n",
    "plt.ylim([0.6,4.8])\n",
    "plt.xlim([0.3,number_features+1])\n",
    "plt.yticks([1.2,2.2,3.2,4.2],['Periphery','CoreToPeriphery','Core','Complete'])\n",
    "plt.xticks(range(1,number_features),feature_names, rotation='vertical')\n",
    "plt.savefig('../results/Molecular_Determinants/Overviewplot.pdf', bbox_inches = \"tight\")\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize Plates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Included Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Routinely used functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_dir(file_path):\n",
    "    '''\n",
    "    Function to ensure a file path exists, else creates the path\n",
    "\n",
    "    :param file_path:\n",
    "    :return:\n",
    "    '''\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "\n",
    "#Methods for getting feature by feature\n",
    "def getFeatureList(db_table):\n",
    "    mypath = '../results/' + db_table + '/NormalizedFeatures/'\n",
    "\n",
    "    #mypath = '../data/Normalized_Wells/'\n",
    "    onlyfiles = [f for f in os.listdir(mypath) if os.path.isfile(os.path.join(mypath, f))]      # get all files of this folder (but no directories)\n",
    "    onlyfiles.sort()\n",
    "    features = []\n",
    "    for file in onlyfiles:\n",
    "        features.append(file.strip().split('.')[0])\n",
    "\n",
    "    if '' in features:\n",
    "        features.remove('')\n",
    "\n",
    "    return  features\n",
    "\n",
    "#Get the actual feature results from the Tukey plate normalized values\n",
    "def get_feature_result(feature,db_table):\n",
    "\n",
    "\n",
    "    #go threw the input file of the feature\n",
    "    #path = '../data/Normalized_Wells/' + feature + '.csv'\n",
    "    path = '../results/'+db_table+'/NormalizedFeatures/' + feature + '.csv'\n",
    "    fp = open(path, 'r')\n",
    "    fp.next()\n",
    "    feature_results = {}\n",
    "    #mean = {}\n",
    "    for line in fp:\n",
    "        tmp = line.strip().split(',')\n",
    "\n",
    "        plate = int(tmp[0])\n",
    "        well = tmp[1]\n",
    "        drug1 = tmp[2]\n",
    "        conc = tmp[3]\n",
    "        worked = tmp[4]\n",
    "        \n",
    "\n",
    "        #if 'nan' for some features this might happen, then just set to mean of the plate\n",
    "        if tmp[5] != 'nan':\n",
    "            normed_value = tmp[5]\n",
    "        else:\n",
    "            #normed_value = np.mean(mean[plate])\n",
    "            normed_value = 0\n",
    "            worked = 'FALSE'\n",
    "        if normed_value == -100000.0:\n",
    "            worked = 'FALSE'\n",
    "\n",
    "\n",
    "        #else basically create an entry in the dictionary with the information as well as the normed value\n",
    "        #if the dictionary does not yet contain the plate, then set it\n",
    "        if feature_results.has_key(plate):\n",
    "            feature_results[plate][well] = {'Drug_1': drug1, 'Conc': conc, 'Worked': worked,\n",
    "                                                 'N_Value': float(normed_value)}\n",
    "        else:\n",
    "            feature_results[plate] = {\n",
    "                well: {'Drug_1': drug1, 'Conc': conc, 'Worked': worked, 'N_Value': float(normed_value)}}\n",
    "\n",
    "\n",
    "    return  feature_results\n",
    "\n",
    "# Extract the maximum and minimum value for the individual features\n",
    "def get_Xmin_Xmax_perFeatures(db_table):\n",
    "    '''\n",
    "    for each feature find the borders to be set.\n",
    "    Right now the top and lower border are 0.5 percentile as well as 99.5. The most extreme percent (in both direction)\n",
    "    might be an outlier.\n",
    "\n",
    "    :param batch:\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    # load all features\n",
    "    features = getFeatureList(db_table)\n",
    "\n",
    "    #contains all the feature max/min\n",
    "    feature_MaxMin = {}\n",
    "\n",
    "    #output file: create a file for each batch that contains all Max and Min values per feature\n",
    "    ensure_dir('../results/'+db_table+'/POCNormalized/MaxMin_Values.csv')\n",
    "    fp = open('../results/'+db_table+'/POCNormalized/MaxMin_Values.csv','w')\n",
    "    fp.write('Feature,Max,Min\\n')\n",
    "\n",
    "    # go through all the features\n",
    "    for f in features:\n",
    "        feature_MaxMin[f] = {'Max':0.0,'Min':0.0}\n",
    "        # load the data for the spcific feature\n",
    "        screen_results = get_feature_result(f,db_table)\n",
    "\n",
    "        plates = screen_results.keys()\n",
    "\n",
    "        #get all values\n",
    "        all_values = []\n",
    "        for plate in plates:\n",
    "            all_values.extend([screen_results[plate][k]['N_Value'] for k in screen_results[plate] if\n",
    "                          str(screen_results[plate][k]['N_Value']) != '-100000' and screen_results[plate][k]['Worked'] != 'FALSE'])\n",
    "\n",
    "        if len(all_values) == 0:\n",
    "            print 'No Valid results for: %s' %f\n",
    "            continue\n",
    "        max_val = np.percentile(all_values, 99.5)   # discard 0.5% of the highest & lowest values to avoid normalization according to outliers\n",
    "        min_val = np.percentile(all_values, 0.5)\n",
    "\n",
    "\n",
    "        feature_MaxMin[f]['Max'] = max_val\n",
    "        feature_MaxMin[f]['Min'] = min_val\n",
    "        fp.write(f+','+str(max_val)+','+str(min_val)+'\\n')\n",
    "\n",
    "    return feature_MaxMin\n",
    "\n",
    "def Normalize_To_POC(db_table='Default'):\n",
    "\n",
    "    # Define table name\n",
    "    if db_table == 'Default':\n",
    "        print 'Set correct table:'\n",
    "        exit()\n",
    "\n",
    "    if os.path.isfile('../results/'+db_table+'/POCNormalized/MaxMin_Values.csv') == False:\n",
    "        print 'Extracting Min/Max Values'\n",
    "        feature_MaxMin = get_Xmin_Xmax_perFeatures(db_table)\n",
    "    else:\n",
    "        feature_MaxMin = {}\n",
    "        fp = open('../results/'+db_table+'/POCNormalized/MaxMin_Values.csv', 'r')\n",
    "        fp.next()\n",
    "        for line in fp:\n",
    "            tmp = line.strip().split(',')\n",
    "            feature_MaxMin[tmp[0]] = {'Max':float(tmp[1]),'Min':float(tmp[2])}\n",
    "\n",
    "\n",
    "    for feature, values in feature_MaxMin.iteritems():\n",
    "        # pick min & max values from MinMax_Values file\n",
    "        max = values['Max']\n",
    "        min = values['Min']\n",
    "\n",
    "\n",
    "        if min != max:\n",
    "\n",
    "            fp_POC = open('../results/'+db_table+'/POCNormalized/' + feature + '.csv','w')\n",
    "            fp_POC.write('Image_Metadata_Plate,Image_Metadata_Well,Image_Metadata_ID_A,Image_Metadata_ID_B,Worked,POC_Normalized\\n')\n",
    "\n",
    "            # open feature file\n",
    "            fp_features = open('../results/'+db_table+'/NormalizedFeatures/' + feature + '.csv', 'r')\n",
    "            fp_features.next()\n",
    "\n",
    "\n",
    "            for line_f in fp_features:\n",
    "                tmp_f = line_f.strip().split(',')\n",
    "                first_part = tmp_f[0:5]     # new/normalized value should be written between first and second part\n",
    "\n",
    "                value_to_normalize = float(tmp_f[5])\n",
    "\n",
    "                if value_to_normalize > max:    # all values that are higher than the max value should be set to 1\n",
    "                    POC_normalized = 1\n",
    "                elif value_to_normalize < min:      # all values that are smaller than the min value should be set to 0\n",
    "                    POC_normalized = 0\n",
    "                else:                               # if values are between max and min, they should be normalized between 0 and 1\n",
    "                    POC_normalized = (value_to_normalize - min) / (max - min)\n",
    "\n",
    "                fp_POC.write(','.join(first_part)+','+str(POC_normalized)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing to POC for: IsabelCLOUPAC_Per_Image\n",
      "Extracting Min/Max Values\n"
     ]
    }
   ],
   "source": [
    "# - - - - - - - - - - - - - - - - - - - -\n",
    "# Define Experiment\n",
    "table = 'IsabelCLOUPAC_Per_Image'\n",
    "\n",
    "# - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print 'Normalizing to POC for: %s' %table\n",
    "\n",
    "    Normalize_To_POC(table)\n",
    "    #exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Coefficient of Variation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "from matplotlib import pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions and Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - - - - - - - - - - - - - - - - - - - -\n",
    "# Define Experiment\n",
    "table = 'IsabelCLOUPAC_Per_Image'\n",
    "\n",
    "# - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "\n",
    "\n",
    "# Some Easy Outlier detection\n",
    "def reject_outliers_2(data, m=6.):\n",
    "    d = np.abs(data - np.median(data))\n",
    "    mdev = np.median(d)\n",
    "    s = d / (mdev if mdev else 1.)\n",
    "    return [data[i] for i in range(0, len(data)) if s[i] < m]\n",
    "\n",
    "\n",
    "def ensure_dir(file_path):\n",
    "    '''\n",
    "    Function to ensure a file path exists, else creates the path\n",
    "\n",
    "    :param file_path:\n",
    "    :return:\n",
    "    '''\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "\n",
    "# Methods for getting feature by feature\n",
    "def getFeatureList(mypath='../results/' + table + '/POCNormalized/'):\n",
    "    onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "    onlyfiles.sort()\n",
    "    features = []\n",
    "    for file in onlyfiles:\n",
    "        features.append(file.strip().split('.')[0])\n",
    "\n",
    "\n",
    "    if '' in features:\n",
    "        features.remove('')\n",
    "\n",
    "    if 'MaxMin_Values' in features:\n",
    "        features.remove('MaxMin_Values')\n",
    "\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def get_feature_result(feature, db_table):\n",
    "\n",
    "    # go through the input file of the feature\n",
    "    # path = '../data/Normalized_Wells/' + feature + '.csv'\n",
    "    path = '../results/' + db_table + '/POCNormalized/' + feature + '.csv'\n",
    "    fp = open(path, 'r')\n",
    "    fp.next()\n",
    "    feature_results = {}\n",
    "    # mean = {}\n",
    "    for line in fp:\n",
    "        tmp = line.strip().split(',')\n",
    "\n",
    "        plate = int(tmp[0])\n",
    "        well = tmp[1]\n",
    "        drug1 = tmp[2]\n",
    "        conc = tmp[3]\n",
    "        worked = tmp[4]\n",
    "\n",
    "        # if 'nan' for some features this might happen, then just set to mean of the plate\n",
    "        if tmp[5] != 'nan':\n",
    "            normed_value = tmp[5]\n",
    "\n",
    "        else:\n",
    "            # normed_value = np.mean(mean[plate])\n",
    "            normed_value = 0\n",
    "            worked = 'FALSE'\n",
    "\n",
    "        if normed_value == -100000.0:\n",
    "            worked = 'FALSE'\n",
    "\n",
    "\n",
    "        #else basically create an entry in the dictionary with the information as well as the normed value\n",
    "        #if the dictionary does not yet contain the plate, then set it\n",
    "        if feature_results.has_key(plate):\n",
    "            feature_results[plate][well] = {'Drug_1': drug1, 'Conc': conc, 'Worked': worked,\n",
    "                                                 'N_Value': float(normed_value)}\n",
    "        else:\n",
    "            feature_results[plate] = {\n",
    "                well: {'Drug_1': drug1, 'Conc': conc, 'Worked': worked, 'N_Value': float(normed_value)}}\n",
    "\n",
    "    # print feature_results\n",
    "    return feature_results\n",
    "\n",
    "\n",
    "def calculate_intraPlate_CV(table):\n",
    "    '''\n",
    "    Calculate intra plate cv, should be smaller than 0.1. Bigger values indicate features that fluctuate too much\n",
    "    in the same plate. Create a IntraPlate_CV file\n",
    "    :param batch: which batch should be analysed\n",
    "    :return: nothing\n",
    "    '''\n",
    "    print 'Calculate Intra Plate CV for plates (based on DMSO wells): %s' % (str(table))\n",
    "\n",
    "    # load all features\n",
    "    features = getFeatureList()\n",
    "\n",
    "    # open output file\n",
    "    ensure_dir('../results/'+table+'/Coefficient_of_Variation/IntraPlate_Variability.csv')\n",
    "    fp_out = open('../results/'+table+'/Coefficient_of_Variation/IntraPlate_Variability.csv', 'w')\n",
    "    fp_out.write('Feature,IntraPlateCV\\n')\n",
    "\n",
    "\n",
    "    intra_CVs = []\n",
    "    # Calculate CV for each feature\n",
    "    for f in features:\n",
    "        # print f\n",
    "        # load the data for the specific feature\n",
    "        screen_results = get_feature_result(f, table)\n",
    "        plates = screen_results.keys()\n",
    "        # plate_cvs contains the individual intraplate cv's, (final cv = mean over all)\n",
    "        plate_cvs = []\n",
    "\n",
    "        for plate in plates:\n",
    "            # plate well contains all the dmso (POC) values\n",
    "            plate_wells = []\n",
    "\n",
    "            # go through all the wells and look for DMSO treated wells\n",
    "            for well in screen_results[plate]:\n",
    "                if screen_results[plate][well]['Worked'] == 'FALSE' or screen_results[plate][well][\n",
    "                    'N_Value'] == -100000:\n",
    "                    continue\n",
    "\n",
    "                if screen_results[plate][well]['Drug_1'] == 'DMSO':\n",
    "                    plate_wells.append(screen_results[plate][well]['N_Value'])\n",
    "\n",
    "            # if all valus below zero (now set to zero, means all dmso again same value) good cv, else divide by zero\n",
    "            if sum(plate_wells) == 0:\n",
    "                plate_cvs.append(0)\n",
    "            else:\n",
    "                # Reject most extreme outlier\n",
    "                plate_wells_no_outlier = reject_outliers_2(plate_wells)\n",
    "\n",
    "                # calculate the cv\n",
    "                sd = abs(np.std(plate_wells_no_outlier))\n",
    "                mean = abs(np.mean(plate_wells_no_outlier))\n",
    "                cv = (sd / mean)\n",
    "\n",
    "                # add the cv of this plate to the other plates\n",
    "                plate_cvs.append(cv)\n",
    "\n",
    "        # calculate mean cv over all plates and write to file\n",
    "        fp_out.write(f + ',' + str(np.mean(plate_cvs)) + '\\n')\n",
    "        intra_CVs.append(np.mean(plate_cvs))\n",
    "\n",
    "    fp_out.close()\n",
    "\n",
    "    plt.hist(intra_CVs,bins='auto',color='grey')\n",
    "    plt.axvline(0.2,ls='--',c='red')\n",
    "    plt.legend(['Rejected Features: %d' %len([x for x in intra_CVs if x > 0.2])] )\n",
    "    plt.savefig('../results/'+table+'/Coefficient_of_Variation/IntraPlate_Variability.pdf')\n",
    "    plt.close()\n",
    "\n",
    "#calculate_intraPlate_CV(table)\n",
    "\n",
    "\n",
    "def calculate_interPlate_CV(table):\n",
    "    '''\n",
    "    Calculate intra plate cv, should be smaller than 0.1. Bigger values indicate features that fluctuate too much\n",
    "    in the same plate. Create a IntraPlate_CV file\n",
    "    :param batch: which batch should be analysed\n",
    "    :return: nothing\n",
    "    '''\n",
    "    print 'Calculate Inter Plate CV for plates (based on DMSO wells): %s' % (str(table))\n",
    "\n",
    "    # load all features\n",
    "    features = getFeatureList()\n",
    "\n",
    "    # open output file\n",
    "    ensure_dir('../results/' + table + '/Coefficient_of_Variation/InterPlate_Variability.csv')\n",
    "    fp_out = open('../results/' + table + '/Coefficient_of_Variation/InterPlate_Variability.csv', 'w')\n",
    "\n",
    "    fp_out.write('Feature,IntraPlateCV\\n')\n",
    "\n",
    "    inter_CVs = []\n",
    "    # Calculate CV for each feature\n",
    "    for f in features:\n",
    "        # load the data for the spcific feature\n",
    "        screen_results = get_feature_result(f, table)\n",
    "        plates = screen_results.keys()\n",
    "\n",
    "        # plate_means means of all DMSO wells on one plate\n",
    "        plate_means = []\n",
    "        for plate in plates:\n",
    "            # plate well contains all the dmso (POC) values\n",
    "            plate_wells = []\n",
    "            # go threw all the wells and look for DMSO treated wlls\n",
    "            for well in screen_results[plate]:\n",
    "                if screen_results[plate][well]['Worked'] == 'FALSE' or screen_results[plate][well][\n",
    "                    'N_Value'] == -100000:\n",
    "                    continue\n",
    "\n",
    "                if screen_results[plate][well]['Drug_1'] == 'DMSO':\n",
    "                    plate_wells.append(screen_results[plate][well]['N_Value'])\n",
    "\n",
    "            # Reject most extreme outlier\n",
    "            plate_wells_no_outlier = reject_outliers_2(plate_wells)\n",
    "            # add the mean of this plate, later calculate cv for the individual plates\n",
    "\n",
    "            plate_means.append(np.mean(plate_wells_no_outlier))\n",
    "\n",
    "\n",
    "        # if all values are zero, that means also pretty consistant (but would lead to divide by zero error)\n",
    "        if sum(plate_means) == 0:\n",
    "            cv = 0\n",
    "        else:\n",
    "            # calculate the cv\n",
    "            sd = abs(np.std(plate_means))\n",
    "            mean = abs(np.mean(plate_means))\n",
    "            cv = (sd / mean)\n",
    "\n",
    "        # write inter plate CV to file\n",
    "        fp_out.write(f + ',' + str(cv) + '\\n')\n",
    "        inter_CVs.append(cv)\n",
    "\n",
    "\n",
    "    fp_out.close()\n",
    "\n",
    "\n",
    "    plt.hist(inter_CVs, bins='auto', color='grey')\n",
    "    plt.axvline(0.2, ls='--', c='red')\n",
    "    plt.legend(['Rejected Features: %d' % len([x for x in inter_CVs if x > 0.2])])\n",
    "    plt.savefig('../results/' + table + '/Coefficient_of_Variation/InterPlate_Variability.pdf')\n",
    "    plt.close()\n",
    "    # print 'DONE'\n",
    "\n",
    "\n",
    "\n",
    "def calculate_Correlation_BetweenPlates(table,plot=False):\n",
    "\n",
    "\n",
    "    print 'Calculate Correlation between replicates (based on single drug wells): %s' % (str(table))\n",
    "\n",
    "    # load all features\n",
    "    features = getFeatureList()\n",
    "\n",
    "    ensure_dir('../results/' + table + '/Correlation_Between_Replicates/')\n",
    "    fp = open('../results/' + table + '/Correlation_Between_Replicates/Correlation_Results.csv','w')\n",
    "    fp.write('Feature,PearsonCorrelation\\n')\n",
    "    correlations = []\n",
    "    for f in features:\n",
    "\n",
    "        #ensure_dir('../results/' + table + '/Replicates/' + f + '.csv')\n",
    "        # fp_replicates = open('../results/Replicates_Batch' + str(batch) + '/' + f + '.csv', 'w')\n",
    "        # fp_replicates.write('Drug, Concentration, Replicate_1, Replicate_2\\n')\n",
    "\n",
    "        # print f\n",
    "        screen_results = get_feature_result(f, table)\n",
    "\n",
    "        plates = screen_results.keys()\n",
    "\n",
    "\n",
    "        drugs = {}\n",
    "        for plate in plates:\n",
    "            # plate well contains all the dmso (POC) values\n",
    "\n",
    "            # go threw all the wells and look for DMSO treated wlls\n",
    "            for well in screen_results[plate]:\n",
    "                if screen_results[plate][well]['Worked'] == 'FALSE' or screen_results[plate][well][\n",
    "                    'N_Value'] == -100000:\n",
    "                    continue\n",
    "\n",
    "                # if screen_results[plate][well]['Drug_2'] == 'DMSO':\n",
    "                if screen_results[plate][well]['Drug_1'] != 'DMSO':\n",
    "                    if drugs.has_key(screen_results[plate][well]['Drug_1']+','+screen_results[plate][well]['Conc']):\n",
    "                        drugs[screen_results[plate][well]['Drug_1']+','+screen_results[plate][well]['Conc']].append(screen_results[plate][well]['N_Value'])\n",
    "                    else:\n",
    "                        drugs[screen_results[plate][well]['Drug_1']+','+screen_results[plate][well]['Conc']] = [screen_results[plate][well]['N_Value']]\n",
    "\n",
    "                        \n",
    "        X = []\n",
    "        Y = []\n",
    "        for d, v in drugs.iteritems():\n",
    "            if len(drugs[d]) == 2:\n",
    "                #continue\n",
    "                X.append(drugs[d][0])\n",
    "                Y.append(drugs[d][1])\n",
    "                \n",
    "\n",
    "            #for i in range(0, len(drugs[d])):\n",
    "            #    for i2 in range(0, len(drugs[d])):\n",
    "            #        if i > i2:\n",
    "            #            X.append(drugs[d][i])\n",
    "            #            Y.append(drugs[d][i2])\n",
    "\n",
    "        # calculate pearson\n",
    "        cor = np.corrcoef(X, Y)[0][1]\n",
    "        # print f + ': %f' % cor\n",
    "        fp.write(f+','+str(cor)+'\\n')\n",
    "\n",
    "        #In case a feature with only same values 'nan' is result/WIll be filtured through X_min = X_Max filter\n",
    "        if str(cor) != 'nan':\n",
    "\n",
    "            correlations.append(cor)\n",
    "\n",
    "            # make plot\n",
    "            if plot:\n",
    "                plt.xlabel('Replicate 1')\n",
    "                plt.ylabel('Replicate 2')\n",
    "                plt.scatter(X, Y, s=2)\n",
    "                plt.title(f)\n",
    "                plt.legend(['Correlation = %.2f' % (cor)])\n",
    "                ensure_dir('../results/Correlation_Singles_Normalized/Correlation_' + f + '.pdf')\n",
    "                plt.savefig('../results/Correlation_Singles_Normalized/Correlation_' + f + '.pdf', format='pdf', dpi=800)\n",
    "                #plt.show()\n",
    "                plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    plt.hist(correlations, bins='auto', color='grey')\n",
    "    plt.axvline(0.3, ls='--', c='red')\n",
    "    plt.legend(['Rejected Features: %d' % len([x for x in correlations if x < 0.3])])\n",
    "    plt.savefig('../results/' + table + '/Correlation_Between_Replicates/Correlations.pdf')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate Correlation between replicates (based on single drug wells): IsabelCLOUPAC_Per_Image\n"
     ]
    }
   ],
   "source": [
    "#calculate_intraPlate_CV(table)\n",
    "#calculate_interPlate_CV(table)\n",
    "calculate_Correlation_BetweenPlates(table, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

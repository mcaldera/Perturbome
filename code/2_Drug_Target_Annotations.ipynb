{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotate the CLOUD library\n",
    "Find targets for the 267 CLOUD drugs using 3 different databases  \n",
    "a.) DrugBank  \n",
    "b.) PubChem  \n",
    "c.) ChEMBL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Include all libraries needed\n",
    "import networkx as nx\n",
    "import mygene\n",
    "import urllib2\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn3\n",
    "\n",
    "\n",
    "#Use MyGeneInfo to parse between different gene identifiers\n",
    "mg = mygene.MyGeneInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DrugBank\n",
    "Get drugs from the DrugBank-CLOUD subnetwork --> see GenerateDrugBankNetwork.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download Drugbank from https://www.drugbank.ca/releases/latest (version 5.1.2 used), then use 2a_Create_DrugBank_Network.ipynb to parse the xml file\n",
    "DrugBankInfo = nx.read_gml('../data/Drug_Target_Annotations/Drugbank_2018-07-03_CLOUD_Only.gml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse through the gml file for annotated targets (splitted in Targets, Transporters, Carriers, Enzymes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionaries to save extrated DrugBank symbols/Ids\n",
    "CLOUD_DrugBank_Symbols = {}\n",
    "CLOUD_DrugBank_EntrezIDs = {}\n",
    "CLOUD_DrugBank_Symbols_targetsOnly = {}\n",
    "CLOUD_DrugBank_EntrezIDs_targetsOnly = {}\n",
    "CLOUD_Name = {}\n",
    "\n",
    "#Open CLOUD library overview file (contains CLOUD plus identifiers)\n",
    "fp = open('../data/Drug_Target_Annotations/CLOUD_DrugBank_PubChem_Chembl.csv','r')\n",
    "fp.next()\n",
    "\n",
    "#Parse through all CLOUD drugs and check the DrugBank gml file for targets\n",
    "for line in fp:\n",
    "    \n",
    "    tmp = line.strip().split(',')\n",
    "    \n",
    "    CLOUD_Name[tmp[0]] = tmp[4]\n",
    "    \n",
    "    #Dictionary for symbols and entrezIDs (all)\n",
    "    CLOUD_DrugBank_Symbols[tmp[0]] = []\n",
    "    CLOUD_DrugBank_EntrezIDs[tmp[0]] = []\n",
    "    \n",
    "    #Dictionary for symbols and entrezIDs (targets only)\n",
    "    CLOUD_DrugBank_Symbols_targetsOnly[tmp[0]] = []\n",
    "    CLOUD_DrugBank_EntrezIDs_targetsOnly[tmp[0]] = []\n",
    "    \n",
    "    \n",
    "    #Get the raw DrugBank symbols (all)\n",
    "    DrugBank_Target_Symbols = DrugBankInfo.node[tmp[1]]['Targets']\n",
    "    DrugBank_Target_Symbols += ',' +DrugBankInfo.node[tmp[1]]['Enzymes']\n",
    "    DrugBank_Target_Symbols += ',' +DrugBankInfo.node[tmp[1]]['Transporters']\n",
    "    DrugBank_Target_Symbols += ',' +DrugBankInfo.node[tmp[1]]['Carriers']\n",
    "\n",
    "    #Get the raw DrugBank symbols (targets only)\n",
    "    DrugBank_Target_Symbols_targetsOnly = DrugBankInfo.node[tmp[1]]['Targets']\n",
    "    \n",
    "    \n",
    "    #Parse separate drug target from role (e.g. inhibitor) (all)\n",
    "    targets_roles = [x.strip().split('_') for x in DrugBank_Target_Symbols.split(',') if x != '']\n",
    "    targets = []\n",
    "    for t in targets_roles:\n",
    "        targets.append(t[0])\n",
    "        \n",
    "        \n",
    "    #Parse separate drug target from role (e.g. inhibitor) (all)\n",
    "    targets_roles_targetsOnly = [x.strip().split('_') for x in DrugBank_Target_Symbols_targetsOnly.split(',') if x != '']\n",
    "    targets_targetsOnly = []\n",
    "    for t in targets_roles_targetsOnly:\n",
    "        targets_targetsOnly.append(t[0])    \n",
    "    \n",
    "     \n",
    "    #DrugBank only offers symbols, use mygeneinfo the get the corresponding entrezIDs (all)\n",
    "    Symbols = []\n",
    "    EntrezIDs = []\n",
    "    for t in targets:\n",
    "        try:\n",
    "            query = mg.query(t, species='human')\n",
    "            if query.has_key('hits'):\n",
    "                ids = query['hits']\n",
    "                if len(ids) > 0:\n",
    "                    if ids[0]['symbol'] == t:\n",
    "                        CLOUD_DrugBank_Symbols[tmp[0]].append(t)\n",
    "                        CLOUD_DrugBank_EntrezIDs[tmp[0]].append(ids[0]['entrezgene'])\n",
    "        except:\n",
    "            print 'Problem with: %s' %t\n",
    "            \n",
    "    \n",
    "    #DrugBank only offers symbols, use mygeneinfo the get the corresponding entrezIDs (all)\n",
    "    Symbols_targetsOnly = []\n",
    "    EntrezIDs_targetsOnly = []\n",
    "    for t in targets_targetsOnly:\n",
    "        try:\n",
    "            query = mg.query(t, species='human')\n",
    "            if query.has_key('hits'):\n",
    "                ids = query['hits']\n",
    "                if len(ids) > 0:\n",
    "                    if ids[0]['symbol'] == t:\n",
    "                        CLOUD_DrugBank_Symbols_targetsOnly[tmp[0]].append(t)\n",
    "                        CLOUD_DrugBank_EntrezIDs_targetsOnly[tmp[0]].append(ids[0]['entrezgene'])\n",
    "        except:\n",
    "            print 'Problem with: %s' %t\n",
    "    \n",
    "\n",
    "fp.close()\n",
    "\n",
    "\n",
    "# ##################\n",
    "# Save the results #\n",
    "# ##################\n",
    "\n",
    "all_CLOUDS = CLOUD_DrugBank_EntrezIDs.keys()\n",
    "all_CLOUDS.sort()\n",
    "\n",
    "fp_out = open('../results/Drug_Target_Annotations/CLOUD_DrugBank_Targets.csv','w')\n",
    "fp_out.write('CLOUD,Name,EntrezIDs,Symbols\\n')\n",
    "\n",
    "fp_out2 = open('../results/Drug_Target_Annotations/CLOUD_DrugBank_Targets_ONLY.csv','w')\n",
    "fp_out2.write('CLOUD,Name,EntrezIDs,Symbols\\n')\n",
    "for cloud in all_CLOUDS:\n",
    "    fp_out.write(cloud+','+CLOUD_Name[cloud]+','+';'.join([str(x) for x in CLOUD_DrugBank_EntrezIDs[cloud]])+','+';'.join(CLOUD_DrugBank_Symbols[cloud]) +'\\n')\n",
    "    fp_out2.write(cloud+','+CLOUD_Name[cloud]+','+';'.join([str(x) for x in CLOUD_DrugBank_EntrezIDs_targetsOnly[cloud]])+','+';'.join(CLOUD_DrugBank_Symbols_targetsOnly[cloud]) +'\\n')\n",
    "fp_out.close()\n",
    "fp_out2.close()\n",
    "print 'Finished finding DrugBank targets'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PubChem\n",
    "Use the REST service of pubchem to find targets for given drugs; Use the pubchem supported significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getresult(url):\n",
    "    '''\n",
    "    Short function to get json from the PubChem webpage\n",
    "    '''\n",
    "    try:\n",
    "        connection = urllib2.urlopen(url)\n",
    "    except urllib2.HTTPError, e:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return connection.read().rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open CLOUD library overview file (contains CLOUD plus identifiers)\n",
    "fp = open('../data/Drug_Target_Annotations/CLOUD_DrugBank_PubChem_Chembl.csv', 'r')\n",
    "fp.next()\n",
    "\n",
    "#Dictionaries to save extrated pubchem symbols/Ids\n",
    "CLOUD_PubChem_Symbols = {}\n",
    "CLOUD_PubChem_EntrezIDs = {}\n",
    "\n",
    "#Parse through all CLOUD drugs\n",
    "for line in fp:\n",
    "    \n",
    "    tmp = line.strip().split(',')\n",
    "    \n",
    "    PubChem_ID = tmp[2]\n",
    "    CLOUD_PubChem_Symbols[tmp[0]] = []\n",
    "    CLOUD_PubChem_EntrezIDs[tmp[0]] = []\n",
    "    CLOUD_Name[tmp[0]] = tmp[4]\n",
    "    \n",
    "    #Find all assays for a given PubchemID\n",
    "    #Extract then all activities --> Filter for active results\n",
    "    pubChemResults = getresult('https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/%d/assaysummary/CSV' %int(PubChem_ID))\n",
    "    activities = pubChemResults.split('\\n')\n",
    "    geneIDs = set()\n",
    "    tests = set()\n",
    "    for element in activities[1:]:\n",
    "        tmp2 = element.split(',')\n",
    "\n",
    "        if tmp2[6] == '\"Active\"' and tmp2[8] != '\"\"':\n",
    "            geneIDs.add(int(tmp2[8]))\n",
    "            tests.add(tmp2[10])\n",
    "\n",
    "    #After extracting entrezIDs not reversly find the corresponding symbol\n",
    "    query = mg.querymany(geneIDs, scope='entrezgene', species='human',verbose=False)\n",
    "\n",
    "    for result in query:\n",
    "        if result.has_key('symbol'):\n",
    "            CLOUD_PubChem_Symbols[tmp[0]].append(result['symbol'])\n",
    "            CLOUD_PubChem_EntrezIDs[tmp[0]].append(str(result['_id']))         \n",
    "fp.close()\n",
    "\n",
    "# ##################\n",
    "# Save the results #\n",
    "# ##################\n",
    "\n",
    "fp_out = open('../results/Drug_Target_Annotations/CLOUD_PubChem_Targets.csv','w')\n",
    "fp_out.write('CLOUD,Name,EntrezIDs,Symbols\\n')\n",
    "for cloud in all_CLOUDS:\n",
    "    fp_out.write(cloud+','+CLOUD_Name[cloud]+','+';'.join(CLOUD_PubChem_EntrezIDs[cloud])+','+';'.join(CLOUD_PubChem_Symbols[cloud]) +'\\n')\n",
    "fp_out.close()\n",
    "\n",
    "print 'Finished finding PubChem targets'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChEMBL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getresult(url):\n",
    "    '''\n",
    "    Short function to get json from the PubChem webpage\n",
    "    '''\n",
    "    try:\n",
    "        connection = urllib2.urlopen(url)\n",
    "    except urllib2.HTTPError, e:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return connection.read().rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionaries to save extrated ChEMBL symbols/Ids\n",
    "CLOUD_ChEMBL_Symbols = {}\n",
    "CLOUD_ChEMBL_EntrezIDs = {}\n",
    "\n",
    "#Cutoff (in uM) for activity\n",
    "cutoff = 10.0\n",
    "\n",
    "#allowed result types\n",
    "allowed_Types = ['IC50','Ki','EC50']\n",
    "\n",
    "#Open CLOUD library overview file (contains CLOUD plus identifiers)\n",
    "fp = open('../data/Drug_Target_Annotations/CLOUD_DrugBank_PubChem_Chembl.csv', 'r')\n",
    "fp.next()\n",
    "\n",
    "#Parse through all CLOUD drugs\n",
    "for line in fp:\n",
    "    tmp = line.strip().split(',')\n",
    "    \n",
    "    chembl = tmp[3]\n",
    "    \n",
    "    CLOUD_ChEMBL_Symbols[tmp[0]] = []\n",
    "    CLOUD_ChEMBL_EntrezIDs[tmp[0]] = []\n",
    "    CLOUD_Name[tmp[0]] = tmp[4]\n",
    "    \n",
    "\n",
    "    #################################\n",
    "    #Get the annotated targets (ON Targets)\n",
    "    ################################\n",
    "    \n",
    "    #Get the ON Targets (characterized being found under the mechanism page)\n",
    "    onTargets = []\n",
    "    got_data = False\n",
    "    while got_data == False\n",
    "    try:\n",
    "        data = getresult('https://www.ebi.ac.uk/chembl/api/data/mechanism?molecule_chembl_id=' + chembl + '&limit=1000&format=json')\n",
    "        Drug_Data = json.loads(data)\n",
    "        got_data = True\n",
    "    except:\n",
    "        print 'Error'\n",
    "\n",
    "    if Drug_Data.has_key('mechanisms'):\n",
    "        for mechanism in Drug_Data['mechanisms']:\n",
    "            if mechanism['target_chembl_id'] != None:\n",
    "                onTargets.append(mechanism['target_chembl_id'])\n",
    "    \n",
    "    got_data = False\n",
    "    while got_data == False\n",
    "    try:\n",
    "        data = getresult('https://www.ebi.ac.uk/chembl/api/data/target?target_chembl_id__in=' + ','.join(onTargets) + '&format=json')\n",
    "        Target_Data = json.loads(data)\n",
    "        got_data = True\n",
    "    except:\n",
    "        print 'Error'\n",
    "    \n",
    "    #Parse through all targets that are of human origin (discard e.g. bacterial targets)\n",
    "    uniprot_IDs = []\n",
    "    for target in Target_Data['targets']:\n",
    "        if target['tax_id'] ==  9606:\n",
    "            if len(target['target_components']) > 0:\n",
    "                uniprot_IDs.append(target['target_components'][0]['accession'])\n",
    "\n",
    "    #Parse from Uniprot to entrezID and symbols\n",
    "    query = mg.querymany(uniprot_IDs, scope='uniprot', species='human', verbose=False)\n",
    "\n",
    "    for result in query:\n",
    "        if result.has_key('symbol'):\n",
    "            CLOUD_ChEMBL_Symbols[tmp[0]].append(result['symbol'])\n",
    "            CLOUD_ChEMBL_EntrezIDs[tmp[0]].append(str(result['_id'])) \n",
    "\n",
    "            \n",
    "    #################################\n",
    "    #Get the remaining active targets (OFF Targets)\n",
    "    ################################\n",
    "    \n",
    "    #Find all assay results for a given chembl ID\n",
    "    got_data = False\n",
    "    while got_data == False\n",
    "    try:\n",
    "        data = getresult('https://www.ebi.ac.uk/chembl/api/data/activity?molecule_chembl_id='+chembl+'&target_tax_id=9606&assay_type=B&limit=1000&format=json')\n",
    "        Drug_Data = json.loads(data)\n",
    "        got_data = True\n",
    "    except:\n",
    "        print 'Error'\n",
    "    \n",
    "    #Go through Mata information to find actual activities\n",
    "    continueFlag = True\n",
    "    while Drug_Data['page_meta']['next'] != None and continueFlag:\n",
    "        data = getresult('https://www.ebi.ac.uk'+Drug_Data['page_meta']['next'])\n",
    "        Drug_Data_NextPage = json.loads(data)\n",
    "\n",
    "        if Drug_Data_NextPage['page_meta']['next'] != None:\n",
    "            continueFlag = True\n",
    "        else:\n",
    "            continueFlag = False\n",
    "\n",
    "        Drug_Data['activities'].extend(Drug_Data_NextPage['activities'])\n",
    "\n",
    "    \n",
    "    #Find only active results \n",
    "    active = set()\n",
    "    not_active = set()\n",
    "    for act in Drug_Data['activities']:\n",
    "        if act['standard_type'] in allowed_Types:\n",
    "            try:\n",
    "                value = act['published_value']\n",
    "                unit = act['units']\n",
    "\n",
    "                if (unit == 'pM' and float(value) < cutoff * 1000000) or (unit == 'nM' and float(value) < cutoff * 1000) or (unit == 'uM' and float(value) < cutoff) or (unit == 'mM' and float(value) < cutoff/1000) or (unit == 'M' and float(value) < cutoff/1000000):\n",
    "                    active.add(act['target_chembl_id'])\n",
    "                else:\n",
    "                    not_active.add(act['target_chembl_id'])\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    #Extract the uniport target identifiers\n",
    "    got_data = False\n",
    "    while got_data == False\n",
    "    try:\n",
    "        data = getresult('https://www.ebi.ac.uk/chembl/api/data/target?target_chembl_id__in='+','.join(list(active))+'&format=json')\n",
    "        Target_Data = json.loads(data)\n",
    "        got_data = True\n",
    "    except:\n",
    "        print 'Error'\n",
    "                \n",
    "    uniprot_IDs = []\n",
    "    for target in Target_Data['targets']:\n",
    "        if target['tax_id'] == 9606:\n",
    "            if len(target['target_components']) > 0:\n",
    "                uniprot_IDs.append(target['target_components'][0]['accession'])\n",
    "\n",
    "    #Parse from uniprot to entrezID and symbol\n",
    "    query = mg.querymany(uniprot_IDs,scope='uniprot',species='human',verbose=False)\n",
    "\n",
    "    for result in query:\n",
    "        if result.has_key('symbol'):\n",
    "            CLOUD_ChEMBL_Symbols[tmp[0]].append(result['symbol'])\n",
    "            CLOUD_ChEMBL_EntrezIDs[tmp[0]].append(str(result['_id']))\n",
    "    \n",
    "fp.close()\n",
    "\n",
    "\n",
    "# ##################\n",
    "# Save the results #\n",
    "# ##################\n",
    "\n",
    "\n",
    "fp_out = open('../results/Drug_Target_Annotations/CLOUD_ChEMBL_Targets.csv','w')\n",
    "fp_out.write('CLOUD,Name,EntrezIDs,Symbols\\n')\n",
    "for cloud in all_CLOUDS:\n",
    "    fp_out.write(cloud+','+CLOUD_Name[cloud]+','+';'.join(CLOUD_ChEMBL_EntrezIDs[cloud])+','+';'.join(CLOUD_ChEMBL_Symbols[cloud]) +'\\n')\n",
    "fp_out.close()\n",
    "\n",
    "print 'Finished finding ChEMBL targets'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Final List of Targets\n",
    "Create a final list that contains all targets from all sources combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary containing all found targets for a given drug\n",
    "CLOUD_Combined_EntrezIDs = {}\n",
    "\n",
    "#parse through all drugs and find targets from the different source; create output file\n",
    "fp_out = open('../results/Drug_Target_Annotations/CLOUD_All_Targets.csv','w')\n",
    "fp_out.write('CLOUD,Name,EntrezIDs,Symbols\\n')\n",
    "for cloud in all_CLOUDS:\n",
    "    targets = list(CLOUD_DrugBank_EntrezIDs[cloud])\n",
    "    \n",
    "    for t in CLOUD_PubChem_EntrezIDs[cloud]:\n",
    "        if t not in targets:\n",
    "            targets.append(t)\n",
    "    \n",
    "    for t in CLOUD_ChEMBL_EntrezIDs[cloud]:\n",
    "        if t not in targets:\n",
    "            targets.append(t)\n",
    "   \n",
    "    \n",
    "    symbols = list(CLOUD_DrugBank_Symbols[cloud])\n",
    "    for t in CLOUD_PubChem_Symbols[cloud]:\n",
    "        if t not in targets:\n",
    "            symbols.append(t)\n",
    "    \n",
    "    for t in CLOUD_ChEMBL_Symbols[cloud]:\n",
    "        if t not in targets:\n",
    "            symbols.append(t)\n",
    "    \n",
    "    CLOUD_Combined_EntrezIDs[cloud] = targets\n",
    "    \n",
    "    fp_out.write(cloud+','+CLOUD_Name[cloud]+','+';'.join(targets)+','+';'.join(symbols) +'\\n')\n",
    "fp_out.close()\n",
    "print 'Finished Creating Final CLOUD target list'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Drug Target Annotation\n",
    "Check the individual sources for mean, median, total amount of targets found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "targets_DrugBank = []\n",
    "counts_DrugBank = []\n",
    "for c in all_CLOUDS:\n",
    "    targets_DrugBank.extend(CLOUD_DrugBank_EntrezIDs[c])\n",
    "    counts_DrugBank.append(len(CLOUD_DrugBank_EntrezIDs[c]))\n",
    "    \n",
    "print 'DrugBank:'\n",
    "print '\\tTotal amount of targets: %d' %len(targets_DrugBank)\n",
    "print '\\tAmount of distinct targets: %d' %len(set(targets_DrugBank))\n",
    "print '\\tMean targets: %.2f' %np.mean(counts_DrugBank)\n",
    "print '\\tMedian targets: %.2f' %np.median(counts_DrugBank)\n",
    "\n",
    "targets_PubChem = []\n",
    "counts_PubChem = []\n",
    "for c in all_CLOUDS:\n",
    "    targets_PubChem.extend(CLOUD_PubChem_EntrezIDs[c])\n",
    "    counts_PubChem.append(len(CLOUD_PubChem_EntrezIDs[c]))\n",
    "    \n",
    "print 'PubChem:'\n",
    "print '\\tTotal amount of targets: %d' %len(targets_PubChem)\n",
    "print '\\tAmount of distinct targets: %d' %len(set(targets_PubChem))\n",
    "print '\\tMean targets: %.2f' %np.mean(counts_PubChem)\n",
    "print '\\tMedian targets: %.2f' %np.median(counts_PubChem)\n",
    "\n",
    "targets_ChEMBL = []\n",
    "counts_ChEMBL = []\n",
    "for c in all_CLOUDS:\n",
    "    targets_ChEMBL.extend(CLOUD_ChEMBL_EntrezIDs[c])\n",
    "    counts_ChEMBL.append(len(CLOUD_ChEMBL_EntrezIDs[c]))\n",
    "    \n",
    "print 'ChEMBL:'\n",
    "print '\\tTotal amount of targets: %d' %len(targets_ChEMBL)\n",
    "print '\\tAmount of distinct targets: %d' %len(set(targets_ChEMBL))\n",
    "print '\\tMean targets: %.2f' %np.mean(counts_ChEMBL)\n",
    "print '\\tMedian targets: %.2f' %np.median(counts_ChEMBL)\n",
    "\n",
    "\n",
    "targets_combined = []\n",
    "counts_combined = []\n",
    "for c in all_CLOUDS:\n",
    "    targets_combined.extend(CLOUD_Combined_EntrezIDs[c])\n",
    "    counts_combined.append(len(CLOUD_Combined_EntrezIDs[c]))\n",
    "    \n",
    "print '\\nCombined:'\n",
    "print '\\tTotal amount of targets: %d' %len(targets_combined)\n",
    "print '\\tAmount of distinct targets: %d' %len(set(targets_combined))\n",
    "print '\\tMean targets: %.2f' %np.mean(counts_combined)\n",
    "print '\\tMedian targets: %.2f' %np.median(counts_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read results files\n",
    "Read drug targets files e.g. for creating the Venn Diagram below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lists  containing the individual targets\n",
    "targets_DrugBank = []\n",
    "targets_ChEMBL = []\n",
    "targets_PubChem = []\n",
    "\n",
    "fp = open('../results/Drug_Target_Annotations/CLOUD_DrugBank_Targets.csv')\n",
    "fp.next()\n",
    "for line in fp:\n",
    "    tmp = line.strip().split(',')\n",
    "    targets_DrugBank.extend(tmp[2].split(';'))\n",
    "    \n",
    "fp = open('../results/Drug_Target_Annotations/CLOUD_ChEMBL_Targets.csv')\n",
    "fp.next()\n",
    "for line in fp:\n",
    "    tmp = line.strip().split(',')\n",
    "    targets_ChEMBL.extend(tmp[2].split(';'))\n",
    "    \n",
    "fp = open('../results/Drug_Target_Annotations/CLOUD_PubChem_Targets.csv')\n",
    "fp.next()\n",
    "for line in fp:\n",
    "    tmp = line.strip().split(',')\n",
    "    targets_PubChem.extend(tmp[2].split(';'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Venn Diagram to show the overlap between the data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a triple Venn Diagram\n",
    "venn3([set(targets_DrugBank), set(targets_ChEMBL),set(targets_PubChem)], set_labels = ('DrugBank', 'ChEMBL','PubChem'))\n",
    "#plt.show()\n",
    "plt.savefig('../results/Drug_Target_Annotations/Database_Overlap.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram of the number of drug targets per drug. (Not filtered! still containing Transporters/Enzymes e.g. CYP proteins)\n",
    "plt.hist(counts_combined,bins='auto',color='#D2323C')\n",
    "plt.axvline(np.mean(counts_combined), ls ='--', color = 'grey')\n",
    "plt.xlabel('Number of Targets')\n",
    "plt.ylabel('Number of Drugs')\n",
    "plt.savefig('../results/Drug_Target_Annotations/Amount_Targets')\n",
    "plt.close"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

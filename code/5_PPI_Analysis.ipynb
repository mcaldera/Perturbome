{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPI Analysis\n",
    "1.) Drug perturbations and PPI degree  \n",
    "2.) Drug perturbations and PPI centrality  \n",
    "3.) LCC size of drug perturbations  \n",
    "4.) Shortest paths of drug perturbations  \n",
    "5.) Calculate overlap between two drug modules  \n",
    "6.) Localization/Separation and GO term similarity  \n",
    "7.) Localization/Separation and Disease similarity  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all python libraries needed\n",
    "import networkx as nx\n",
    "from matplotlib import pylab as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import random as rand\n",
    "from scipy.stats import mannwhitneyu\n",
    "import gene2terms_addupstream as GO\n",
    "from scipy.stats import binned_statistic\n",
    "import random\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load PPI (see 1_Interactome_Construction_And_Analysis.ipynb)\n",
    "PPI = nx.read_gml('../data/PPI_Analysis/Human_Interactome.gml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all the CLOUD Targets\n",
    "cloud_targets = {}\n",
    "different_Targets = set()\n",
    "fp = open('../data/PPI_Analysis/CLOUD_to_TargetsSplit.csv','r')\n",
    "fp.next()\n",
    "for line in fp:\n",
    "    tmp = line.strip().split(',')\n",
    "    #cloud_targets[tmp[0]] = list(set(tmp[2].split(';')))\n",
    "    cloud_targets[tmp[0]] = list(set(tmp[1].split(';')))\n",
    "    for t in tmp[1].split(';'):\n",
    "        different_Targets.add(t)\n",
    "\n",
    "print 'Number of different targets: %d' %len(different_Targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Drug perturbations and PPI degree\n",
    "Check if targets of drugs rather tend to interact with high or lower degree nodes in the PPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the degree distribution of the whole PPI\n",
    "degrees_PPI = [x[1] for x in  nx.degree(PPI)]\n",
    "degrees_PPI_unique = list(set(degrees_PPI))\n",
    "degrees_PPI_unique.sort()\n",
    "degreesPPI = []\n",
    "degreeDistributionPPI = []\n",
    "cumulativedegreeDistributionPPI = []\n",
    "for degree in degrees_PPI_unique:\n",
    "    degreesPPI.append(degree)\n",
    "    degreeDistributionPPI.append(degrees_PPI.count(degree)/float(len(degrees_PPI)))\n",
    "    cumulativedegreeDistributionPPI.append(len([x for x in degrees_PPI if x >= degree]) / float(len(degrees_PPI)))\n",
    "\n",
    "\n",
    "#Extract the degree distribution of the subpart of the PPI containing targeted proteins\n",
    "degrees_Drugs = [x[1] for x in  PPI.degree(different_Targets)]\n",
    "degrees_Drugs_unique = list(set(degrees_Drugs))\n",
    "degrees_Drugs_unique.sort()\n",
    "degreesDrugs = []\n",
    "degreeDistributionDrugs = []\n",
    "cumulativedegreeDistributionDrugs = []\n",
    "for degree in degrees_Drugs_unique:\n",
    "    degreesDrugs.append(degree)\n",
    "    degreeDistributionDrugs.append(degrees_Drugs.count(degree)/float(len(degrees_Drugs)))\n",
    "    cumulativedegreeDistributionDrugs.append(len([x for x in degrees_Drugs if x >= degree]) / float(len(degrees_Drugs)))\n",
    "\n",
    "\n",
    "print 'Mean PPI degree: %.2f' %np.mean(degrees_PPI)\n",
    "print 'Mean Drug degree: %.2f' %np.mean(degrees_Drugs)\n",
    "\n",
    "#Plot the normal degree distribution (log/log)\n",
    "plt.scatter(degreesPPI, degreeDistributionPPI, c='grey', alpha=0.4)\n",
    "plt.scatter(degreesDrugs, degreeDistributionDrugs, c='#40B9D4', alpha=0.4)\n",
    "plt.legend(['PPI','CLOUD\\nKS_pValue: %.2e' %stats.ks_2samp(degrees_PPI, degrees_Drugs)[1]],frameon=False)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('P(k)')\n",
    "plt.ylim(10 ** -5, 1)\n",
    "plt.savefig('../results/PPI_Analysis/Degree/Scatter_DegreeDistribution_LogLog.pdf',format='pdf')\n",
    "#plt.show()\n",
    "plt.close()\n",
    "\n",
    "#Plot the cumulative degree distribution (log/log)\n",
    "plt.scatter(degreesPPI, cumulativedegreeDistributionPPI, c='grey', alpha=0.4)\n",
    "plt.scatter(degreesDrugs, cumulativedegreeDistributionDrugs, c='#40B9D4', alpha=0.4)\n",
    "plt.legend(['PPI','CLOUD\\nKS_pValue: %.2e' %stats.ks_2samp(degrees_PPI, degrees_Drugs)[1]],frameon=False)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('P(x >= k)')\n",
    "plt.ylim(10 ** -4, 1)\n",
    "plt.savefig('../results/PPI_Analysis/Degree/Scatter_CumulativeDegreeDistribution_LogLog.pdf',format='pdf')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "#Plot a histogram degree distribution (log/log)\n",
    "PPI_Bins = plt.hist(degrees_PPI, normed = True, bins = 'auto', alpha = 0.4, color='grey')\n",
    "Drug_Bins =plt.hist(degrees_Drugs, normed = True, bins = 'auto', alpha = 0.4, color='#40B9D4')\n",
    "plt.legend(['PPI','CLOUD\\nKS_pValue: %.2e' %stats.ks_2samp(degrees_PPI, degrees_Drugs)[1]],frameon=False)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('P(k)')\n",
    "plt.savefig('../results/PPI_Analysis/Degree/Histogram_LogLog.pdf',format='pdf')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "#Plot a noraml degree distribution (single log)\n",
    "plt.hist(degrees_PPI, normed = True, bins = 'auto', alpha = 0.4, color='grey')\n",
    "plt.hist(degrees_Drugs, normed = True, bins = 'auto', alpha = 0.4, color='#40B9D4')\n",
    "plt.legend(['PPI','CLOUD\\nKS_pValue: %.2e' %stats.ks_2samp(degrees_PPI, degrees_Drugs)[1]],frameon=False)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('P(k)')\n",
    "plt.savefig('../results/PPI_Analysis/Degree/Histogram_Log.pdf',format='pdf')\n",
    "plt.close()\n",
    "\n",
    "#Plot a noraml degree distribution line plot (log/log)\n",
    "plt.plot(degreesPPI,degreeDistributionPPI, c='grey')\n",
    "plt.plot(degreesDrugs,degreeDistributionDrugs, c='#40B9D4')\n",
    "plt.legend(['PPI','CLOUD\\nKS_pValue: %.2e' %stats.ks_2samp(degrees_PPI, degrees_Drugs)[1]],frameon=False)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('P(k)')\n",
    "plt.savefig('../results/PPI_Analysis/Degree/LinePlot_LogLog.pdf',format='pdf')\n",
    "plt.close()\n",
    "\n",
    "#Plot a noraml degree distribution line plot (single log)\n",
    "plt.plot(degreesPPI,degreeDistributionPPI, c='grey')\n",
    "plt.plot(degreesDrugs,degreeDistributionDrugs, c='#40B9D4')\n",
    "plt.legend(['PPI','CLOUD\\nKS_pValue: %.2e' %stats.ks_2samp(degrees_PPI, degrees_Drugs)[1]],frameon=False)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('P(k)')\n",
    "plt.savefig('../results/PPI_Analysis/Degree/LinePlot_Log.pdf',format='pdf')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Drug perturbations and PPI centrality\n",
    "Check if drug perturbations tend to interact with more central nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_Centrality(PPI, targets):\n",
    "    '''\n",
    "    Extract centralities for nodes on the PPI. Return list of centralities or None if no node is found on the PPI\n",
    "    '''\n",
    "    filtered_targets = []\n",
    "    for t in targets:\n",
    "        if PPI.has_node(t):\n",
    "            filtered_targets.append(t)\n",
    "\n",
    "    if len(filtered_targets) > 0:\n",
    "        centralities = []\n",
    "        for node in filtered_targets:\n",
    "            centralities.append(nx.closeness_centrality(PPI, node))\n",
    "\n",
    "        return centralities\n",
    "\n",
    "    else:\n",
    "        return  None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateCLOUD_Centralities():\n",
    "    '''\n",
    "    Check the centralities of normal PPI nodes and nodes targeted by the CLOUD perturbers\n",
    "    '''\n",
    "\n",
    "    #Load PPI\n",
    "    PPI = nx.read_gml('../data/PPI_Analysis/Human_Interactome.gml')\n",
    "\n",
    "    #Get all the CLOUD Targets\n",
    "    cloud_targets = {}\n",
    "    different_Targets = set()\n",
    "    fp = open('../data/PPI_Analysis/CLOUD_All_Targets.csv','r')\n",
    "    fp.next()\n",
    "    for line in fp:\n",
    "        tmp = line.strip().split(',')\n",
    "        cloud_targets[tmp[0]] = list(set(tmp[2].split(';')))\n",
    "        for t in tmp[2].split(';'):\n",
    "            different_Targets.add(t)\n",
    "    print 'Number of different targets: %d' %len(different_Targets)\n",
    "\n",
    "    #create a random distribution of centralities on the PPI \n",
    "    NumRandom = 10000\n",
    "    print 'Create Random Distribution'\n",
    "    random_distances = []\n",
    "    for i in range(0, NumRandom):\n",
    "        node = rand.sample(PPI.nodes(), 1)[0]\n",
    "        random_distances.append(nx.closeness_centrality(PPI,node))\n",
    "\n",
    "\n",
    "    #calculate the centralities of the targets for an individual drug\n",
    "    cloud_centrality_results = {}\n",
    "    for c in cloud_targets.keys():\n",
    "        print c\n",
    "        if len(cloud_targets[c]) == 0:\n",
    "            continue\n",
    "            \n",
    "        #get the centralities for all targets for a specific CLOUD drug\n",
    "        drug_centralities = calculate_Centrality(PPI, cloud_targets[c])\n",
    "\n",
    "        #claculate the PValue,MeanCentrality and Glass' Delta if targets found on the PPI\n",
    "        if drug_centralities != None:\n",
    "            pValue = mannwhitneyu(drug_centralities, random_distances)[1]\n",
    "            # FoldChange = d_d / np.mean(random_distances)\n",
    "            GlassDelta = (np.mean(drug_centralities) - np.mean(random_distances)) / np.std(random_distances)\n",
    "\n",
    "            cloud_centrality_results[c] = {'MeanCentrality': np.mean(drug_centralities), 'PValue': pValue,\n",
    "                                           'FoldChange': GlassDelta}\n",
    "\n",
    "    #Save the results\n",
    "    fp_out = open('../results/PPI_Analysis/Centralities/Centralities.csv','w')\n",
    "    fp_out.write('CLOUD,MeanCentrality,PValue,FoldChange\\n')\n",
    "    clouds = cloud_centrality_results.keys()\n",
    "    clouds.sort()\n",
    "\n",
    "    for c in clouds:\n",
    "        fp_out.write(c+','+str(cloud_centrality_results[c]['MeanCentrality'])+','+str(cloud_centrality_results[c]['PValue'])+','+str(cloud_centrality_results[c]['FoldChange'])+'\\n')\n",
    "    fp_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CalculateCLOUD_Centralities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_Centralities():\n",
    "    '''\n",
    "    Function to plot the resulting Glass' Deltas of centralities\n",
    "    '''\n",
    "\n",
    "    #Get the calculated centrality results\n",
    "    fp = open('../results/PPI_Analysis/Centralities/Centralities.csv')\n",
    "    fp.next()\n",
    "\n",
    "    \n",
    "    #parse through results\n",
    "    pValues = []\n",
    "    FoldChange =  []\n",
    "    for line in fp:\n",
    "        tmp = line.strip().split(',')\n",
    "\n",
    "        pValues.append(float(tmp[2]))\n",
    "        FoldChange.append(float(tmp[3]))\n",
    "\n",
    "\n",
    "    #Plot foldchange (=Glass' Delta) and PValues\n",
    "    plt.scatter(FoldChange,pValues,c='#40B9D4', alpha=0.6)\n",
    "    plt.xlim([min(FoldChange), max((FoldChange))])\n",
    "    plt.ylim([min(pValues), max((pValues))])\n",
    "    plt.yscale('log')\n",
    "    plt.legend(['Total/Significant:  %d/%d (%.2f)' % (len(pValues), len([x for x in pValues if x < 0.05]),len([x for x in pValues if x < 0.05]) / float(len(pValues)))],\n",
    "               frameon=False)\n",
    "    plt.fill([min(FoldChange), max(FoldChange), max(FoldChange), min(FoldChange)], [1, 1, 0.05, 0.05], c='grey', alpha=0.3)\n",
    "    plt.xlabel(\"Glass' Delta\")\n",
    "    plt.ylabel('PValue')\n",
    "    #plt.show()\n",
    "    plt.savefig('../results/PPI_Analysis/Centralities/Centrality_Scatter.pdf', format='pdf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot_Centralities()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LCC and CLOUDS\n",
    "Check if the LCC size of CLOUD drugs is somehow larger or smaller than what you expect from random. Calculate 10k random sample of same size to compare with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Check_LCC_Size(PPI, targets):\n",
    "    '''\n",
    "    Check the LCC size of given targets on the PPI\n",
    "\n",
    "    '''\n",
    "    LCC = 1\n",
    "\n",
    "    SubGraph = nx.subgraph(PPI, targets)\n",
    "    if len(SubGraph.nodes) > 0:\n",
    "        components = nx.connected_component_subgraphs(SubGraph)\n",
    "        LCC = max([len(x.nodes()) for x in components])\n",
    "\n",
    "    return LCC\n",
    "\n",
    "\n",
    "def create_LCC_Results():\n",
    "    \n",
    "    #Load PPI\n",
    "    PPI = nx.read_gml('../data/PPI_Analysis/Human_Interactome.gml')\n",
    "\n",
    "    #Get all the CLOUD Targets\n",
    "    cloud_targets = {}\n",
    "    different_Targets = set()\n",
    "    fp = open('../data/PPI_Analysis/CLOUD_All_Targets.csv','r')\n",
    "    fp.next()\n",
    "    for line in fp:\n",
    "        tmp = line.strip().split(',')\n",
    "        cloud_targets[tmp[0]] = list(set(tmp[2].split(';')))\n",
    "        for t in tmp[2].split(';'):\n",
    "            different_Targets.add(t)\n",
    "\n",
    "    #Calculate LCC sizes and compare to randomly drawn LCC on the PPI of same size as the number of targets of the specific drug\n",
    "    cloud_LCCs_results = {}\n",
    "    for c in cloud_targets.keys():\n",
    "        print c\n",
    "        \n",
    "        #Get specific drug LCC\n",
    "        if len(cloud_targets[c]) == 0:\n",
    "            continue\n",
    "        lcc = Check_LCC_Size(PPI, cloud_targets[c])\n",
    "        number_of_Genes = len(cloud_targets[c])\n",
    "        relative_LCC_Size = float(lcc) / number_of_Genes\n",
    "        \n",
    "        #Create random distribution of LCCs \n",
    "        random_distribution = []\n",
    "        for i in range(0, 10000):\n",
    "            randGenes = rand.sample(PPI.nodes(), len(cloud_targets[c]))\n",
    "            rand_LCC = Check_LCC_Size(PPI, randGenes)\n",
    "            random_distribution.append(rand_LCC)\n",
    "\n",
    "        #Calculate ZScore\n",
    "        ZScore = (lcc - np.mean(random_distribution)) / np.std(random_distribution)\n",
    "        \n",
    "        cloud_LCCs_results[c] = {'lcc': lcc, 'ZScore': ZScore, '#Genes': number_of_Genes, 'RelativeSize': relative_LCC_Size}\n",
    "\n",
    "        \n",
    "    #Save Output\n",
    "    fp_out = open('../results/PPI_Analysis/LCC/LCC_Sizes.csv','w')\n",
    "    fp_out.write('CLOUD,LCC,ZScore,#Genes,RelativeSize\\n')\n",
    "    clouds = cloud_LCCs_results.keys()\n",
    "    clouds.sort()\n",
    "\n",
    "    for c in clouds:\n",
    "        fp_out.write(c+','+str(cloud_LCCs_results[c]['lcc'])+','+str(cloud_LCCs_results[c]['ZScore'])+','+str(cloud_LCCs_results[c]['#Genes'])+','+str(cloud_LCCs_results[c]['RelativeSize'])+'\\n')\n",
    "    fp_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_LCC_Results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_LCC_Results():\n",
    "    '''\n",
    "    Use the LCC output file and create a plot\n",
    "    \n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    fp = open('../results/PPI_Analysis/LCC/LCC_Sizes.csv')\n",
    "    fp.next()\n",
    "\n",
    "    zscores =[]\n",
    "    rel_sizes = []\n",
    "    for line in fp:\n",
    "        tmp = line.strip().split(',')\n",
    "        if tmp[2] != 'nan' and int(tmp[3]) > 1:\n",
    "\n",
    "            zscores.append(float(tmp[2]))\n",
    "            rel_sizes.append(float(tmp[4]))\n",
    "     \n",
    "    \n",
    "    print 'Total: %d' %len(zscores)\n",
    "    print 'Significant: %d' %len([x for x in zscores if abs(x) > 2])\n",
    "    print len([x for x in zscores if abs(x) > 2])/float(len(zscores))\n",
    "\n",
    "    #Plot relative size (e.g. percent of targets within LCC and the ZScore)\n",
    "    plt.scatter(rel_sizes,zscores, alpha=0.6, c='#40B9D4')\n",
    "    plt.legend(['Total/Significant:  %d/%d (%.2f)' %(len(zscores),len([x for x in zscores if abs(x) > 2]),len([x for x in zscores if abs(x) > 2])/float(len(zscores)))],frameon=False)\n",
    "    plt.fill([0, 0, 1, 1], [-2, 2, 2, -2], color='grey', alpha=0.4)\n",
    "    plt.xlabel('relative module size s=Nd /S')\n",
    "    plt.ylabel('z-score of module size S')\n",
    "    plt.xlim([min(rel_sizes),max((rel_sizes))])\n",
    "    plt.ylim([min(zscores), max((zscores))])\n",
    "    plt.savefig('../results/PPI_Analysis/LCC/LCC.pdf', format='pdf')\n",
    "    #plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot_LCC_Results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Shortest Path\n",
    "Check if the shortest path between the targets of a CLOUD drug is shorter and larger than what you expect from random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Check_Shortest_Distances(PPI, targets):\n",
    "    '''\n",
    "    Extract the min path between targets.\n",
    "    This is always the minimum path between one target and any other target of the other set.\n",
    "    Returns Mean of all paths (d_d) as well as paths (min_paths)\n",
    "    \n",
    "    This function uses only one set hence calulcates the intra drug distance or drug_module diamter\n",
    "    '''\n",
    "    filtered_targets = []\n",
    "    for t in targets:\n",
    "        if PPI.has_node(t):\n",
    "            filtered_targets.append(t)\n",
    "\n",
    "    min_paths = []\n",
    "    if len(filtered_targets) > 1:\n",
    "        try:\n",
    "            for t1 in filtered_targets:\n",
    "                min_distances = []\n",
    "                for t2 in filtered_targets:\n",
    "                    if t1 != t2:\n",
    "\n",
    "                        if nx.has_path(PPI, t1, t2):\n",
    "                            min_distances.append(len(nx.shortest_path(PPI, t1, t2)) - 1)\n",
    "                min_paths.append(min(min_distances))\n",
    "            d_d = sum(min_paths) / float(len(filtered_targets))\n",
    "\n",
    "            return d_d, min_paths\n",
    "        except:\n",
    "            return None, None\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def Create_Shortest_Distances_Output():\n",
    "    '''\n",
    "    Fucntion to calculate the intra_drug module distance e.g. shortest distances of any target of a given drug to any other target of this drug (mean over all)\n",
    "    \n",
    "    '''\n",
    "\n",
    "    #Load PPI\n",
    "    PPI = nx.read_gml('../data/PPI_Analysis/Human_Interactome.gml')\n",
    "\n",
    "    #Get all the CLOUD Targets\n",
    "    cloud_targets = {}\n",
    "    different_Targets = set()\n",
    "    fp = open('../data/PPI_Analysis/CLOUD_All_Targets.csv','r')\n",
    "    fp.next()\n",
    "    for line in fp:\n",
    "        tmp = line.strip().split(',')\n",
    "        cloud_targets[tmp[0]] = list(set(tmp[2].split(';')))\n",
    "        for t in tmp[2].split(';'):\n",
    "            different_Targets.add(t)\n",
    "\n",
    "    #Create random distribution for randomly drawn proteins on the PPI\n",
    "    NumRandom = 10000\n",
    "    print 'Create Random Distribution'\n",
    "    random_distances = []\n",
    "    for i in range(0, NumRandom):\n",
    "        targets = rand.sample(PPI.nodes(), 2)\n",
    "        if nx.has_path(PPI, targets[0], targets[1]):\n",
    "            random_distances.append(len(nx.shortest_path(PPI, targets[0], targets[1])) - 1)\n",
    "\n",
    "    \n",
    "    #Calculate the drug module PPI diameter\n",
    "    cloud_ShortestPaths_results = {}\n",
    "    for c in cloud_targets.keys():\n",
    "        print c\n",
    "        if len(cloud_targets[c]) == 0:\n",
    "            continue\n",
    "\n",
    "        #Extract min distances\n",
    "        d_d, min_paths = Check_Shortest_Distances(PPI, cloud_targets[c])\n",
    "\n",
    "        if d_d == None:\n",
    "            continue\n",
    "\n",
    "        #Calculate pValue by comparing with random Distribution\n",
    "        pValue = mannwhitneyu(min_paths, random_distances)[1]\n",
    "\n",
    "        #Calculate fold change (Glass' Delata)\n",
    "        GlassDelta = (d_d - np.mean(random_distances))/np.std(random_distances)\n",
    "\n",
    "        #Save Result\n",
    "        cloud_ShortestPaths_results[c] = {'MeanShortestPath':d_d,'PValue':pValue,'FoldChange':GlassDelta}\n",
    "\n",
    "\n",
    "    #Save result to output\n",
    "    fp_out = open('../results/PPI_Analysis/ShortestPath/ShortestPaths.csv','w')\n",
    "    fp_out.write('CLOUD,MeanShortestPath,PValue,FoldChange\\n')\n",
    "    clouds = cloud_ShortestPaths_results.keys()\n",
    "    clouds.sort()\n",
    "\n",
    "    for c in clouds:\n",
    "        fp_out.write(c+','+str(cloud_ShortestPaths_results[c]['MeanShortestPath'])+','+str(cloud_ShortestPaths_results[c]['PValue'])+','+str(cloud_ShortestPaths_results[c]['FoldChange'])+'\\n')\n",
    "    fp_out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_SPath_Results():\n",
    "    '''\n",
    "    Use the drug module diameter output file and create a plot\n",
    "\n",
    "    :return:\n",
    "    '''\n",
    "    \n",
    "    #Load the drug module diamter results\n",
    "    fp = open('../results/PPI_Analysis/ShortestPath/ShortestPaths.csv')\n",
    "    fp.next()\n",
    "\n",
    "    pValue =[]\n",
    "    GlassDelta = []\n",
    "    for line in fp:\n",
    "        tmp = line.strip().split(',')\n",
    "        pValue.append(float(tmp[2]))\n",
    "        GlassDelta.append(float(tmp[3]))\n",
    "\n",
    "\n",
    "\n",
    "    print 'Total: %d' % len(pValue)\n",
    "    print 'Significant: %d' % len([x for x in pValue if x < 0.05])\n",
    "    print len([x for x in pValue if x < 0.05]) / float(len(pValue))\n",
    "\n",
    "    #Plot output again with foldchange (glass delta) and Significance (pValue) \n",
    "    plt.scatter(GlassDelta, pValue, alpha=0.6,c='#40B9D4')\n",
    "    plt.legend(['Total/Significant:  %d/%d  (%.2f)' % (len(pValue), len([x for x in pValue if abs(x) < 0.05]),\n",
    "                                                              len([x for x in pValue if abs(x) < 0.05]) / float(\n",
    "                                                              len(pValue)))], frameon=False)\n",
    "    plt.ylim(min(pValue), 1)\n",
    "    plt.xlim([min(GlassDelta),max(GlassDelta)])\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel(\"Glass' Delta\")\n",
    "    plt.ylabel('PValue')\n",
    "    #plt.show()\n",
    "    plt.savefig('../results/PPI_Analysis/ShortestPath/ShortestDistance.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot_SPath_Results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculate Overlap Between two Drugs\n",
    "Calculate S_AB scores for all pairwise drug modules. Negative values indicate that two modules are overlapping while positive indicate they are separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Check_Shortest_Distances(PPI,targets):\n",
    "    '''\n",
    "    Extract the min path between targets.\n",
    "    This is always the minimum path between one target and any other target of the other set.\n",
    "    Returns Mean of all paths (d_d) as well as paths (min_paths)\n",
    "    \n",
    "    This function uses only one set hence calulcates the intra drug distance or drug_module diamter\n",
    "    \n",
    "    '''\n",
    "    filtered_targets = []\n",
    "    for t in targets:\n",
    "        if PPI.has_node(t):\n",
    "            filtered_targets.append(t)\n",
    "\n",
    "    min_paths = []\n",
    "    if len(filtered_targets) > 1:\n",
    "        try:\n",
    "            for t1 in filtered_targets:\n",
    "                min_distances = []\n",
    "                for t2 in filtered_targets:\n",
    "                    if t1 != t2:\n",
    "                        if nx.has_path(PPI,t1,t2):\n",
    "                            min_distances.append(len(nx.shortest_path(PPI,t1,t2))-1)\n",
    "                min_paths.append(min(min_distances))\n",
    "            d_d = sum(min_paths)/float(len(filtered_targets))\n",
    "\n",
    "            return d_d,min_paths\n",
    "        except:\n",
    "            return None,None\n",
    "    else:\n",
    "        return None,None\n",
    "\n",
    "def Check_Shortest_DistancesBetween(PPI, targets1, targets2):\n",
    "    '''\n",
    "    Extract the min path between targets.\n",
    "    This is always the minimum path between one target and any other target of the other set.\n",
    "    Returns Mean of all paths (d_d) as well as paths (min_paths)\n",
    "    \n",
    "    This function uses two sets hence calulcates the inter drug distance\n",
    "    \n",
    "    '''\n",
    "    filtered_targets = []\n",
    "    for t in targets1:\n",
    "        if PPI.has_node(t):\n",
    "            filtered_targets.append(t)\n",
    "\n",
    "    filtered_targets2 = []\n",
    "    for t in targets2:\n",
    "        if PPI.has_node(t):\n",
    "            filtered_targets2.append(t)\n",
    "\n",
    "    min_paths = []\n",
    "    if len(filtered_targets) >= 1 and len(filtered_targets2) >= 1:\n",
    "        try:\n",
    "            for t1 in filtered_targets:\n",
    "                min_distances = []\n",
    "                for t2 in filtered_targets2:\n",
    "                    if nx.has_path(PPI, t1, t2):\n",
    "                        min_distances.append(len(nx.shortest_path(PPI, t1, t2)) - 1)\n",
    "                min_paths.append(min(min_distances))\n",
    "            return min_paths\n",
    "        except:\n",
    "            return None, None\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load PPI\n",
    "PPI = nx.read_gml('../data/PPI_Analysis/Human_Interactome.gml')\n",
    "\n",
    "#Get all the CLOUD Targets\n",
    "cloud_targets = {}\n",
    "different_Targets = set()\n",
    "\n",
    "#Calculate Sab based on only Targets (remove transporters and enzymes)\n",
    "fp = open('../data/PPI_Analysis/CLOUD_to_TargetsSplit.csv','r')\n",
    "fp.next()\n",
    "for line in fp:\n",
    "    tmp = line.strip().split(',')\n",
    "    cloud_targets[tmp[0]] = list(set(tmp[1].split(';')))\n",
    "    for t in tmp[1].split(';'):\n",
    "        different_Targets.add(t)\n",
    "\n",
    "#Calcualte within distances\n",
    "within_Distances = {}\n",
    "for c in cloud_targets:\n",
    "    #print c\n",
    "    if len(cloud_targets[c]) == 0:\n",
    "        continue\n",
    "\n",
    "    d_d, min_paths = Check_Shortest_Distances(PPI, cloud_targets[c])\n",
    "\n",
    "    if d_d == None:\n",
    "        continue\n",
    "    else:\n",
    "        within_Distances[c] = d_d\n",
    "\n",
    "clouds = within_Distances.keys()\n",
    "clouds.sort()\n",
    "\n",
    "#Calculate separation between two drugs Sab\n",
    "fp_out = open('../results/PPI_Analysis/Separation/Separation_TargetsOnly.csv','w')\n",
    "fp_out.write('Drug1,Drug2,D_Drug1,D_Drug2,D_D1_D2,S\\n')\n",
    "for c in clouds:\n",
    "    print c\n",
    "    d_A = within_Distances[c]\n",
    "    targets1 = cloud_targets[c]\n",
    "\n",
    "    for c2 in clouds:\n",
    "        #if c > c2:\n",
    "        d_B = within_Distances[c2]\n",
    "        targets2 = cloud_targets[c2]\n",
    "        distances1 = Check_Shortest_DistancesBetween(PPI, targets1, targets2)\n",
    "        distances2 = Check_Shortest_DistancesBetween(PPI, targets2, targets1)\n",
    "        \n",
    "        #Dab\n",
    "        between_Distance = (sum(distances1)+sum(distances2))/float((len(distances1)+len(distances2)))\n",
    "\n",
    "        #Sab\n",
    "        separation = between_Distance - (d_A+d_B)/2.0\n",
    "\n",
    "        fp_out.write(c+','+c2+','+str(d_A)+','+str(d_B)+','+str(between_Distance)+','+str(separation)+'\\n')\n",
    "fp_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Localization/Separation and GO term similarity\n",
    "Check if the localization of drugs e.g. how close they are in matter of (i) LCC and (ii) shortest path as well as (iii) seperation, influences how similar two drugs are in matter of their associated GO terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calculate_Similarity_MaxSpecificity(targets1, targets2, GO_genes_annotation, GO_Association_UP,isSeparation = False):\n",
    "    '''\n",
    "    Calculates similarity between two sets derived from an ontology based on the most specific term e.g. term with least annotations.\n",
    "    Hence maximum similarity exits of two drugs are associated to exactly one GO term that exactly is associated only to these two proteins\n",
    "    \n",
    "    '''\n",
    "    sims = []\n",
    "    for t1 in targets1:\n",
    "        for t2 in targets2:\n",
    "            if t1 > t2 or isSeparation:\n",
    "                if len([len(GO_genes_annotation[x]) for x in set(GO_Association_UP[t1]).intersection(GO_Association_UP[t2])]) == 0:\n",
    "                    SimDis = 0\n",
    "                else:\n",
    "                    SimDis = 2.0 / min([len(GO_genes_annotation[x]) for x in set(GO_Association_UP[t1]).intersection(GO_Association_UP[t2])])\n",
    "                sims.append(SimDis)\n",
    "    if len(sims) > 0:\n",
    "        return np.mean(sims)\n",
    "    else:\n",
    "        return  0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GO_Self_ShortestPath():\n",
    "    '''\n",
    "    Check how the drug diameter (module size) correlates with GO-term similarity\n",
    "    '''\n",
    "\n",
    "    similarity_Type = 'MaxSpecificity'\n",
    "\n",
    "    #Go through all three branches\n",
    "    for go_branch in ['Component','Function','Process']:\n",
    "\n",
    "        print go_branch\n",
    "\n",
    "        # Get all the CLOUD Targets\n",
    "        cloud_targets = {}\n",
    "        fp = open('../data/PPI_Analysis/CLOUD_All_Targets.csv','r')\n",
    "        fp.next()\n",
    "        for line in fp:\n",
    "            tmp = line.strip().split(',')\n",
    "            cloud_targets[tmp[0]] = list(set(tmp[2].split(';')))\n",
    "\n",
    "        #Get the drug module diamters\n",
    "        fp = open('../results/PPI_Analysis/ShortestPath/ShortestPaths.csv','r')\n",
    "        fp.next()\n",
    "        drug_ShortestPath = []\n",
    "        drugs = []\n",
    "        for line in fp:\n",
    "            tmp = line.strip().split(',')\n",
    "            drugs.append(tmp[0])\n",
    "            drug_ShortestPath.append(float(tmp[3]))\n",
    "\n",
    "        #Bin the diameter sizes\n",
    "        bin_means = binned_statistic(drug_ShortestPath, drug_ShortestPath,bins=[-3.2, -2.5, -2, -1.5, -1, -0.5, 0, 0.5, 1.6])\n",
    "        \n",
    "        #create a similarity dictionary\n",
    "        similarties = {}\n",
    "        for i in range(1,max(bin_means[2])+1):\n",
    "            similarties[i] = []\n",
    "\n",
    "        #Load the GO-Upstream branches\n",
    "        print 'Load GO Associations:'\n",
    "        GO_Association_UP,GO_genes_annotation = GO.getAllGene_Annotation(go_branch)\n",
    "        print 'Done'\n",
    "\n",
    "        #Calculate the similarity scores for all the drugs and add them to the specific bins\n",
    "        for d,bin in zip(drugs,bin_means[2]):\n",
    "            targets = cloud_targets[d]\n",
    "            if len(targets) > 1:\n",
    "                if similarity_Type == 'MaxSpecificity':\n",
    "                    sims = Calculate_Similarity_MaxSpecificity(targets, targets, GO_genes_annotation,\n",
    "                                                               GO_Association_UP)\n",
    "\n",
    "                similarties[bin].append(np.mean(sims))\n",
    "\n",
    "        #Plot the results as Barplot\n",
    "        plt.bar(range(1,max(bin_means[2])+1), [np.mean(similarties[x]) for x in range(1,max(bin_means[2])+1)], yerr=[1.96 * (np.std(similarties[x]) / float(len(similarties[x]))) for x in range(1,max(bin_means[2])+1)], align='center', alpha=0.5, ecolor='black', capsize=10, color='#40B9D4', zorder=2)\n",
    "        plt.xticks(range(1,max(bin_means[2])+1),['{:2.2f}'.format(x) for x in bin_means[1]])\n",
    "        plt.xlabel(\"Glass' Delta\")\n",
    "        plt.ylabel(\"GO Similarity (%s)\\n%s Similarity (95%% CI)\" %(go_branch,similarity_Type))\n",
    "        #plt.show()\n",
    "        plt.savefig('../results/PPI_Analysis/GO_Enrichment/Drugs_Self_ShortestPath/'+go_branch+'_%s_BarPlot.pdf' %similarity_Type,format='pdf')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GO_Self_ShortestPath()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GO_Self_LCC():\n",
    "    '''\n",
    "    Check how the drug LCC size correlates with GO-term similarity\n",
    "    '''\n",
    "\n",
    "    similarity_Type = 'MaxSpecificity'\n",
    "    \n",
    "    #Go through all three branches\n",
    "    for go_branch in ['Component','Function','Process']:\n",
    "\n",
    "        print go_branch\n",
    "\n",
    "        # Get all the CLOUD Targets\n",
    "        cloud_targets = {}\n",
    "        fp = open('../data/PPI_Analysis/CLOUD_All_Targets.csv','r')\n",
    "        fp.next()\n",
    "        for line in fp:\n",
    "            tmp = line.strip().split(',')\n",
    "            cloud_targets[tmp[0]] = list(set(tmp[2].split(';')))\n",
    "\n",
    "        # Read the per drug LCC sizes\n",
    "        fp = open('../results/PPI_Analysis/LCC/LCC_Sizes.csv','r')\n",
    "        fp.next()\n",
    "        drug_ShortestPath = []\n",
    "        drugs = []\n",
    "        for line in fp:\n",
    "            tmp = line.strip().split(',')\n",
    "            if tmp[2] != 'nan':\n",
    "                drugs.append(tmp[0])\n",
    "                drug_ShortestPath.append(float(tmp[2]))\n",
    "\n",
    "        #Bin the LCC sizes\n",
    "        bin_means = binned_statistic(drug_ShortestPath, drug_ShortestPath,bins=[min(drug_ShortestPath), 4, 8, 12, 16, max(drug_ShortestPath)])\n",
    "        \n",
    "        #Create a similarity dictionary\n",
    "        similarties = {}\n",
    "        for i in range(1, max(bin_means[2]) + 1):\n",
    "            similarties[i] = []\n",
    "\n",
    "        #Extract GO-upstream ontologies\n",
    "        print 'Load GO Associations:'\n",
    "        GO_Association_UP, GO_genes_annotation = GO.getAllGene_Annotation(go_branch)\n",
    "        print 'Done'\n",
    "\n",
    "        #Calcualte the similarities and add results to the specific bins\n",
    "        for d,bin in zip(drugs,bin_means[2]):\n",
    "            targets = cloud_targets[d]\n",
    "            if len(targets) > 1:\n",
    "                if similarity_Type == 'MaxSpecificity':\n",
    "                    sims = Calculate_Similarity_MaxSpecificity(targets, targets, GO_genes_annotation,\n",
    "                                                               GO_Association_UP)\n",
    "                similarties[bin].append(np.mean(sims))\n",
    "\n",
    "        \n",
    "        #Plot a barplot\n",
    "        plt.bar(range(1, max(bin_means[2]) + 1), [np.mean(similarties[x]) for x in range(1, max(bin_means[2]) + 1)],\n",
    "                yerr=[1.96 * (np.std(similarties[x]) / float(len(similarties[x]))) for x in\n",
    "                      range(1, max(bin_means[2]) + 1)], align='center', alpha=0.5, ecolor='black', capsize=10,color='#40B9D4',zorder=2)\n",
    "\n",
    "        plt.xticks(range(1, max(bin_means[2]) + 1),['{:2.2f}'.format(x) for x in bin_means[1]])\n",
    "        plt.xlabel(\"ZScore\")\n",
    "        plt.ylabel(\"GO Similarity (%s)\\n%s Similarity\" %(go_branch,similarity_Type))\n",
    "        #plt.show()\n",
    "        plt.savefig('../results/PPI_Analysis/GO_Enrichment/Drugs_Self_LCC/'+go_branch+'_%s_BarPlot.pdf' %similarity_Type,format='pdf')\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GO_Self_LCC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GO_Separation():\n",
    "    '''\n",
    "    Check how the drug Sab (drug module overlap) correlates with GO-term similarity\n",
    "    '''\n",
    "\n",
    "    similarity_Type = 'MaxSpecificity'\n",
    "    \n",
    "    #Go through all branches\n",
    "    for go_branch in ['Component','Function','Process']:\n",
    "\n",
    "        print go_branch\n",
    "\n",
    "        # Get all the CLOUD Targets\n",
    "        cloud_targets = {}\n",
    "        all_Drugs = []\n",
    "        fp = open('../data/PPI_Analysis/CLOUD_All_Targets.csv','r')\n",
    "        fp.next()\n",
    "        for line in fp:\n",
    "            tmp = line.strip().split(',')\n",
    "            cloud_targets[tmp[0]] = list(set(tmp[2].split(';')))\n",
    "            all_Drugs.append(tmp[0])\n",
    "        \n",
    "        #Load separation results\n",
    "        fp = open('../results/PPI_Analysis/Separation/Separation_half.csv', 'r')\n",
    "        fp.next()\n",
    "        drug_ShortestPath = []\n",
    "        drugs = []\n",
    "        for line in fp:\n",
    "            tmp = line.strip().split(',')\n",
    "            if tmp[2] != 'nan':\n",
    "                drugs.append(tmp[0]+','+tmp[1])\n",
    "                drug_ShortestPath.append(float(tmp[5]))\n",
    "\n",
    "        #Bin the separation sizes\n",
    "        bin_means = binned_statistic(drug_ShortestPath, drug_ShortestPath,bins=[min(drug_ShortestPath), -1.5, -1, -0.5, 0, 0.5, 1, 1.5, max(drug_ShortestPath)])\n",
    "\n",
    "        #Create a similarity dictionary    \n",
    "        similarties = {}\n",
    "        for i in range(1, max(bin_means[2]) + 1):\n",
    "            similarties[i] = []\n",
    "\n",
    "        #Load GO association (plus upstream for all genes)\n",
    "        print 'Load GO Associations:'\n",
    "        GO_Association_UP, GO_genes_annotation = GO.getAllGene_Annotation(go_branch)\n",
    "        print 'Done'\n",
    "\n",
    "        #Create a random distribution (10k)\n",
    "        random_distribution = []\n",
    "        for i in range(1,10000):\n",
    "            randDrugs = random.sample(all_Drugs,2)\n",
    "            targets1 = cloud_targets[randDrugs[0]]\n",
    "            targets2 = cloud_targets[randDrugs[1]]\n",
    "\n",
    "\n",
    "            if len(targets1) > 0 and len(targets2) > 0:\n",
    "                if similarity_Type == 'MaxSpecificity':\n",
    "                    sim = Calculate_Similarity_MaxSpecificity(targets1, targets2, GO_genes_annotation,GO_Association_UP, isSeparation=True)\n",
    "                random_distribution.append(sim)\n",
    "\n",
    "        print 'Finished Random'\n",
    "        #Calculate the similarity between two drugs an add it to the correspdoning bin\n",
    "        for d, bin in zip(drugs, bin_means[2]):\n",
    "            drugs = d.split(',')\n",
    "\n",
    "            targets1 = cloud_targets[drugs[0]]\n",
    "            targets2 = cloud_targets[drugs[1]]\n",
    "            if len(targets1) > 0 and len(targets2) > 0:\n",
    "                if similarity_Type == 'MaxSpecificity':\n",
    "                    sim = Calculate_Similarity_MaxSpecificity(targets1, targets2, GO_genes_annotation,GO_Association_UP, isSeparation=True)\n",
    "                similarties[bin].append(sim)\n",
    "\n",
    "    \n",
    "        #Plot as barplot\n",
    "        plt.bar(range(1, max(bin_means[2]) + 1), [np.mean(similarties[x]) for x in range(1, max(bin_means[2]) + 1)],\n",
    "                yerr=[1.96 * (np.std(similarties[x]) / float(len(similarties[x]))) for x in\n",
    "                      range(1, max(bin_means[2]) + 1)], align='center', alpha=0.5, ecolor='black', capsize=10, color='#40B9D4', zorder=2)\n",
    "\n",
    "        plt.xticks(range(1, max(bin_means[2]) + 1),['{:2.2f}'.format(x) for x in bin_means[1]])\n",
    "        plt.xlabel(\"Separation Sab\")\n",
    "        plt.ylabel(\"GO Similarity (%s)\\n%s Similarity\" %(go_branch,similarity_Type))\n",
    "        plt.axhline(np.mean(random_distribution), c='grey', ls='--')\n",
    "        #plt.show()\n",
    "        plt.savefig('../results/PPI_Analysis/GO_Enrichment/Drugs_Separation/'+go_branch+'_%s_BarPlot.pdf' %similarity_Type,format='pdf')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GO_Separation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Localization/Separation and Disease similarity\n",
    "Check if the localization of drugs e.g. how close they are in matter of (i) LCC and (ii) shortest path as well as (iii) seperation, influences how similar two drugs are in matter of their associated Disease terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Disease_Self_ShortestPath():\n",
    "    '''\n",
    "    Check how the intra drug distance (drug module diamters) correlates with Disease term similarity\n",
    "    '''\n",
    "\n",
    "    similarity_Type = 'MaxSpecificity'\n",
    "\n",
    "    # Get all the CLOUD Targets\n",
    "    cloud_targets = {}\n",
    "    fp = open('../data/PPI_Analysis/CLOUD_All_Targets.csv','r')\n",
    "    fp.next()\n",
    "    for line in fp:\n",
    "        tmp = line.strip().split(',')\n",
    "        cloud_targets[tmp[0]] = list(set(tmp[2].split(';')))\n",
    "\n",
    "    #Get drug module diamters\n",
    "    fp = open('../results/PPI_Analysis/ShortestPath/ShortestPaths.csv','r')\n",
    "    fp.next()\n",
    "    drug_ShortestPath = []\n",
    "    drugs = []\n",
    "    for line in fp:\n",
    "        tmp = line.strip().split(',')\n",
    "        drugs.append(tmp[0])\n",
    "        drug_ShortestPath.append(float(tmp[3]))\n",
    "\n",
    "    #Bin the drug module diamter sizes\n",
    "    bin_means = binned_statistic(drug_ShortestPath, drug_ShortestPath, bins=[-3.2,-2.5,-2,-1.5,-1,1.6])\n",
    "   \n",
    "    #create similarity file\n",
    "    similarties = {}\n",
    "    for i in range(1,max(bin_means[2])+1):\n",
    "        similarties[i] = []\n",
    "\n",
    "    #Load disease annotion (plus upstream annotation)\n",
    "    print 'Load Disease Associations:'\n",
    "    Disease_Association_UP,d_diseases_annotation = GO.getAllGene_Disease_Annotation()\n",
    "    print 'Done'\n",
    "\n",
    "    #calculate similarity and add to specific bin\n",
    "    for d,bin in zip(drugs,bin_means[2]):\n",
    "\n",
    "        targets =  cloud_targets[d]\n",
    "\n",
    "        if len(targets) > 1:\n",
    "            if similarity_Type == 'MaxSpecificity':\n",
    "                sims = Calculate_Similarity_MaxSpecificity(targets, targets, d_diseases_annotation,Disease_Association_UP)\n",
    "            similarties[bin].append(sims)\n",
    "\n",
    "    #Plot as Barplot\n",
    "    plt.bar(range(1,max(bin_means[2])+1), [np.mean(similarties[x]) for x in range(1,max(bin_means[2])+1)], yerr=[1.96 * (np.std(similarties[x]) / float(len(similarties[x]))) for x in range(1,max(bin_means[2])+1)], align='center', alpha=0.5, ecolor='black', capsize=10, color='#40B9D4', zorder = 2)\n",
    "    plt.xticks(range(1,max(bin_means[2])+1),['{:2.2f}'.format(x) for x in bin_means[1]])\n",
    "    plt.xlabel(\"Glass' Delta\")\n",
    "    plt.ylabel(\"Disease Similarity\\n%s (95%% CI)\" %similarity_Type)\n",
    "    #plt.show()\n",
    "    plt.savefig('../results/PPI_Analysis/Disease_Enrichment/ShortestPath_Disease_BarPlot.pdf',format='pdf')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Disease_Self_ShortestPath()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Disease_Self_LCC():\n",
    "    '''\n",
    "    Check how the  drug LCC size correlates with Disease term similarity\n",
    "    '''\n",
    "    \n",
    "    similarity_Type = 'MaxSpecificity'\n",
    "\n",
    "    # Get all the CLOUD Targets\n",
    "    cloud_targets = {}\n",
    "    fp = open('../data/PPI_Analysis/CLOUD_All_Targets.csv','r')\n",
    "    fp.next()\n",
    "    for line in fp:\n",
    "        tmp = line.strip().split(',')\n",
    "        cloud_targets[tmp[0]] = list(set(tmp[2].split(';')))\n",
    "\n",
    "    # Load LCC sizes\n",
    "    fp = open('../results/PPI_Analysis/LCC/LCC_Sizes.csv','r')\n",
    "    fp.next()\n",
    "    drug_ShortestPath = []\n",
    "    drugs = []\n",
    "    for line in fp:\n",
    "        tmp = line.strip().split(',')\n",
    "        if tmp[2] != 'nan':\n",
    "            drugs.append(tmp[0])\n",
    "            drug_ShortestPath.append(float(tmp[2]))\n",
    "\n",
    "    #Bin the LCC sizes\n",
    "    bin_means = binned_statistic(drug_ShortestPath, drug_ShortestPath, bins=[min(drug_ShortestPath), 4, 8, 12, 16, max(drug_ShortestPath)])\n",
    "\n",
    "    #Calcualte similarity dictionary\n",
    "    similarties = {}\n",
    "    for i in range(1, max(bin_means[2]) + 1):\n",
    "        similarties[i] = []\n",
    "\n",
    "    #Load disease ontology plus upstream terms\n",
    "    print 'Load Disease Associations:'\n",
    "    Disease_Association_UP,d_diseases_annotation = GO.getAllGene_Disease_Annotation()\n",
    "    print 'Done'\n",
    "\n",
    "    #Calculate similarity and add to specific bin\n",
    "    for d,bin in zip(drugs,bin_means[2]):\n",
    "\n",
    "        targets = cloud_targets[d]\n",
    "        if len(targets) > 1:\n",
    "            if similarity_Type == 'MaxSpecificity':\n",
    "                sims = Calculate_Similarity_MaxSpecificity(targets, targets, d_diseases_annotation, Disease_Association_UP)\n",
    "            similarties[bin].append(np.mean(sims))\n",
    "\n",
    " \n",
    "    #plot as barplot\n",
    "    plt.bar(range(1,max(bin_means[2])+1), [np.mean(similarties[x]) for x in range(1,max(bin_means[2])+1)], yerr=[1.96 * (np.std(similarties[x]) / float(len(similarties[x]))) for x in range(1,max(bin_means[2])+1)], align='center', alpha=0.5, ecolor='black', capsize=10, color='#40B9D4', zorder = 2)\n",
    "    plt.xticks(range(1,max(bin_means[2])+1),['{:2.2f}'.format(x) for x in bin_means[1]])\n",
    "    plt.xlabel(\"Glass' Delta\")\n",
    "    plt.ylabel(\"Disease Similarity\\n%s (95%% CI)\" %similarity_Type)\n",
    "    #plt.show()\n",
    "    plt.savefig('../results/PPI_Analysis/Disease_Enrichment/LCC_Disease_BarPlot.pdf',format='pdf')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Disease_Self_LCC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Disease_Separation():\n",
    "    '''\n",
    "    Check how the drug module overlap (Sab score) correlates with Disease term similarity\n",
    "    '''\n",
    "\n",
    "    similarity_Type = 'MaxSpecificity'\n",
    "\n",
    "    # Get all the CLOUD Targets\n",
    "    cloud_targets = {}\n",
    "    all_Drugs = []\n",
    "    fp = open('../data/PPI_Analysis/CLOUD_All_Targets.csv','r')\n",
    "    fp.next()\n",
    "    for line in fp:\n",
    "        tmp = line.strip().split(',')\n",
    "        cloud_targets[tmp[0]] = list(set(tmp[2].split(';')))\n",
    "        all_Drugs.append(tmp[0])\n",
    "\n",
    "    #Load the results\n",
    "    fp = open('../results/PPI_Analysis/Separation/Separation_half.csv', 'r')\n",
    "    fp.next()\n",
    "    drug_ShortestPath = []\n",
    "    Alldrugs = []\n",
    "    for line in fp:\n",
    "        tmp = line.strip().split(',')\n",
    "        if tmp[2] != 'nan':\n",
    "            Alldrugs.append(tmp[0]+','+tmp[1])\n",
    "            drug_ShortestPath.append(float(tmp[5]))\n",
    "\n",
    "    #Bin the sab overlaps\n",
    "    bin_means = binned_statistic(drug_ShortestPath, drug_ShortestPath, bins=[min(drug_ShortestPath),-1.5,-1,-0.5,0,0.5,1,1.5,max(drug_ShortestPath)])\n",
    "\n",
    "    #create similarity dictionary\n",
    "    similarties = {}\n",
    "    for i in range(1, max(bin_means[2]) + 1):\n",
    "        similarties[i] = []\n",
    "\n",
    "    #Load disease ontology (plus upstream)\n",
    "    print 'Load Disease Associations:'\n",
    "    Disease_Association_UP,d_diseases_annotation = GO.getAllGene_Disease_Annotation()\n",
    "    print 'Done'\n",
    "\n",
    "\n",
    "    #Calculate random distribution\n",
    "    random_distribution = []\n",
    "    for i in range(1,1000):\n",
    "        randDrugs = random.sample(all_Drugs,2)\n",
    "        targets1 = cloud_targets[randDrugs[0]]\n",
    "        targets2 = cloud_targets[randDrugs[1]]\n",
    "\n",
    "        if len(targets1) > 0 and len(targets2) > 0:\n",
    "            if similarity_Type == 'MaxSpecificity':\n",
    "                sim = Calculate_Similarity_MaxSpecificity(targets1,targets2,d_diseases_annotation,Disease_Association_UP,isSeparation=True)\n",
    "            random_distribution.append(sim)\n",
    "\n",
    "    print 'Finished Random'\n",
    "\n",
    "    #calculate similatities and add to specific bin\n",
    "    for d, bin in zip(Alldrugs, bin_means[2]):\n",
    "\n",
    "        drugs = d.split(',')\n",
    "\n",
    "        targets1 = cloud_targets[drugs[0]]\n",
    "        targets2 = cloud_targets[drugs[1]]\n",
    "\n",
    "        if len(targets1) > 0 and len(targets2) > 0:\n",
    "            if similarity_Type == 'MaxSpecificity':\n",
    "                sim = Calculate_Similarity_MaxSpecificity(targets1,targets2,d_diseases_annotation,Disease_Association_UP,isSeparation=True)\n",
    "            else:\n",
    "                sim = Calculate_Similarity_Jaccard(targets1, targets2,Disease_Association_UP,isSeparation=True)\n",
    "\n",
    "            similarties[bin].append(np.mean(sim))\n",
    "\n",
    "   \n",
    "    #Plot as barplot\n",
    "    plt.bar(range(1,max(bin_means[2])+1), [np.mean(similarties[x]) for x in range(1,max(bin_means[2])+1)], yerr=[1.96 * (np.std(similarties[x]) / float(len(similarties[x]))) for x in range(1,max(bin_means[2])+1)], align='center', alpha=0.5, ecolor='black', capsize=10, color='#40B9D4', zorder = 2)\n",
    "    plt.xticks(range(1,max(bin_means[2])+1),['{:2.2f}'.format(x) for x in bin_means[1]])\n",
    "    plt.axhline(np.mean(random_distribution), c='grey', ls='--')\n",
    "    plt.xlabel(\"Separation Sab\")\n",
    "    plt.ylabel(\"Disease Similarity\\n%s (95%% CI)\" %similarity_Type)\n",
    "    #plt.show()\n",
    "    plt.savefig('../results/PPI_Analysis/Disease_Enrichment/Separation_Disease_BarPlot.pdf',format='pdf')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Disease_Separation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Shared Side Effects\n",
    "Check if localization and separation influences the amount of shared side effects using the Offside DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkSameSEs(SEs1,SEs2):\n",
    "    '''\n",
    "    Check overlap between atcs; 1 if overlap exists 0 if not. Check for at least ONE overlap within the two sets.\n",
    "    Return 1 if true or 0 if false\n",
    "    '''\n",
    "        \n",
    "    oneOverlap = False\n",
    "    for SE1 in SEs1:\n",
    "        for SE2 in SEs2:\n",
    "            if SE1 == SE2:\n",
    "                oneOverlap = True\n",
    "\n",
    "    if oneOverlap:\n",
    "        return  1\n",
    "    else:\n",
    "        return  0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortest_distanceSideEffects():\n",
    "\n",
    "    # Get all the CLOUD Targets\n",
    "    cloud_SideEffects = {}\n",
    "    all_Drugs = []\n",
    "    fp = open('../data/PPI_Analysis/CLOUD_to_Offsides.csv','r')\n",
    "    fp.next()\n",
    "    for line in fp:\n",
    "        tmp = line.strip().split(',')\n",
    "        cloud_SideEffects[tmp[0]] = list(set(tmp[2].split(';')))\n",
    "        all_Drugs.append(tmp[0])\n",
    "\n",
    "    \n",
    "    #Load the results\n",
    "    fp = open('../results/PPI_Analysis/Separation/Separation_half.csv', 'r')\n",
    "    fp.next()\n",
    "    drug_ShortestPath = []\n",
    "    drug_ShortestPath_2 = {}\n",
    "    Alldrugs = []\n",
    "    for line in fp:\n",
    "        tmp = line.strip().split(',')\n",
    "        if tmp[2] != 'nan':\n",
    "            Alldrugs.append(tmp[0]+','+tmp[1])\n",
    "            drug_ShortestPath.append(float(tmp[5]))\n",
    "            drug_ShortestPath_2[tmp[0] + ',' + tmp[1]] = float(tmp[5])\n",
    "\n",
    "            \n",
    "    #Split Sab scores in positive (>0 ) and negative (<0) scores. Then calculate the percent overlap (FIRST LEVEL)\n",
    "    negative_sab = []\n",
    "    positive_sab = []\n",
    "    for drugPair in drug_ShortestPath_2.keys():\n",
    "        drugs = drugPair.split(',')\n",
    "        if drug_ShortestPath_2[drugPair] < 0:\n",
    "            negative_sab.append(checkSameSEs(cloud_SideEffects[drugs[0]],cloud_SideEffects[drugs[1]]))\n",
    "        else:\n",
    "            positive_sab.append(checkSameSEs(cloud_SideEffects[drugs[0]], cloud_SideEffects[drugs[1]]))\n",
    "        \n",
    "    \n",
    "    #calcualte the percentage overlap\n",
    "    negative_sab = sum(negative_sab)/float(len(negative_sab)) * 100\n",
    "    positive_sab =  sum(positive_sab)/float(len(positive_sab)) * 100\n",
    "    \n",
    "    #Create the bar plot showing the overlap (in percent)\n",
    "    plt.bar([0,1],[negative_sab,positive_sab],align='center', alpha=0.5, ecolor='black', capsize=10,color='#40B9D4', zorder=2)\n",
    "    plt.xticks([0,1], ['Negative','Positive'])\n",
    "    plt.xlabel(\"Sab\")\n",
    "    plt.ylabel(\"Percent overlap drugs have overlap overlap\")\n",
    "    #plt.show()\n",
    "    plt.savefig('../results/PPI_Analysis/SideEffect_Enrichment/SideEffects_Overlap_Bars.pdf',format='pdf')\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "    print 'Average Sab'\n",
    "    #Inverse logic and now split Sab scores bases on if a drugpair has overlaping ATC classes or not\n",
    "    same_SE = []\n",
    "    different_SE = []\n",
    "    for drugPair in drug_ShortestPath_2.keys():\n",
    "        drugs = drugPair.split(',')\n",
    "        SE_Overlap = checkSameSEs(cloud_SideEffects[drugs[0]], cloud_SideEffects[drugs[1]])\n",
    "        if SE_Overlap == 1:\n",
    "            same_SE.append(drug_ShortestPath_2[drugPair])\n",
    "        else:\n",
    "            different_SE.append(drug_ShortestPath_2[drugPair])\n",
    "\n",
    "\n",
    "    #calcualte the mean Sab score for drug pairs with overlapping and without overlapping ATC classes\n",
    "    same = np.mean(same_SE)\n",
    "    different = np.mean(different_SE)\n",
    "\n",
    "    #Create bar plot\n",
    "    plt.bar([0, 1], [same, different], align='center', alpha=0.5, ecolor='black', capsize=10,color='#40B9D4', zorder=2, yerr=[1.96 * (np.std(x) / np.sqrt(float(len(x)))) for x in [same_SE, different_SE]])\n",
    "    plt.xticks([0, 1], ['Yes', 'No'])\n",
    "    plt.xlabel(\"Has SE overlap\")\n",
    "    plt.ylabel(\"Average Sab\")\n",
    "    #plt.show()\n",
    "    plt.savefig('../results/PPI_Analysis/SideEffect_Enrichment/SAB_with_DrugOverlap.pdf', format='pdf')\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "            \n",
    "    similarity_Type = 'Number of overlapping Side Effects'\n",
    "            \n",
    "    #Bin the sab overlaps\n",
    "    bin_means = binned_statistic(drug_ShortestPath, drug_ShortestPath, bins=[min(drug_ShortestPath),-1.5,-1,-0.5,0,0.5,1,1.5,max(drug_ShortestPath)])\n",
    "\n",
    "    #create similarity dictionary\n",
    "    similarties = {}\n",
    "    for i in range(1, max(bin_means[2]) + 1):\n",
    "        similarties[i] = []\n",
    "\n",
    "   \n",
    "    #Calculate random distribution\n",
    "    random_distribution = []\n",
    "    for i in range(1,1000):\n",
    "        randDrugs = random.sample(all_Drugs,2)\n",
    "        sideEffects1 = set(cloud_SideEffects[randDrugs[0]])\n",
    "        sideEffects2 = set(cloud_SideEffects[randDrugs[1]])\n",
    "\n",
    "        \n",
    "        if len(sideEffects1) > 0 and len(sideEffects2) > 0:\n",
    "            result = len(sideEffects1.intersection(sideEffects2))\n",
    "\n",
    "            random_distribution.append(result)\n",
    "\n",
    "    print 'Finished Random'\n",
    "\n",
    "    \n",
    "    #calculate similatities and add to specific bin\n",
    "    for d, bin in zip(Alldrugs, bin_means[2]):\n",
    "\n",
    "        drugs = d.split(',')\n",
    "\n",
    "        sideEffects1 = set(cloud_SideEffects[drugs[0]])\n",
    "        sideEffects2 = set(cloud_SideEffects[drugs[1]])\n",
    "\n",
    "        if len(sideEffects1) > 0 and len(sideEffects2) > 0:\n",
    "            result = len(sideEffects1.intersection(sideEffects2))\n",
    "\n",
    "            similarties[bin].append(result)\n",
    "        \n",
    "\n",
    "    #Plot as barplot\n",
    "    plt.bar(range(1,max(bin_means[2])+1), [np.mean(similarties[x]) for x in range(1,max(bin_means[2])+1)], yerr=[1.96 * (np.std(similarties[x]) / float(len(similarties[x]))) for x in range(1,max(bin_means[2])+1)], align='center', alpha=0.5, ecolor='black', capsize=10, color='#40B9D4', zorder = 2)\n",
    "    plt.xticks(range(1,max(bin_means[2])+1),['{:2.2f}'.format(x) for x in bin_means[1]])\n",
    "    plt.axhline(np.mean(random_distribution), c='grey', ls='--')\n",
    "    plt.xlabel(\"Separation Sab\")\n",
    "    plt.ylabel(\"Side Effect Similarity\\n%s (95%% CI)\" %similarity_Type)\n",
    "    #plt.show()\n",
    "    plt.savefig('../results/PPI_Analysis/SideEffect_Enrichment/Separation_SideEffects_BarPlot.pdf',format='pdf')\n",
    "    plt.close()\n",
    "              \n",
    "shortest_distanceSideEffects()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the DPI Network (Perturbome)\n",
    "1.) Define Thresholds   \n",
    "2.) Calculate Thresholds  \n",
    "3.) Get significant interactions  \n",
    "4.) Visualize the type and count of interactions  \n",
    "5.) Create gml file  \n",
    "6.) Check network parameters (e.g. degree distributions)  \n",
    "7.) Check adjecency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define python libraries\n",
    "import numpy as np\n",
    "from matplotlib import pylab as plt\n",
    "import networkx as nx\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Thresholds\n",
    "Define which thresholds to be used, as well as which wells should be excluded (e.g. Cytotoxic Drugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Certain wells show specific problem that need to be excluded from further analysis\n",
    "problematic_Well_Signs = ['ProblemWithCombinationWell','CombinationTransferProblem','Drug1Problem','Drug2Problem','CytotoxicDrug1','CytotoxicDrug2','CytotoxicCombination']\n",
    "\n",
    "#Types of possible interactions\n",
    "interactionTypes = ['Emergent','Increasing','Decreasing']\n",
    "\n",
    "#Batches of the screen\n",
    "batches = ['Batch1','Batch2']\n",
    "\n",
    "'''\n",
    "#############\n",
    "Thresholds###\n",
    "#############\n",
    "'''\n",
    "\n",
    "#Choose the parameter to find an optimal balance between interactions significance and effect size\n",
    "interaction_significance = 3 #how far away in means of mahalanobis distances from the NI point cloud does the real interaction need to be to be significant\n",
    "perturbaion_significnace = 7 #how far away in means of mahalanobis distances from DMSO does a perturbation need to be to be significanctly perturbed\n",
    "\n",
    "AlphaBeta_MAD_range = 2 #range of normal perturbed alpha/beta values per drug for non signifant drug pairs\n",
    "Gamma_percentile = 100 #range of normal perturbed gamma values per drug for non signifant drug pairs\n",
    "\n",
    "#Create the corresponding output_folder\n",
    "output_folder = 'DPI_iS%d_pS%d_abMAD%d_gP%d' %(interaction_significance,perturbaion_significnace,AlphaBeta_MAD_range,Gamma_percentile)\n",
    "output_path = '../results/Create_DPI_Network/' + output_folder +'/'\n",
    "\n",
    "#create the directory if it does not exist\n",
    "directory = os.path.dirname(output_path)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    os.makedirs(directory+'/Degree_Distributions/')\n",
    "    os.makedirs(directory+'/Interaction_Images/')\n",
    "    os.makedirs(directory+'/Networks/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Easy Outlier detection\n",
    "def reject_outliers_2(data, m=6.):\n",
    "    d = np.abs(data - np.median(data))\n",
    "    mdev = np.median(d)\n",
    "    s = d / (mdev if mdev else 1.)\n",
    "    #return s < m\n",
    "    return [data[i] for i in range(0, len(data)) if s[i] < m]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Thresholds\n",
    "Create thresholds by extracting for all drugs their respective alpha/beta and gamma values belonging to NON significant interactions. Those values then the range of alpha and beta values that a drug can be modulated without significantly changing it. In order to to avoid outliers we used MAD=2 for the alpha/beta values that follow a ca. Gaussian distribution for normal values while for gamma we used a 100 percentile range as the distribution follows more a exponential function with many small values and only some bigger. \n",
    "\n",
    "The idea behind this is that smaller effect drugs (having smaller morphological vectors) can be much more changed e.g. 8x while still not resulting in a significant interaction while on the other hand strong effect drugs (with large morphological vectors) already have a strong impact if being changed e.g. 1.1x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open the file\n",
    "fp = open('../data/Create_DPI_Network/All_MC_Scores.csv','r')\n",
    "fp.next()\n",
    "\n",
    "#File to save all non-significant alpha/beta/gamma values (to later calculate suited thresholds)\n",
    "perDrug_AlphaBetaGammas = {'Batch1':{},'Batch2':{}}\n",
    "\n",
    "#collect all alpha/beta/gammas\n",
    "for line in fp:\n",
    "    tmp = line.strip().split(',')\n",
    "    \n",
    "    #ignore the drug pair if there seemed to be a problem\n",
    "    if tmp[5] in problematic_Well_Signs:\n",
    "        continue\n",
    "    \n",
    "    #extract drug and batch information\n",
    "    drug1 = tmp[0]\n",
    "    drug2 = tmp[1]\n",
    "    batch = tmp[2]\n",
    "    \n",
    "    #add the drug to the dictionary if not already so\n",
    "    if perDrug_AlphaBetaGammas[batch].has_key(drug1) == False:\n",
    "        perDrug_AlphaBetaGammas[batch][drug1] = {'AlphaBetas':[],'Gammas':[]}\n",
    "    if perDrug_AlphaBetaGammas[batch].has_key(drug2) == False:\n",
    "        perDrug_AlphaBetaGammas[batch][drug2] = {'AlphaBetas':[],'Gammas':[]}\n",
    "    \n",
    "    #get the interaction significance\n",
    "    maha_General = float(tmp[20])\n",
    "\n",
    "    #include only non-significant interactions\n",
    "    if  maha_General < interaction_significance:\n",
    "        \n",
    "        #add the alpha/beta values\n",
    "        perDrug_AlphaBetaGammas[batch][drug1]['AlphaBetas'].append(float(tmp[14]))\n",
    "        perDrug_AlphaBetaGammas[batch][drug2]['AlphaBetas'].append(float(tmp[15]))\n",
    "        \n",
    "        #add the same gamma to BOTH drugs (as gamma is undirected)\n",
    "        perDrug_AlphaBetaGammas[batch][drug1]['Gammas'].append(float(tmp[16]))\n",
    "        perDrug_AlphaBetaGammas[batch][drug2]['Gammas'].append(float(tmp[16]))\n",
    "fp.close()\n",
    "        \n",
    "#Dictionary with the thresholds for each drug        \n",
    "perDrug_AlphaBetaGammaThresholds = {'Batch1':{},'Batch2':{}}       \n",
    "\n",
    "#calculate thresholds\n",
    "for b in batches:\n",
    "    for key in perDrug_AlphaBetaGammas[b]:\n",
    "\n",
    "        #create alpha/beta threshold by using the borders of alpha/beta within 2 MADs and gamma within 99 percentiles\n",
    "        alphaBeta_NoOutlier = reject_outliers_2(perDrug_AlphaBetaGammas[b][key]['AlphaBetas'], AlphaBeta_MAD_range)\n",
    "        alphaBeta_NoOutlier.append(1)\n",
    "        perDrug_AlphaBetaGammas[b][key]['Gammas'].append(0)\n",
    "        perDrug_AlphaBetaGammaThresholds[b][key] = {'Upper':max([x for x in alphaBeta_NoOutlier if x >= 1]), 'Lower':min([x for x in alphaBeta_NoOutlier if x <= 1]), 'Emergent':np.percentile(perDrug_AlphaBetaGammas[b][key]['Gammas'],Gamma_percentile)}\n",
    "\n",
    "\n",
    "#Example CLOUD057\n",
    "'''\n",
    "plt.hist(perDrug_AlphaBetaGammas['Batch2']['CLOUD057']['AlphaBetas'], bins=10, color = 'grey')\n",
    "plt.axvline(perDrug_AlphaBetaGammaThresholds['Batch2']['CLOUD057']['Upper'] )\n",
    "plt.axvline(perDrug_AlphaBetaGammaThresholds['Batch2']['CLOUD057']['Lower'] )\n",
    "#plt.show()\n",
    "plt.savefig(output_path + 'Cytarabine_DirectedThreshold.pdf',format='pdf',dpi=600)\n",
    "plt.close()\n",
    "\n",
    "plt.hist(perDrug_AlphaBetaGammas['Batch2']['CLOUD057']['Gammas'], bins=10, color = 'grey')\n",
    "plt.axvline(perDrug_AlphaBetaGammaThresholds['Batch2']['CLOUD057']['Emergent'] )\n",
    "plt.savefig(output_path + 'Cytarabine_EmergentThreshold.pdf',format='pdf',dpi=600)\n",
    "plt.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get Significant Interactions\n",
    "Go through all drug pairs and associate significant interactions (effect/sgnificance) correctly to interactions according to our vector math e.g. 1.2 alpha would be a increasing interaction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary with interactions\n",
    "Interactions = {}\n",
    "\n",
    "#create the 3 interaction types (increasing, decreasing and emergent)\n",
    "for iT in interactionTypes:\n",
    "    Interactions[iT] = {}\n",
    "\n",
    "#dictionary with significant drug\n",
    "significant_Drugs = {'Batch1':set(),'Batch2':set()}\n",
    "\n",
    "#save the perturbation values of the individual drugs\n",
    "drug_mahalanobis_values = {'Batch1':{},'Batch2':{}}\n",
    "\n",
    "#Open file with drug pair calculations\n",
    "fp = open('../data/Create_DPI_Network/All_MC_Scores.csv','r')\n",
    "fp.next()\n",
    "\n",
    "#count number of significant interactions (does not nececarry mean final interactions)\n",
    "InteractionCount = 0\n",
    "#number of all drug pairs \n",
    "Number_Of_Valid_DrugPairs = 0\n",
    "\n",
    "for line in fp:\n",
    "    Number_Of_Valid_DrugPairs +=1\n",
    "    tmp = line.strip().split(',')\n",
    "    \n",
    "    #ignore the drug pair if there seemed to be a problem\n",
    "    if tmp[5] in problematic_Well_Signs:\n",
    "        continue\n",
    "    \n",
    "    #get the interaction significance\n",
    "    maha_General = float(tmp[20])\n",
    "    \n",
    "    #only check interaction if significantly away from NI point\n",
    "    if maha_General > interaction_significance:\n",
    "\n",
    "        #increment significant interaction count\n",
    "        InteractionCount += 1\n",
    "        \n",
    "        #extract drug information\n",
    "        drug1 = tmp[0]\n",
    "        drug2 = tmp[1]\n",
    "        batch = tmp[2]\n",
    "        \n",
    "        #extract mahalanobis distances (how far away from DMSO)\n",
    "        maha_drug1 = float(tmp[5])\n",
    "        maha_drug2 = float(tmp[8])\n",
    "        maha_Combi = float(tmp[11])\n",
    "        \n",
    "        #check for significance (usually > 6)\n",
    "        drug1_significance = maha_drug1 > perturbaion_significnace\n",
    "        drug2_significance = maha_drug2 > perturbaion_significnace\n",
    "        combi_significance = maha_Combi > perturbaion_significnace\n",
    "        \n",
    "        #extract alpha/beta/gamma\n",
    "        alpha = float(tmp[14])\n",
    "        beta = float(tmp[15])\n",
    "        gamma =  float(tmp[16])\n",
    "        \n",
    "      \n",
    "        #add drugs to significant drugs if significant\n",
    "        if drug1_significance:\n",
    "            significant_Drugs[batch].add(drug1)\n",
    "        if drug2_significance:\n",
    "            significant_Drugs[batch].add(drug2)\n",
    "        \n",
    "        \n",
    "        drug_mahalanobis_values[batch][drug1] = maha_drug1\n",
    "        drug_mahalanobis_values[batch][drug2] = maha_drug2\n",
    "        \n",
    "        \n",
    "        #####\n",
    "        # GOT THROUGH ALL 7 POSSIBILITIES of where a drug can be modulated\n",
    "        ###\n",
    "        #0.\n",
    "        # Singles not active, combination not active ==> no interactions\n",
    "        \n",
    "        # 1.)\n",
    "        #Single not active, combination active ==> possible Emergent\n",
    "        if drug1_significance == False and drug2_significance == False and combi_significance == True:\n",
    "            #if gamma > Emergent_Threshold[batch]:\n",
    "            if gamma > max([perDrug_AlphaBetaGammaThresholds[batch][drug1]['Emergent'],perDrug_AlphaBetaGammaThresholds[batch][drug2]['Emergent']]):\n",
    "                Interactions['Emergent'][drug1+','+drug2] = {'Value':gamma,'Batch':batch, 'Mahalanobis':maha_General}\n",
    "        #2.)\n",
    "        #One Single active, combination active anymore ==> possible Deactivting\n",
    "        elif drug1_significance == True and drug2_significance == False and combi_significance == False:\n",
    "            #if alpha < AlphaBeta_Threshold_Decreasing[batch]:\n",
    "            if alpha < perDrug_AlphaBetaGammaThresholds[batch][drug1]['Lower']:\n",
    "                Interactions['Decreasing'][drug2+','+drug1] = {'Value':alpha,'Batch':batch, 'Mahalanobis':maha_General}\n",
    "        #3.)\n",
    "        #One Single active, combination active anymore ==> possible Deactivting\n",
    "        elif drug1_significance == False and drug2_significance == True and combi_significance == False:\n",
    "            #if beta < AlphaBeta_Threshold_Decreasing[batch]:\n",
    "            if beta < perDrug_AlphaBetaGammaThresholds[batch][drug2]['Lower']:\n",
    "                Interactions['Decreasing'][drug1+','+drug2] = {'Value':beta,'Batch':batch, 'Mahalanobis':maha_General}\n",
    "        #4.)\n",
    "        #Both Single active, combination not active anymore ==> possible Double Deactivating\n",
    "        elif drug1_significance == True and drug2_significance == True and combi_significance == False:\n",
    "            #if beta < AlphaBeta_Threshold_Decreasing[batch]:\n",
    "            if beta < perDrug_AlphaBetaGammaThresholds[batch][drug2]['Lower']:\n",
    "                Interactions['Decreasing'][drug1+','+drug2] = {'Value':beta,'Batch':batch, 'Mahalanobis':maha_General}\n",
    "            \n",
    "            if alpha < perDrug_AlphaBetaGammaThresholds[batch][drug1]['Lower']:\n",
    "                Interactions['Decreasing'][drug2+','+drug1] = {'Value':alpha,'Batch':batch, 'Mahalanobis':maha_General}\n",
    "        \n",
    "        #5.)\n",
    "        #One Single active, combination active  ==> The one Single gets modulated\n",
    "        elif drug1_significance == True and drug2_significance == False and combi_significance == True:\n",
    "            #print tmp\n",
    "            #if gamma > Emergent_Threshold[batch]:\n",
    "            if gamma > max([perDrug_AlphaBetaGammaThresholds[batch][drug1]['Emergent'],perDrug_AlphaBetaGammaThresholds[batch][drug2]['Emergent']]):\n",
    "                Interactions['Emergent'][drug1+','+drug2] = {'Value':gamma,'Batch':batch, 'Mahalanobis':maha_General}\n",
    "\n",
    "            if alpha > perDrug_AlphaBetaGammaThresholds[batch][drug1]['Upper']:\n",
    "                Interactions['Increasing'][drug2+','+drug1] = {'Value':alpha,'Batch':batch , 'Mahalanobis':maha_General}\n",
    "\n",
    "            if alpha < perDrug_AlphaBetaGammaThresholds[batch][drug1]['Lower']:\n",
    "                Interactions['Decreasing'][drug2+','+drug1] = {'Value':alpha,'Batch':batch , 'Mahalanobis':maha_General}\n",
    "        #6.)\n",
    "        #One Single active, combination active  ==> The one Single gets modulated\n",
    "        elif drug1_significance == False and drug2_significance == True and combi_significance == True:\n",
    "            \n",
    "            #if gamma > Emergent_Threshold[batch]:\n",
    "            if gamma > max([perDrug_AlphaBetaGammaThresholds[batch][drug1]['Emergent'],perDrug_AlphaBetaGammaThresholds[batch][drug2]['Emergent']]):\n",
    "                Interactions['Emergent'][drug1+','+drug2] = {'Value':gamma,'Batch':batch, 'Mahalanobis':maha_General}\n",
    "            if beta > perDrug_AlphaBetaGammaThresholds[batch][drug2]['Upper']:\n",
    "                Interactions['Increasing'][drug1+','+drug2] = {'Value':beta,'Batch':batch , 'Mahalanobis':maha_General}\n",
    "            if beta < perDrug_AlphaBetaGammaThresholds[batch][drug2]['Lower']:\n",
    "                Interactions['Decreasing'][drug1+','+drug2] = {'Value':beta,'Batch':batch , 'Mahalanobis':maha_General}\n",
    "        #7.)\n",
    "        #Both Single active, combination active  ==> Both Single gets modulated\n",
    "        elif drug1_significance == True and drug2_significance == True and combi_significance == True:\n",
    "            if gamma > max([perDrug_AlphaBetaGammaThresholds[batch][drug1]['Emergent'],perDrug_AlphaBetaGammaThresholds[batch][drug2]['Emergent']]):\n",
    "                Interactions['Emergent'][drug1+','+drug2] = {'Value':gamma,'Batch':batch, 'Mahalanobis':maha_General}\n",
    "\n",
    "\n",
    "            if alpha > perDrug_AlphaBetaGammaThresholds[batch][drug1]['Upper']:\n",
    "                Interactions['Increasing'][drug2+','+drug1] = {'Value':alpha,'Batch':batch , 'Mahalanobis':maha_General}\n",
    "            if alpha < perDrug_AlphaBetaGammaThresholds[batch][drug1]['Lower']:\n",
    "                Interactions['Decreasing'][drug2+','+drug1] = {'Value':alpha,'Batch':batch , 'Mahalanobis':maha_General}\n",
    "\n",
    "\n",
    "            if beta > perDrug_AlphaBetaGammaThresholds[batch][drug2]['Upper']:\n",
    "                Interactions['Increasing'][drug1+','+drug2] = {'Value':beta,'Batch':batch, 'Mahalanobis':maha_General }\n",
    "            if beta < perDrug_AlphaBetaGammaThresholds[batch][drug2]['Lower']:\n",
    "                Interactions['Decreasing'][drug1+','+drug2] = {'Value':beta,'Batch':batch, 'Mahalanobis':maha_General }\n",
    "\n",
    "                \n",
    "'''\n",
    "Plot results\n",
    "'''\n",
    "        \n",
    "print 'Theoretical number of pairs: 35.511'\n",
    "print 'Number investigated drug prais (drug decay, screening problems etc.): %d' %Number_Of_Valid_DrugPairs\n",
    "print 'Significant Pairs: %d\\n' %InteractionCount                \n",
    "                \n",
    "NumberOfInteractions = 0      \n",
    "for iT in interactionTypes:\n",
    "    print 'Number %s: %d' %(iT , len(Interactions[iT]))\n",
    "    NumberOfInteractions = NumberOfInteractions + len(Interactions[iT])\n",
    "print '-------------'\n",
    "print 'Number of interactions: %d' %NumberOfInteractions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Results and create output file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Quick overview over all interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Per Batch Results:'\n",
    "print 'Batch1:'\n",
    "for iT in interactionTypes:\n",
    "    print 'Number %s: %d' %(iT , len([x for x in Interactions[iT] if Interactions[iT][x]['Batch'] == 'Batch1']))\n",
    "print 'Batch2:'\n",
    "for iT in interactionTypes:\n",
    "    print 'Number %s: %d' %(iT , len([x for x in Interactions[iT] if Interactions[iT][x]['Batch'] == 'Batch2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Create an output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the significant interaction in a separate file\n",
    "fp_out = open(output_path+'InteractionsOverview_'+output_folder+'.csv','w')\n",
    "fp_out.write('Drug1,Drug2,Batch,InteractionType,Value,MahalanobisDistance\\n')\n",
    "for iT in interactionTypes:\n",
    "    for interaction in Interactions[iT].keys():\n",
    "        drugs = interaction.split(',')\n",
    "        fp_out.write(drugs[0]+','+drugs[1]+','+Interactions[iT][interaction]['Batch']+','+iT+','+str(Interactions[iT][interaction]['Value'])+',' +str(Interactions[iT][interaction]['Mahalanobis'])+'\\n')\n",
    " \n",
    "fp_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create the Perturbome network (gml file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculatePossibleNumberOfInteractions(network,name):\n",
    "    '''\n",
    "    Quick function calculating the theoretical possible amount of edges for a given network. \n",
    "    As well as the sparcisity for this given network.\n",
    "    '''\n",
    "    \n",
    "    # Get number of nodes and edges\n",
    "    number_edges = len(network.edges())\n",
    "    number_nodes = len(network.nodes())\n",
    "    \n",
    "    # Get number of nodes being significant perturbers\n",
    "    S = len([x for x in network.nodes() if network.node[x]['OnceSignificant'] == True])        \n",
    "    # Non significant perturbers are all remaining nodes\n",
    "    N =  number_nodes - S\n",
    "    \n",
    "    print 'Number Significant: %d' %S\n",
    "    print 'Number NonSignificant: %d' %N\n",
    "    print 'Percent: %.2f' %(float(S)/(S+N))\n",
    "\n",
    "    PossibleNumberOfInteractions = 3 * (number_nodes*(number_nodes-1)/2)\n",
    "    PossibleNumberOfInteractions_IncludingNS = 1*(N*(N-1)/2) + 2*N*S + 3*(S*(S-1)/2)\n",
    "    \n",
    "    print 'Possible Number Interactions (easy): %d' %PossibleNumberOfInteractions\n",
    "    print 'Possible Number Interactions (including N/S): %d' %PossibleNumberOfInteractions_IncludingNS\n",
    "    \n",
    "    print 'Sparsity (easy): %.2f' %(1 - float(number_edges)/PossibleNumberOfInteractions)\n",
    "    print 'Sparsity (including N/S): %.2f' %(1 - float(number_edges)/PossibleNumberOfInteractions_IncludingNS)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Create gml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#go through all interactions and add the corresponding interactions to the network (convert dict to networkx object)\n",
    "DPI = nx.MultiDiGraph()\n",
    "for iT in interactionTypes:\n",
    "    for interaction in Interactions[iT].keys():\n",
    "        drugs = interaction.split(',')\n",
    "        DPI.add_edge(drugs[0],drugs[1])\n",
    "        new_edge = max(DPI[drugs[0]][drugs[1]])\n",
    "        DPI[drugs[0]][drugs[1]][new_edge]['Type'] = iT\n",
    "        DPI[drugs[0]][drugs[1]][new_edge]['Value'] = Interactions[iT][interaction]['Value']\n",
    "        DPI[drugs[0]][drugs[1]][new_edge]['Batch'] = Interactions[iT][interaction]['Batch']\n",
    "        \n",
    "        DPI[drugs[0]][drugs[1]][new_edge]['Mahalanobis'] = Interactions[iT][interaction]['Mahalanobis']\n",
    "\n",
    "# number of significant drugs\n",
    "significant_drugs = 0\n",
    "# Get all perturbome degrees\n",
    "degrees = nx.degree(DPI)\n",
    "\n",
    "#Split into core/periphery (use straight forward top10% approach)\n",
    "top10 = np.percentile([x[1] for x in degrees],90)\n",
    "core_nodes = [x[0] for x in degrees if x[1] > top10]\n",
    "periphery_nodes = [x[0] for x in degrees if x[1] <= top10]\n",
    "\n",
    "print 'Cutoff Degree: %d' %top10\n",
    "\n",
    "#add further information to all nodes\n",
    "for degree in degrees:\n",
    "    #extract drug name\n",
    "    drug = degree[0]\n",
    "    \n",
    "    #Add degree to perturbome information\n",
    "    DPI.node[drug]['Degree'] = degree[1]\n",
    "    \n",
    "    \n",
    "    # Add information if the drug was in any batch significant\n",
    "    if drug in significant_Drugs['Batch1']: \n",
    "        DPI.node[drug]['Batch1Significant'] = True\n",
    "    else:\n",
    "        DPI.node[drug]['Batch1Significant'] = False\n",
    "\n",
    "    if drug in significant_Drugs['Batch2']: \n",
    "        DPI.node[drug]['Batch2Significant'] = True\n",
    "    else:\n",
    "        DPI.node[drug]['Batch2Significant'] = False\n",
    "\n",
    "    #add information if the drug was at least in one of the two batches significant\n",
    "    if drug in significant_Drugs['Batch1'] or drug in significant_Drugs['Batch2']:\n",
    "        DPI.node[drug]['OnceSignificant'] = True\n",
    "        significant_drugs += 1      \n",
    "    else:\n",
    "        DPI.node[drug]['OnceSignificant'] = False\n",
    "        \n",
    "    #add single drug perturbation values to the drugs (in the even of a drug being always cytotoxic, never corretly transfered etc. add nan) \n",
    "    if drug_mahalanobis_values['Batch1'].has_key(drug):\n",
    "        DPI.node[drug]['Batch1MahalanobisDistance'] = drug_mahalanobis_values['Batch1'][drug]\n",
    "    else:\n",
    "        DPI.node[drug]['Batch1MahalanobisDistance'] = 'nan'\n",
    "    \n",
    "    if drug_mahalanobis_values['Batch2'].has_key(drug):\n",
    "        DPI.node[drug]['Batch2MahalanobisDistance'] = drug_mahalanobis_values['Batch2'][drug]\n",
    "    else:\n",
    "        DPI.node[drug]['Batch2MahalanobisDistance'] = 'nan'\n",
    "    \n",
    "    #add information if a node belongs to the core or periphery (i.e. 10% biggest degree nodes)\n",
    "    if drug in core_nodes:\n",
    "        DPI.node[drug]['Compartment'] = 'Core'\n",
    "    else:\n",
    "        DPI.node[drug]['Compartment'] = 'Periphery'\n",
    "        \n",
    "#add degree information\n",
    "for node in DPI.nodes():\n",
    "    DPI.node[node]['InDegree'] = len(DPI.in_edges(node))\n",
    "    DPI.node[node]['OutDegree'] = len(DPI.out_edges(node))\n",
    "    \n",
    "\n",
    "flat_network = DPI.to_undirected()\n",
    "print 'Number of drug pairs: %d' %len(flat_network.edges())\n",
    "print 'Number of Edges: %d' %len(DPI.edges())\n",
    "\n",
    "\n",
    "##\n",
    "# CORE / CORE <> Periphery / Periphery\n",
    "##\n",
    "\n",
    "#split the DPI additionally in the three compartments (Periphery, Core_to_Periphery, Core)\n",
    "DPI_core = DPI.subgraph(core_nodes)\n",
    "DPI_periphery = DPI.subgraph(periphery_nodes)\n",
    "DPI_Core_To_Periphery = DPI.copy()\n",
    "all_edges = DPI_Core_To_Periphery.edges()\n",
    "for edge in all_edges:\n",
    "    if (edge[0] in core_nodes and edge[1] in periphery_nodes) or (edge[1] in core_nodes and edge[0] in periphery_nodes):\n",
    "        continue\n",
    "    else:\n",
    "        DPI_Core_To_Periphery.remove_edge(edge[0],edge[1])\n",
    "\n",
    "        \n",
    "#Create output regarding sparsicity of the individual networks\n",
    "        \n",
    "print 'DPI (Sparsity): '        \n",
    "CalculatePossibleNumberOfInteractions(DPI,'DPI')\n",
    "print\n",
    "print 'Core (Sparsity): '        \n",
    "CalculatePossibleNumberOfInteractions(DPI_core,'Core')\n",
    "print\n",
    "print 'Periphery (Sparsity): '        \n",
    "CalculatePossibleNumberOfInteractions(DPI_periphery,'Periphery') \n",
    "print\n",
    "print 'CoreToPeriphery (Sparsity): '        \n",
    "CalculatePossibleNumberOfInteractions(DPI_Core_To_Periphery,'CoreToPerihpery') \n",
    "print\n",
    "\n",
    "\n",
    "'''\n",
    "Show output\n",
    "--> SHOW individual percentage of interaction types for the individual networks\n",
    "'''        \n",
    "print 'EDGE TYPES:'\n",
    "\n",
    "#\n",
    "# WHOLE PERTURBOME\n",
    "type_count = []\n",
    "for edge in list(set(DPI.edges())):\n",
    "    for key in DPI[edge[0]][edge[1]]:\n",
    "        type_count.append(DPI[edge[0]][edge[1]][key]['Type'])\n",
    "\n",
    "increasePercent = (type_count.count('Increasing')/float(len(type_count)))\n",
    "decreasePercent = (type_count.count('Decreasing')/float(len(type_count)))\n",
    "emergentPercent = (type_count.count('Emergent')/float(len(type_count)))\n",
    "print 'Edges DPI: %d' %len(type_count)\n",
    "print '\\t Increasing: %.2f' %increasePercent\n",
    "print '\\t Decreasing: %.2f' %decreasePercent\n",
    "print '\\t Emergent: %.2f' %emergentPercent\n",
    "plt.pie([increasePercent,decreasePercent,emergentPercent], colors=['#ACD900','#F70020','#0096FF'])\n",
    "#plt.show()\n",
    "plt.savefig(output_path + 'DPIPercent.pdf',format='pdf',dpi=600)\n",
    "plt.close()\n",
    "\n",
    "\n",
    "#\n",
    "# PERIPHERY\n",
    "type_count = []\n",
    "for edge in list(set(DPI_periphery.edges())):\n",
    "    for key in DPI_periphery[edge[0]][edge[1]]:\n",
    "        type_count.append(DPI_periphery[edge[0]][edge[1]][key]['Type'])\n",
    "\n",
    "increasePercent = (type_count.count('Increasing')/float(len(type_count)))\n",
    "decreasePercent = (type_count.count('Decreasing')/float(len(type_count)))\n",
    "emergentPercent = (type_count.count('Emergent')/float(len(type_count)))\n",
    "print 'Edges Periphery: %d' %len(type_count)\n",
    "print '\\t Increasing: %.2f' %increasePercent\n",
    "print '\\t Decreasing: %.2f' %decreasePercent\n",
    "print '\\t Emergent: %.2f' %emergentPercent\n",
    "plt.pie([increasePercent,decreasePercent,emergentPercent], colors=['#ACD900','#F70020','#0096FF'])\n",
    "#plt.show()\n",
    "plt.savefig(output_path + 'PeripheryPercent.pdf',format='pdf',dpi=600)\n",
    "plt.close()\n",
    "\n",
    "\n",
    "#\n",
    "# CORE\n",
    "type_count = []\n",
    "for edge in list(set(DPI_core.edges())):\n",
    "    for key in DPI_core[edge[0]][edge[1]]:\n",
    "        type_count.append(DPI_core[edge[0]][edge[1]][key]['Type'])\n",
    "\n",
    "increasePercent = (type_count.count('Increasing')/float(len(type_count)))\n",
    "decreasePercent = (type_count.count('Decreasing')/float(len(type_count)))\n",
    "emergentPercent = (type_count.count('Emergent')/float(len(type_count)))        \n",
    "print 'Edges Core: %d' %len(type_count)\n",
    "print '\\t Increasing: %.2f' %increasePercent\n",
    "print '\\t Decreasing: %.2f' %decreasePercent\n",
    "print '\\t Emergent: %.2f' %emergentPercent\n",
    "plt.pie([increasePercent,decreasePercent,emergentPercent], colors=['#ACD900','#F70020','#0096FF'])\n",
    "#plt.show()\n",
    "plt.savefig(output_path + 'CorePercent.pdf',format='pdf',dpi=600)\n",
    "plt.close()\n",
    "\n",
    "#\n",
    "# CORE <> PERIPHERY\n",
    "type_count = []\n",
    "for edge in list(set(DPI_Core_To_Periphery.edges())):\n",
    "    for key in DPI_Core_To_Periphery[edge[0]][edge[1]]:\n",
    "        type_count.append(DPI_Core_To_Periphery[edge[0]][edge[1]][key]['Type'])\n",
    "increasePercent = (type_count.count('Increasing')/float(len(type_count)))\n",
    "decreasePercent = (type_count.count('Decreasing')/float(len(type_count)))\n",
    "emergentPercent = (type_count.count('Emergent')/float(len(type_count)))\n",
    "print 'Edges CoreToPeriphery: %d' %len(type_count)\n",
    "print '\\t Increasing: %.2f' %increasePercent\n",
    "print '\\t Decreasing: %.2f' %decreasePercent\n",
    "print '\\t Emergent: %.2f' %emergentPercent\n",
    "plt.pie([increasePercent,decreasePercent,emergentPercent], colors=['#ACD900','#F70020','#0096FF'])\n",
    "#plt.show()\n",
    "plt.savefig(output_path + 'CoreToPeripheryPercent.pdf',format='pdf',dpi=600)\n",
    "plt.close()\n",
    "print '--'\n",
    "\n",
    "#WRITE Output\n",
    "print 'NumberSignificant Drugs (at least in one batch): %d' %significant_drugs\n",
    "nx.write_gml(DPI, output_path + 'Networks/DPI_Network_Complete.gml')\n",
    "nx.write_gml(DPI_core,output_path + 'Networks/DPI_Network_Core.gml')\n",
    "nx.write_gml(DPI_periphery,output_path + 'Networks/DPI_Network_Periphery.gml')\n",
    "nx.write_gml(DPI_Core_To_Periphery,output_path + 'Networks/DPI_Network_CoreToPeriphery.gml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Detailed output\n",
    "create a more detailed output that summarizes the incrasing/decreasing/emergent interactions into the 18 possible patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count the possible patterns\n",
    "possible_interactions = ['Decreasing_Decreasing_Emergent', 'Decreasing_Emergent_Increasing','Increasing_Increasing', 'Decreasing_Increasing', 'Emergent', 'Decreasing_Decreasing', 'Emergent_Increasing', 'Emergent_Increasing_Increasing', 'Decreasing', 'Increasing', 'Decreasing_Emergent']\n",
    "interaction_dictionary = {}\n",
    "for pI in possible_interactions:\n",
    "    interaction_dictionary[pI] = []\n",
    "\n",
    "print 'Number of Interactions: %d\\n' %len(DPI.edges())    \n",
    "\n",
    "all_edges = list(set(DPI.edges()))\n",
    "\n",
    "already_used = []\n",
    "\n",
    "#count edges accordingly\n",
    "for edge in all_edges:\n",
    "    if edge in already_used:\n",
    "        continue\n",
    "\n",
    "    interactions = []\n",
    "    for key in DPI[edge[0]][edge[1]]:\n",
    "        interactions.append(DPI[edge[0]][edge[1]][key]['Type'])\n",
    "    if DPI.has_edge(edge[1],edge[0]):\n",
    "        for key in DPI[edge[1]][edge[0]]:\n",
    "            interactions.append(DPI[edge[1]][edge[0]][key]['Type'])\n",
    "            already_used.append((edge[1],edge[0]))\n",
    "    \n",
    "    interactions.sort()\n",
    "    interaction_dictionary['_'.join(interactions)].append(edge)\n",
    "    \n",
    "#output pattern cout\n",
    "print 'INTERACTION TABLE'\n",
    "print '(No)%d\\t(E)%d\\n' %((Number_Of_Valid_DrugPairs - NumberOfInteractions), len(interaction_dictionary['Emergent']))\n",
    "print '(I)%d\\t\\t(IE)%d' %(len(interaction_dictionary['Increasing']), len(interaction_dictionary['Emergent_Increasing']))\n",
    "print '(D)%d\\t\\t(DE)%d\\n' %(len(interaction_dictionary['Decreasing']), len(interaction_dictionary['Decreasing_Emergent']))\n",
    "print '(II)%d\\t\\t(IIE)%d' %(len(interaction_dictionary['Increasing_Increasing']), len(interaction_dictionary['Emergent_Increasing_Increasing']))\n",
    "print '(DD)%d\\t\\t(DDE)%d' %(len(interaction_dictionary['Decreasing_Decreasing']), len(interaction_dictionary['Decreasing_Decreasing_Emergent']))\n",
    "print '(ID)%d\\t\\t(IDE)%d' %(len(interaction_dictionary['Decreasing_Increasing']), len(interaction_dictionary['Decreasing_Emergent_Increasing']))\n",
    "\n",
    "\n",
    "#create a csv file with detailed drug pair interaction output\n",
    "fp_out = open(output_path + 'InteractionsDetailedOverview.csv','w')\n",
    "fp_out.write('Drug1,Drug2,Batch,InteractionType,Mahalanobis\\n')\n",
    "for detailed_interaction in interaction_dictionary:\n",
    "    for interact in interaction_dictionary[detailed_interaction]:\n",
    "        \n",
    "        \n",
    "        interactions = []\n",
    "        for key in DPI[interact[0]][interact[1]]:\n",
    "            interactions.append(interact[0] +' ' +DPI[interact[0]][interact[1]][key]['Type'] +' ' + interact[1] + '(%.2f)' %DPI[interact[0]][interact[1]][key]['Value'] )\n",
    "        \n",
    "        if DPI.has_edge(interact[1],interact[0]):\n",
    "            for key in DPI[interact[1]][interact[0]]:\n",
    "                interactions.append(interact[1] +' ' + DPI[interact[1]][interact[0]][key]['Type'] +' ' + interact[0] + '(%.2f)' %DPI[interact[1]][interact[0]][key]['Value'] )\n",
    "                \n",
    "        fp_out.write(interact[0]+','+interact[1]+','+DPI[interact[0]][interact[1]][0]['Batch']+','+';'.join(interactions) +',%.2f' %(DPI[interact[0]][interact[1]][0]['Mahalanobis'])+'\\n')\n",
    "        \n",
    "        \n",
    "fp_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Check Network Properties\n",
    "Calculate various degree distributions for the individual network and interaction types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set a significance threshold for \n",
    "perturbaion_significnace = 7\n",
    "\n",
    "#save the max. mahalanobis distance over the two batches\n",
    "drug_perturbation_significances = {}\n",
    "\n",
    "#Open file containing the mahalanobis distance of the single perturbations\n",
    "fp = open('../data/Validate_Morphospace/Singles_Significance.csv')\n",
    "fp.next()\n",
    "for line in fp:\n",
    "    tmp = line.strip().split(',')\n",
    "    #print tmp\n",
    "    values = []\n",
    "    if tmp[1] != \"No_Cells\":\n",
    "        value1 = float(tmp[1])\n",
    "        values.append(value1)\n",
    "    \n",
    "    if tmp[3] != \"No_Cells\":\n",
    "        value1 = float(tmp[3])\n",
    "        values.append(value1)\n",
    "    if len(values) > 0:\n",
    "        drug_perturbation_significances[tmp[0]] = max(values)\n",
    "    else:\n",
    "        drug_perturbation_significances[tmp[0]] = 0\n",
    "        \n",
    "print 'Number of drugs (sucessfully transfered in screen): %d' %len(drug_perturbation_significances)\n",
    "print 'Number of Significant drugs: %d' %len([x for x in drug_perturbation_significances if drug_perturbation_significances[x] > perturbaion_significnace])\n",
    "print 'Percent: %.3f' %(len([x for x in drug_perturbation_significances if drug_perturbation_significances[x] > perturbaion_significnace])/float(len(drug_perturbation_significances.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_int = []      # total interaction\n",
    "k_eme = []      # emergent interactions\n",
    "k_in_inc = []   # incoming increasing interactions\n",
    "k_out_inc = []  # outgoing increasing interactions\n",
    "k_in_dec = []   # incoming decreasing interactions\n",
    "k_out_dec = []  # outgoing decreasing interactions\n",
    "significance = []\n",
    "\n",
    "#check for the individual degrees of the node e.g. incrasing_in, out etc.\n",
    "for node in list(DPI.nodes()):\n",
    "    emergent = 0\n",
    "    in_types = list()\n",
    "    in_edges = list(set(DPI.in_edges(node)))\n",
    "    for edge in in_edges:\n",
    "        for key in DPI[edge[0]][edge[1]].keys():\n",
    "            IntType = DPI[edge[0]][edge[1]][key]['Type']\n",
    "\n",
    "            if IntType == 'Emergent':\n",
    "\n",
    "                emergent += 1\n",
    "\n",
    "            else:\n",
    "                in_types.append(IntType)\n",
    "    \n",
    "    out_types = list()\n",
    "    out_edge = list(set(DPI.out_edges(node)))\n",
    "    for edge in out_edge:\n",
    "        for key in DPI[edge[0]][edge[1]]:\n",
    "            IntType = DPI[edge[0]][edge[1]][key]['Type']\n",
    "            if IntType == 'Emergent':\n",
    "                emergent += 1\n",
    "            else:\n",
    "                out_types.append(IntType)\n",
    "    \n",
    "    #add degree accordingly\n",
    "    k_int.append(emergent + len(in_types) + len(out_types))\n",
    "    k_eme.append(emergent)\n",
    "    k_in_inc.append(in_types.count('Increasing'))\n",
    "    k_out_inc.append(out_types.count('Increasing'))\n",
    "    k_in_dec.append(in_types.count('Decreasing'))\n",
    "    k_out_dec.append(out_types.count('Decreasing'))\n",
    "    \n",
    "    #add significance\n",
    "    significance.append(drug_perturbation_significances[node])\n",
    "    \n",
    "    \n",
    "#plot the output (plot the individual degree distributions)\n",
    "degree_distributions = [k_int,k_eme,k_in_inc,k_out_inc,k_in_dec,k_out_dec]\n",
    "titles = ['Interactions','Emergent','Increase_in','Increase_Out','Decrease_in','Decrease_out']\n",
    "interaction_colors = {'Increase_Out':'#ACD900','Decrease_out':'#F70020','Increase_in':'#ACD900','Decrease_in':'#F70020','Emergent':'#0096FF','Interactions':'grey'}\n",
    "\n",
    "for title,distr in zip(titles,degree_distributions):\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    y2 = []\n",
    "    for i in range(0,max(distr)):\n",
    "        x.append(i)\n",
    "        \n",
    "        #absolute value\n",
    "        y.append(distr.count(i))\n",
    "\n",
    "        #calculate cumulative value\n",
    "        y2.append(len([t for t in distr if t >= i]) / float(len(distr)))\n",
    "\n",
    "    #Cumulative Degree Distribution\n",
    "    ######\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.plot(x,y2, c=interaction_colors[title], alpha=1, lw=8)\n",
    "    plt.xlabel('Degree')\n",
    "    plt.ylabel('P(k)')\n",
    "    plt.savefig(output_path + '/Degree_Distributions/Cumulative_'+title+'.pdf')\n",
    "    plt.close()\n",
    "    \n",
    "    # normal Degree distribution\n",
    "    #####\n",
    "    plt.title(title)\n",
    "    plt.scatter(x,y, c=interaction_colors[title], alpha=1)\n",
    "    #plt.xscale('log')\n",
    "    #plt.yscale('log')\n",
    "    plt.xlabel('Degree')\n",
    "    plt.ylabel('P(k)')\n",
    "    #plt.show()\n",
    "    plt.savefig(output_path +'/Degree_Distributions/'+title+'.pdf')\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    #  Check if degree is correlated with the significance (mahalanobis distance) of the individual interactions\n",
    "    ##\n",
    "    x = []\n",
    "    y = []\n",
    "    for degree, signi in zip(distr,significance):\n",
    "        if signi > perturbaion_significnace:\n",
    "            x.append(degree)\n",
    "            y.append(signi)\n",
    "\n",
    "    plt.scatter(x,y, c=interaction_colors[title], alpha=0.4)\n",
    "    #plt.xscale('log')\n",
    "    #plt.yscale('log')\n",
    "    plt.xlabel('Degree')\n",
    "    plt.ylabel('Mahalanobis Distance')\n",
    "    plt.legend(['Pearson: %.2f' %np.corrcoef(x,y)[0][1]])\n",
    "    #plt.show()\n",
    "    plt.savefig(output_path +'/Significance_Degree/'+title+'.pdf')\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "#Make a combined cumulative degree distribtion\n",
    "degree_distributions = [[k_in_inc,k_out_inc],[k_in_dec,k_out_dec]]\n",
    "titles = ['Increase','Decrease']\n",
    "interaction_colors = {'Increase':'#ACD900','Decrease':'#F70020'}\n",
    "ls = {0:'-',1:':'}\n",
    "\n",
    "for title,distr in zip(titles,degree_distributions):\n",
    "\n",
    "    ls_count = 0\n",
    "    for d in distr:\n",
    "        x = []\n",
    "        y = []\n",
    "        y2 = []\n",
    "\n",
    "        for i in range(0,max(d)):\n",
    "            x.append(i)\n",
    "            \n",
    "            #absolute value\n",
    "            y.append(d.count(i))\n",
    "\n",
    "            # calculate cumulative value\n",
    "            y2.append(len([t for t in d if t >= i]) / float(len(d)))\n",
    "\n",
    "\n",
    "        plt.plot(x,y2, c=interaction_colors[title], alpha=1, lw=8, ls = ls[ls_count])\n",
    "        ls_count += 1\n",
    "        \n",
    "    plt.title(title)\n",
    "    plt.xlabel('Degree')\n",
    "    plt.ylabel('P(k)')\n",
    "    #plt.show()\n",
    "    plt.savefig(output_path + '/Degree_Distributions/Combined_Cumulative_'+title+'.pdf')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create the degree sorted adjecency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Creating the adjecency matrix for the DPI network:'\n",
    "\n",
    "#extract degrees\n",
    "degree_distribution = list(DPI.degree())\n",
    "num_nodes = len(list(DPI.degree()))\n",
    "core_cut = len([x for x in degree_distribution if x[1] > top10])\n",
    "degree_sorted_nodes = [x[0] for x  in sorted(degree_distribution, key=lambda x: x[1], reverse=True)]\n",
    "\n",
    "#Create the adjacency matrix\n",
    "rows = []\n",
    "for node1 in degree_sorted_nodes:\n",
    "    column = []\n",
    "    for node2 in degree_sorted_nodes:\n",
    "        if DPI.has_edge(node1,node2) or DPI.has_edge(node2,node1):\n",
    "            column.append(1)\n",
    "        else:\n",
    "            column.append(0)\n",
    "    rows.append(column)\n",
    "\n",
    "\n",
    "#Fill the individual parts of the adjacency matrix according to the CORE/PERIPHERY borders\n",
    "plt.fill([0,0,core_cut,core_cut],[0,core_cut,core_cut,0],c='#FA9900',alpha=0.4)\n",
    "plt.fill([core_cut,core_cut,num_nodes,num_nodes],[core_cut,num_nodes,num_nodes,core_cut],c='#A1999D',alpha=0.4)\n",
    "plt.fill([core_cut,core_cut,num_nodes,num_nodes],[0,core_cut,core_cut,0],c='#376B7B',alpha=0.4)\n",
    "plt.fill([0,0,core_cut,core_cut],[core_cut,num_nodes,num_nodes,core_cut],c='#376B7B',alpha=0.4)\n",
    "\n",
    "\n",
    "#Plot the adjacency matrix\n",
    "plt.imshow(rows,cmap='Blues')\n",
    "plt.xlabel('Node #')\n",
    "plt.ylabel('Node #')\n",
    "plt.axvline(core_cut)\n",
    "plt.axhline(core_cut)\n",
    "plt.savefig(output_path + 'AdjecencyMatrix.pdf',format='pdf',dpi=600)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

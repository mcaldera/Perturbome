{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcualte the actual Perturbation Interactions  \n",
    "Perfore calculating the actual interaction one need to consider:  \n",
    "1.) Check Drug Decay  (some drugs show symptoms of decay e.g. oxidiation --> less potency over time)  \n",
    "2.) Check CellCount  (if ther cellcount is below a certain number not statistical significant assumption can be made regarding the cell morphology)  \n",
    "\n",
    "To calculate meaningful interaction one need to check if the single and combination perturbation are significantly different from DMSO random fluctuation  \n",
    "3.) Check significance of single drugs  \n",
    "4.) Check significance of combinations  \n",
    "\n",
    "Finally drug interaction can be calculated  \n",
    "5.) Check per Single Drug fluctuation (alpha/beta and gamma)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors.kde import KernelDensity\n",
    "\n",
    "from scipy.spatial import distance as dis\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from matplotlib import pylab as plt\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of drugs that have at least one correct well: 245\n",
      "78\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Extract the perturbation vectors as well as DMSO vectors (split per batch to reduce per batch effects)\n",
    "a.) drug_perturbation_vectors (drug perturbations)\n",
    "b.) dmso (DMSO)\n",
    "'''\n",
    "\n",
    "\n",
    "# Load all the drug perturbation vectors\n",
    "path = '../data/Calculate_Interactions/All_Vectors_Combined.csv'\n",
    "fp = open(path)\n",
    "\n",
    "features = fp.readline().split(',')[1:]\n",
    "numfeatures = len(features)\n",
    "\n",
    "drug_perturbation_vectors = {'Batch1':{},'Batch2':{}}\n",
    "dmso = {'Batch1':[],'Batch2':[]}\n",
    "\n",
    "All_CLOUDs = set()\n",
    "# Go threw the file and create DMSO and drug_perturbation_vectors\n",
    "# DMSO per batch\n",
    "# drug_perturbation_vectors per Batch with full identifier\n",
    "for line in fp:\n",
    "    tmp = line.strip().split(',')\n",
    "    \n",
    "    drug1, drug2 = tmp[0].split('_')[0].split('|')\n",
    "    well = tmp[0].split('_')[1]\n",
    "    plate = tmp[0].split('_')[2]\n",
    "    \n",
    "    values = list(np.float_(tmp[1:]))\n",
    "    \n",
    "    if int(plate) < 1315065:\n",
    "        if drug1 == 'DMSO':\n",
    "            dmso['Batch1'].append(values)\n",
    "        drug_perturbation_vectors['Batch1'][drug1+','+drug2+','+plate+','+well] = values\n",
    "        #All_CLOUDs.add(drug1)\n",
    "            \n",
    "    else:\n",
    "        if drug1 == 'DMSO':\n",
    "            dmso['Batch2'].append(values)\n",
    "        drug_perturbation_vectors['Batch2'][drug1+','+drug2+','+plate+','+well] = values\n",
    "        \n",
    "        All_CLOUDs.add(drug1)\n",
    "\n",
    "        \n",
    "all_all_clouds = []\n",
    "for i in range(1,268):\n",
    "    all_all_clouds.append('CLOUD'+str(i).zfill(3))\n",
    "    \n",
    "#Get list of All_CLOUDs, this number is smaller than the original number due to some drugs not being transformer correctly or other problems\n",
    "All_CLOUDs.remove('DMSO')\n",
    "All_CLOUDs.remove('PosCon')\n",
    "\n",
    "All_CLOUDs = list(All_CLOUDs)\n",
    "All_CLOUDs.sort()\n",
    "print 'Number of drugs that have at least one correct well: %d' %len(All_CLOUDs)\n",
    "    \n",
    "print len(drug_perturbation_vectors['Batch2'][drug_perturbation_vectors['Batch2'].keys()[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Drug Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of drugs that decayed in batch1: 6\n",
      "Number of drugs that decayed in batch2: 2\n"
     ]
    }
   ],
   "source": [
    "# Both thresholds need to be true to set a drug as decayed during experiment; threshold_decay is steepness and threshold_MaxDifference absolute difference\n",
    "threshold_decay = 0.05\n",
    "threshold_MaxDifference = 0.3\n",
    "\n",
    "\n",
    "# Load all the drug decay regressions\n",
    "# Created by checking the single drug responses over the different plates (there is a temporal context between plate 1 and 123)\n",
    "# One is interested both in the decay as well as the maximum change e.g. if gradient between 0.1 to 0.2, still ok\n",
    "# Create a dic that tells about the status of drug decay i.e. True if drug WORKED CORRECTLY\n",
    "path = '../data/Calculate_Interactions/DrugDecay_Combined.csv'\n",
    "fp = open(path)\n",
    "fp.next()\n",
    "drug_decay = {}\n",
    "batch1_Failed = 0\n",
    "batch2_Failed = 0\n",
    "for line in fp:\n",
    "    tmp = line.strip().split(',')\n",
    "    \n",
    "    batch1_decay = float(tmp[1])\n",
    "    batch1_diff = float(tmp[2])\n",
    "    \n",
    "    batch2_decay = float(tmp[3])\n",
    "    batch2_diff = float(tmp[4])\n",
    "    \n",
    "    \n",
    "    batch1_Status = True\n",
    "    if batch1_decay >= threshold_decay and batch1_diff >= threshold_MaxDifference:\n",
    "        batch1_Status = False\n",
    "        batch1_Failed += 1\n",
    "        \n",
    "    batch2_Status = True\n",
    "    if batch2_decay >= threshold_decay and batch2_diff >= threshold_MaxDifference:\n",
    "        batch2_Status = False\n",
    "        batch2_Failed += 1\n",
    "    \n",
    "    \n",
    "    drug_decay[tmp[0]] = {'Batch1':batch1_Status,'Batch2':batch2_Status}\n",
    "fp.close()\n",
    "\n",
    "print 'Number of drugs that decayed in batch1: %d' %batch1_Failed\n",
    "print 'Number of drugs that decayed in batch2: %d' %batch2_Failed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Cell Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean number of cells in Batch1: 630.938980\n",
      "Mean number of cells in Batch1: 1717.818782\n",
      "Number of empty wells in Batch1: 1433\n",
      "Number of empty wells in Batch2: 2221\n"
     ]
    }
   ],
   "source": [
    "#Minimum cells allowed\n",
    "cutoff_min_cells = 30\n",
    "\n",
    "#per well count\n",
    "well_cell_count = {}\n",
    "\n",
    "#number of wells below cutoff_min_cells\n",
    "empty_well = 0\n",
    "\n",
    "#go through CellCount file to find wells with too little cells\n",
    "path = '../data/Calculate_Interactions/All_CellCounts_Combined.csv'\n",
    "fp = open(path)\n",
    "fp.next()\n",
    "for line in fp:\n",
    "    tmp = line.strip().split(',')\n",
    "    num_cells = float(tmp[4])\n",
    "    well_cell_count[tmp[0]+','+tmp[1]+','+tmp[2]+','+tmp[3]] = {'Number':num_cells,'Worked':tmp[5]}\n",
    "    \n",
    "#Mean number of cells (DMSO and Perturbations)\n",
    "print 'Mean number of cells in Batch1: %f'  %np.mean([well_cell_count[x]['Number'] for x in well_cell_count if int(x.split(',')[2]) < 1315065])\n",
    "print 'Mean number of cells in Batch1: %f'  %np.mean([well_cell_count[x]['Number'] for x in well_cell_count if int(x.split(',')[2]) >= 1315065])\n",
    "\n",
    "#Number of empty wells (DMSO and Perturbations)\n",
    "print 'Number of empty wells in Batch1: %d'  %len([well_cell_count[x]['Number'] for x in well_cell_count if int(x.split(',')[2]) < 1315065 and well_cell_count[x]['Number'] < cutoff_min_cells])\n",
    "print 'Number of empty wells in Batch2: %d'  %len([well_cell_count[x]['Number'] for x in well_cell_count if int(x.split(',')[2]) >= 1315065 and well_cell_count[x]['Number'] < cutoff_min_cells])\n",
    "\n",
    "#Get the 90 percentile of DMSO cellcount\n",
    "DMSO_CellCount = {}\n",
    "DMSO_CellCount['Batch1']= np.percentile([well_cell_count[x]['Number'] for x in well_cell_count if int(x.split(',')[2]) < 1315065 and x.split(',')[0] == 'DMSO'],90)\n",
    "DMSO_CellCount['Batch2']= np.percentile([well_cell_count[x]['Number'] for x in well_cell_count if int(x.split(',')[2]) >= 1315065 and x.split(',')[0] == 'DMSO'],90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Easy Outlier detection\n",
    "def reject_outliers_2(data, m=6.):\n",
    "    d = np.abs(data - np.median(data))\n",
    "    mdev = np.median(d)\n",
    "    s = d / (mdev if mdev else 1.)\n",
    "    return s < m\n",
    "    #return [data[i] for i in range(0, len(data)) if s[i] < m]\n",
    "\n",
    "    \n",
    "\n",
    "def Create_Single_Drug_Vectors():\n",
    "    '''\n",
    "    Extracts the individual drug perturbation vectors (for the two batches separate).\n",
    "    Outliers e.g. one replicate that is too different from the remaining 5/6 will be removed.\n",
    "    \n",
    "    Only calculated for significant singles\n",
    "    '''\n",
    "    \n",
    "    drug_vectors = {'Batch1':{},'Batch2':{}}\n",
    "    for cloud in All_CLOUDs:\n",
    "        for b in ['Batch1','Batch2']:    \n",
    "\n",
    "\n",
    "            drug_wells = [x for x in drug_perturbation_vectors[b] if cloud+',DMSO' in x and well_cell_count[x]['Number'] > cutoff_min_cells]\n",
    "\n",
    "           \n",
    "            if len(drug_wells) < 3:\n",
    "                drug_vectors[b][cloud] = {}\n",
    "            else:\n",
    "                drug_well_values = []\n",
    "                for well in drug_wells:\n",
    "                    drug_well_values.append(drug_perturbation_vectors[b][well])\n",
    "\n",
    "                drug_well_values = np.array(drug_well_values)\n",
    "\n",
    "                drug_EucledianDistances = []\n",
    "                drug_names = []\n",
    "                drug_values = []\n",
    "                for s1_a,label_a in zip(drug_well_values,drug_wells):\n",
    "                    tmp = []\n",
    "                    for s1_b,label_b in zip(drug_well_values,drug_wells):\n",
    "                        sim = np.linalg.norm(s1_a - s1_b) \n",
    "                        tmp.append(sim)\n",
    "\n",
    "                    drug_EucledianDistances.append(np.mean(tmp))\n",
    "                    drug_names.append(label_a)\n",
    "                    drug_values.append(s1_a)\n",
    "\n",
    "                \n",
    "               \n",
    "                good_rows = reject_outliers_2(drug_EucledianDistances)\n",
    "                keep_values = [drug_values[x] for x in range(0,len(drug_values)) if good_rows[x]]\n",
    "                keep_names = [drug_names[x] for x in range(0,len(drug_names)) if good_rows[x]]\n",
    "\n",
    "                drug_vectors[b][cloud] = {}\n",
    "                for val, lab in zip(keep_values,keep_names):\n",
    "                    drug_vectors[b][cloud][lab] = val\n",
    "\n",
    "    return drug_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create a dictionary for all single drugs, and remove obvious outliers\n",
    "Outliers are detected by first calculating the mean eucledian distance of a point to all other points and then performing an MAD outlier detection\n",
    "'''\n",
    "drug_vectors_WithoutOutliers = Create_Single_Drug_Vectors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check which Drugs should be removed from analysis  (too few cells, transfer problems etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drugs to remove:\n",
      "{'Batch2': ['CLOUD080', 'CLOUD180', 'CLOUD197'], 'Batch1': ['CLOUD065', 'CLOUD083', 'CLOUD120', 'CLOUD139', 'CLOUD205', 'CLOUD243']}\n",
      "Cytotoxic drugs/non usable morphological features:\n",
      "{'Batch2': ['CLOUD024', 'CLOUD152', 'CLOUD193'], 'Batch1': ['CLOUD024', 'CLOUD179', 'CLOUD193']}\n"
     ]
    }
   ],
   "source": [
    "#list of drugs that kill too many cells to do morphological analysis with them (Remove only for Morphology Analysis)\n",
    "killing_drugs = {'Batch1':[],'Batch2':[]}\n",
    "\n",
    "#this drugs must be removed from further analysis (Both the CellCount and Morphology Analysis)\n",
    "drugs_to_remove = {'Batch1':[],'Batch2':[]}\n",
    "\n",
    "for cloud in All_CLOUDs:\n",
    "    for b in ['Batch1','Batch2']:\n",
    "        \n",
    "        #Check if enough replicates exist\n",
    "        enough_replicates_status = len(drug_vectors_WithoutOutliers[b][cloud]) >= 3\n",
    "        \n",
    "        #Get result from drug decay analayis\n",
    "        drug_decay_status = drug_decay[cloud][b]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #Check if both are good\n",
    "        if enough_replicates_status and drug_decay_status:\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            continue\n",
    "        else:\n",
    "            #print 'Bad Drug (%s): %s    Decay?: %s' %(b,cloud, str(not drug_decay_status))\n",
    "          \n",
    "            \n",
    "            #if the drug does not decay and has enough working wells not image problems, you can use it still for CellCount Anlaysis (again if at least 3 wells)\n",
    "            if drug_decay_status:\n",
    "                number_replicates = len([x for x in drug_perturbation_vectors[b] if cloud+',DMSO' in x])\n",
    "                \n",
    "                #print b\n",
    "                #print cloud\n",
    "                #print drug_decay_status\n",
    "                #print number_replicates\n",
    "                \n",
    "                if number_replicates >= 3:\n",
    "                    #print '==> can be used a \"killing drug\"'\n",
    "                    killing_drugs[b].append(cloud)\n",
    "                else:\n",
    "                    drugs_to_remove[b].append(cloud)\n",
    "            else:\n",
    "                drugs_to_remove[b].append(cloud)\n",
    "\n",
    "print 'Drugs to remove:'\n",
    "print drugs_to_remove\n",
    "\n",
    "print 'Cytotoxic drugs/non usable morphological features:'\n",
    "print killing_drugs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check which single Drugs are significantly morphologically changed\n",
    "Compared to DMSO random cell intrinsic morphological fluctuation (compare via Mahalanobis distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_Random_Distribution_DMSO(DMSO_Wells,num_pseudo_treatments=4):\n",
    "    #Fit a PCA\n",
    "    pca = PCA()\n",
    "    pca.fit(DMSO_Wells)\n",
    "\n",
    "    #Take only as many principel components so taht 90% of the variance can be explained\n",
    "    variances = pca.explained_variance_ratio_\n",
    "    total = 0\n",
    "    use_components = 0\n",
    "    for v in variances:\n",
    "        total = total + v\n",
    "        use_components += 1\n",
    "        if total > 0.9:\n",
    "            break\n",
    "\n",
    "    #Use at least 2 components\n",
    "    if use_components <= 1:\n",
    "        use_components = 2\n",
    "    \n",
    "    #Fit the space to the selected amount of components and transform the data\n",
    "    pca = PCA(n_components=use_components)\n",
    "    pca.fit(DMSO_Wells)\n",
    "    transformedX = pca.transform(DMSO_Wells)\n",
    "    weightedPCA = np.multiply(transformedX, pca.explained_variance_ratio_)\n",
    "    \n",
    "    all_mahala_distances = []\n",
    "    for i in range(0, 10000):\n",
    "        np.random.shuffle(weightedPCA)\n",
    "\n",
    "        treatments = weightedPCA[0:num_pseudo_treatments]\n",
    "        control = weightedPCA[num_pseudo_treatments:]\n",
    "\n",
    "        x = []\n",
    "        for i in range(0, use_components):\n",
    "            x.append(np.mean(treatments[:, i]))\n",
    "\n",
    "        u = []\n",
    "        for i in range(0, use_components):\n",
    "            u.append(np.mean(control[:, i]))\n",
    "\n",
    "        covariance_treatment = np.cov(treatments, rowvar=0)\n",
    "        covariance_control = np.cov(control, rowvar=0)\n",
    "\n",
    "        weighted_covariance_treatment = covariance_treatment * (float(len(treatments)) / (len(treatments) + len(control)))\n",
    "        weighted_covariance_control = covariance_control * (float(len(control)) / (len(treatments) + len(control)))\n",
    "\n",
    "        S = weighted_covariance_treatment + weighted_covariance_control\n",
    "\n",
    "        S = np.cov(weightedPCA, rowvar=0)\n",
    "\n",
    "        x = np.array(x)\n",
    "        u = np.array(u)\n",
    "        distance_rand = mahalanobis(x, u, np.linalg.inv(S))\n",
    "        all_mahala_distances.append(distance_rand)\n",
    "    \n",
    "    \n",
    "    return all_mahala_distances\n",
    "    \n",
    "if os.path.isfile('../results/Calculate_Interactions/RandomMahalanobisDistances_DMSO.pickle'):\n",
    "    pickle_in = open('../results/Calculate_Interactions/RandomMahalanobisDistances_DMSO.pickle',\"rb\")\n",
    "    Mahalanobis_Random_Distribution = pickle.load(pickle_in)\n",
    "else:\n",
    "    #Create Random Mahalanobis distributions for k = 1, 3,4,5,6,7 (1 = combination, 3-7 singles)\n",
    "    Mahalanobis_Random_Distribution = {'Batch1':{},'Batch2':{}}\n",
    "    for i in range(3,8):\n",
    "        Mahalanobis_Random_Distribution['Batch1'][i] = make_Random_Distribution_DMSO(dmso['Batch1'],i)\n",
    "    Mahalanobis_Random_Distribution['Batch1'][1] = make_Random_Distribution_DMSO(dmso['Batch1'],1)\n",
    "    print 'Finished Batch1 Random Distribution'\n",
    "    for i in range(3,8):\n",
    "        Mahalanobis_Random_Distribution['Batch2'][i] = make_Random_Distribution_DMSO(dmso['Batch2'],i)\n",
    "    Mahalanobis_Random_Distribution['Batch2'][1] = make_Random_Distribution_DMSO(dmso['Batch2'],1)\n",
    "    print 'Finished Batch2 Random Distribution'\n",
    "\n",
    "    pickle_out = open('../results/Calculate_Interactions/RandomMahalanobisDistances_DMSO.pickle',\"wb\")\n",
    "    pickle.dump(Mahalanobis_Random_Distribution, pickle_out)\n",
    "    pickle_out.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calculate_MahalanobisDistance(k,numberTreatment,number_of_RandomTries=10000, usePreComputedRandomDistribution = True, batch = None):\n",
    "    '''\n",
    "    This function takes a list of feature vectors, sorted with the first n (numberTreatment) belong to group A and the afterwards to group B.\n",
    "    1.) First the dimension of the feature vectors is reduced using PCA\n",
    "    2.) Only the m PCA dimensions are used so taht at least 90% of all variance is explained\n",
    "    3.) The indivudal dimensions are weighted by their importance\n",
    "    4.) Create the Mean Vector for the two grups (mean over columns)\n",
    "    5.) Calculate the Mahalanobis distance\n",
    "    6.) Calculate an empirical PValue by randomly permuting the labels of the groups and creating a random expected mahalanobis distance distribution; compare real mahalanobis distance\n",
    "        to this randomly drawn distribution to calulate a p value (basically: NumberOfRandomDrawn MahalanobisDistance larger than real / number of random Mahalanobis Distances)\n",
    "    '''\n",
    "    #Fit a PCA\n",
    "    pca = PCA()\n",
    "    pca.fit(k)\n",
    "\n",
    "    #Take only as many principel components so taht 90% of the variance can be explained\n",
    "    variances = pca.explained_variance_ratio_\n",
    "    \n",
    "    total = 0\n",
    "    use_components = 0\n",
    "    for v in variances:\n",
    "        total = total + v\n",
    "        use_components += 1\n",
    "        if total > 0.9:\n",
    "            break\n",
    "\n",
    "    #Use at least 2 components\n",
    "    if use_components <= 1:\n",
    "        use_components = 2\n",
    "    \n",
    "\n",
    "    \n",
    "    #Fit the space to the selected amount of components and transform the data\n",
    "    pca = PCA(n_components=use_components)\n",
    "    pca.fit(k)\n",
    "    transformedX = pca.transform(k)\n",
    "\n",
    "    #weight the dimensions regarding the amount of variance explained\n",
    "    weightedPCA = np.multiply(transformedX, pca.explained_variance_ratio_)\n",
    "\n",
    "    \n",
    "    pca1 = list(weightedPCA[:, 0])\n",
    "    pca2 = list(weightedPCA[:, 1])\n",
    "    \n",
    "    #split the list into the two groups (treated/untreated)\n",
    "    treatments = weightedPCA[0:numberTreatment]\n",
    "    control = weightedPCA[numberTreatment:]\n",
    "    \n",
    "    \n",
    "    #Contains the main treatment vector (Calculate mean vector - Over Columns)\n",
    "    x = []\n",
    "    for i in range(0, use_components):\n",
    "        x.append(np.mean(treatments[:, i]))\n",
    "\n",
    "    #Contains the mean untreated vector (Calculate mean vector - Over Columns)\n",
    "    u = []\n",
    "    for i in range(0, use_components):\n",
    "        u.append(np.mean(control[:, i]))\n",
    "\n",
    "    \n",
    "        \n",
    "    #Create the covariance matrix, as well as the groupA (treatment) mean vector and\n",
    "    # groupB (untreated) mean vector to finally calucate the mahalanobis distance between this two groups\n",
    "    S = np.cov(weightedPCA, rowvar=0)\n",
    "    x = np.array(x)\n",
    "    u = np.array(u)\n",
    "\n",
    "    \n",
    "    #Calculate the Mahalanobis distance between treated and untreated\n",
    "    distance_calc = mahalanobis(x, u, np.linalg.inv(S))\n",
    "\n",
    "    #original = weightedPCA.copy()\n",
    "    treatment_row = weightedPCA[0:numberTreatment].copy()\n",
    "\n",
    "    \n",
    "    if usePreComputedRandomDistribution == True:\n",
    "        all_mahala_distances = Mahalanobis_Random_Distribution[batch][numberTreatment]\n",
    "    else:\n",
    "        all_mahala_distances = []\n",
    "        for i in range(0, number_of_RandomTries):\n",
    "            np.random.shuffle(weightedPCA)\n",
    "\n",
    "\n",
    "            #if np.array_equal(original, weightedPCA):\n",
    "            if np.array_equal(treatment_row,weightedPCA[0:numberTreatment]):\n",
    "                continue\n",
    "\n",
    "            treatments = weightedPCA[0:numberTreatment]\n",
    "            control = weightedPCA[numberTreatment:]\n",
    "\n",
    "            x = []\n",
    "            for i in range(0, use_components):\n",
    "                x.append(np.mean(treatments[:, i]))\n",
    "\n",
    "            u = []\n",
    "            for i in range(0, use_components):\n",
    "                u.append(np.mean(control[:, i]))\n",
    "\n",
    "                \n",
    "            \n",
    "            covariance_treatment = np.cov(treatments, rowvar=0)\n",
    "            covariance_control = np.cov(control, rowvar=0)\n",
    "\n",
    "            weighted_covariance_treatment = covariance_treatment * (float(len(treatments)) / (len(treatments) + len(control)))\n",
    "            weighted_covariance_control = covariance_control * (float(len(control)) / (len(treatments) + len(control)))\n",
    "\n",
    "            S = weighted_covariance_treatment + weighted_covariance_control\n",
    "\n",
    "            S = np.cov(weightedPCA, rowvar=0)\n",
    "\n",
    "            x = np.array(x)\n",
    "            u = np.array(u)\n",
    "            distance_rand = mahalanobis(x, u, np.linalg.inv(S))\n",
    "            all_mahala_distances.append(distance_rand)\n",
    "\n",
    "\n",
    "        #print len([x for x in all_mahala_distances if x >= distance_calc]) / float(len(all_mahala_distances))\n",
    "    #caluclate empirical pvalue\n",
    "    mp = len([x for x in all_mahala_distances if x >= distance_calc]) / float(len(all_mahala_distances))        \n",
    "    if mp > 1:\n",
    "        mp = 1\n",
    "\n",
    "    \n",
    "    return distance_calc, mp, pca1, pca2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load singles:\n",
      "Number of significant drugs in Batch1: 52\n",
      "Number of significant drugs in Batch2: 53\n"
     ]
    }
   ],
   "source": [
    "print \"Load singles:\"\n",
    "\n",
    "#set the perturbation significance level\n",
    "perturbaion_significance = 7\n",
    "\n",
    "#save signficance (MP_Value is deprecated)\n",
    "Single_Drug_Significance = {}\n",
    "\n",
    "#If this file already exists it doesn't need to be calculated again (if you wish to recalculate it you need to delete it first)\n",
    "if os.path.isfile('../results/Calculate_Interactions/Singles/Overview.csv'):\n",
    "    fp = open('../results/Calculate_Interactions/Singles/Overview.csv','r')\n",
    "    fp.next()\n",
    "    for line in fp:\n",
    "        tmp = line.strip().split(',')\n",
    "        Single_Drug_Significance[tmp[0]] = {'Batch1':{},'Batch2':{}}\n",
    "        \n",
    "        if tmp[1] == 'No_Cells':\n",
    "            Single_Drug_Significance[tmp[0]]['Batch1']['Mahalanobis_Distance'] = 'Nan'\n",
    "            Single_Drug_Significance[tmp[0]]['Batch1']['MP_Value'] = 'Nan'\n",
    "        else:\n",
    "            Single_Drug_Significance[tmp[0]]['Batch1']['Mahalanobis_Distance'] = float(tmp[1])\n",
    "            Single_Drug_Significance[tmp[0]]['Batch1']['MP_Value'] = float(tmp[2])\n",
    "            \n",
    "        if tmp[3] == 'No_Cells':\n",
    "            Single_Drug_Significance[tmp[0]]['Batch2']['Mahalanobis_Distance'] = 'Nan'\n",
    "            Single_Drug_Significance[tmp[0]]['Batch2']['MP_Value'] = 'Nan'\n",
    "        else:\n",
    "            Single_Drug_Significance[tmp[0]]['Batch2']['Mahalanobis_Distance'] = float(tmp[3])\n",
    "            Single_Drug_Significance[tmp[0]]['Batch2']['MP_Value'] = float(tmp[4])\n",
    "            \n",
    "else:\n",
    "    #Go through all clouds\n",
    "    for cloud in all_all_clouds:\n",
    "        #cloud = 'CLOUD031'\n",
    "        Single_Drug_Significance[cloud] = {}\n",
    "        #calculate the significance for both batches separately\n",
    "        for b in ['Batch1','Batch2']:\n",
    "\n",
    "            #Create a list with Treatments (drug vectors) and DMSO; Including only those perturbations that have enough cells\n",
    "            \n",
    "            #Get the single perturbations\n",
    "            \n",
    "            if drug_vectors_WithoutOutliers[b].has_key(cloud):\n",
    "                k = drug_vectors_WithoutOutliers[b][cloud].values()\n",
    "                numberTreatment = len(k)\n",
    "            else:\n",
    "                numberTreatment = 0\n",
    "            \n",
    "            \n",
    "            #Only perform an analysis if at least 3 replicates exist\n",
    "            if numberTreatment < 3 or cloud in drugs_to_remove[b] or cloud in killing_drugs[b]:\n",
    "                Single_Drug_Significance[cloud][b] = {'Mahalanobis_Distance':'LessThanThreeWells','MP_Value':'LessThanThreeWells'}\n",
    "            elif cloud in killing_drugs[b]:\n",
    "                Single_Drug_Significance[cloud][b] = {'Mahalanobis_Distance':'TooFewCells','MP_Value':'TooFewCells'}\n",
    "            elif cloud in drugs_to_remove[b]:\n",
    "                Single_Drug_Significance[cloud][b] = {'Mahalanobis_Distance':'DrugDecay','MP_Value':'DrugDecay'}\n",
    "            else:\n",
    "                #if enough replicates, add the DMSO wells to the list\n",
    "                k.extend(dmso[b])\n",
    "\n",
    "                #Calculate the mahalanobis distance as well as empirical pValue.\n",
    "                distance_calc, mp, pca1, pca2 = Calculate_MahalanobisDistance(k,numberTreatment,usePreComputedRandomDistribution=True,batch=b)\n",
    "                \n",
    "\n",
    "                '''\n",
    "                PLOT RESULTS\n",
    "                '''\n",
    "                if distance_calc >  perturbaion_significance:\n",
    "                    color = ['#b2182b']*numberTreatment\n",
    "                else:\n",
    "                     color = ['#2166ac']*numberTreatment\n",
    "\n",
    "                for i in range(1,len(k)):\n",
    "                    color.append('grey')\n",
    "\n",
    "                Single_Drug_Significance[cloud][b] = {'Mahalanobis_Distance':distance_calc,'MP_Value':mp}\n",
    "\n",
    "                plt.scatter(pca1[numberTreatment:], pca2[numberTreatment:], c=color[numberTreatment:], alpha=0.4)\n",
    "                plt.scatter(pca1[0:numberTreatment], pca2[0:numberTreatment], c=color[0:numberTreatment], alpha=0.4)\n",
    "                plt.legend(['DMSO','Mahalanobis Distance: %.2f\\nn = %d' % (distance_calc,numberTreatment)])\n",
    "                #plt.show()\n",
    "                plt.savefig('../results/Calculate_Interactions/Singles/'+cloud+'_'+b+'.pdf')\n",
    "                plt.close()\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    WRITE OUTPUT\n",
    "    '''\n",
    "    fp_out = open('../results/Calculate_Interactions/Singles/Overview.csv','w')\n",
    "    fp_out.write('Drug,Batch1_Mahalanobis_Distance,Batch1_MP_Value,Batch2_Mahalanobis_Distance,Batch2_MP_Value\\n')\n",
    "    for cloud in all_all_clouds:\n",
    "        fp_out.write(cloud+','+str(Single_Drug_Significance[cloud]['Batch1']['Mahalanobis_Distance'])+','+str(Single_Drug_Significance[cloud]['Batch1']['MP_Value'])+','+str(Single_Drug_Significance[cloud]['Batch2']['Mahalanobis_Distance'])+','+str(Single_Drug_Significance[cloud]['Batch2']['MP_Value'])+'\\n')\n",
    "    fp_out.close()\n",
    "\n",
    "\n",
    "#print Single_Drug_Significance\n",
    "\n",
    "print 'Number of significant drugs in Batch1: %d' %len([x for x in Single_Drug_Significance if Single_Drug_Significance[x]['Batch1']['Mahalanobis_Distance'] > perturbaion_significance and Single_Drug_Significance[x]['Batch2']['Mahalanobis_Distance']  != 'Nan'])\n",
    "print 'Number of significant drugs in Batch2: %d' %len([x for x in Single_Drug_Significance if Single_Drug_Significance[x]['Batch2']['Mahalanobis_Distance'] > perturbaion_significance and Single_Drug_Significance[x]['Batch2']['Mahalanobis_Distance']  != 'Nan'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.450762686561788, 16.54525660028954, 8.46337435971235, 9.966083909578147, 16.71683996723075, 17.949952458350126, 16.34606329868819, 17.924881748022706, 17.479500343940355, 7.3350116915840164, 8.33341812730868, 16.742875738627355, 13.328909404307346, 18.377966016521892, 17.24857939018964, 16.605955224734267, 17.106955801763682, 8.495399436663076, 15.364717984010674, 11.399561552960712, 7.275186742383035, 7.104791491812883, 10.04720368886666, 13.121110658796146, 9.12686350490176, 11.428307981590214, 15.420142017670113, 13.946862839659515, 9.895147480594584, 7.3477998231898844, 10.277410877786721, 16.485727635103935, 7.1824785720940705, 15.622423453575058]\n",
      "Number at least once significant: 34\n",
      "Number never  significant: 220\n"
     ]
    }
   ],
   "source": [
    "#Make a distribution over all perturbations; use mean over both batches\n",
    "mahalanobis_distances = []\n",
    "for cloud in All_CLOUDs:\n",
    "    \n",
    "    values = []\n",
    "    if Single_Drug_Significance[cloud]['Batch1']['Mahalanobis_Distance'] != 'No_Cells' and Single_Drug_Significance[cloud]['Batch1']['Mahalanobis_Distance'] != 'Nan':\n",
    "        values.append(Single_Drug_Significance[cloud]['Batch1']['Mahalanobis_Distance'])\n",
    "    if Single_Drug_Significance[cloud]['Batch2']['Mahalanobis_Distance'] != 'No_Cells'  and Single_Drug_Significance[cloud]['Batch2']['Mahalanobis_Distance'] != 'Nan':\n",
    "        values.append(Single_Drug_Significance[cloud]['Batch2']['Mahalanobis_Distance'])\n",
    "    \n",
    "    if len(values) > 0:\n",
    "        mahalanobis_distances.append(max(values))\n",
    "\n",
    "\n",
    "print [x for x in mahalanobis_distances if x > 7]\n",
    "print 'Number at least once significant: %d' %len([x for x in mahalanobis_distances if x > 7])\n",
    "print 'Number never  significant: %d' %len([x for x in mahalanobis_distances if x <= 7])\n",
    "plt.hist(mahalanobis_distances,bins=15, color='#40B9D4')\n",
    "plt.axvline(7, color='grey', ls='--')\n",
    "#plt.show()\n",
    "plt.savefig('../results/Calculate_Interactions/Singles/Overview_Histogram.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dictionary of DMSO wells after a (MAD=2) outlier detection; these will serve as random intracellular fluctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmso_wells_Outlier_Removed = {'Batch1':{},'Batch2':{}}\n",
    "\n",
    "#Go through both batches\n",
    "for b in ['Batch1','Batch2']:\n",
    "    #get all plates of this batch\n",
    "    plates = list(set([x.split(',')[2] for x in drug_perturbation_vectors[b].keys()]))\n",
    "    #go through all plates\n",
    "    for plate in plates:\n",
    "        \n",
    "        #Get corresponding DMSO wells of this plate\n",
    "        DMSO_Wells  = [drug_perturbation_vectors[b][x] for x in drug_perturbation_vectors[b] if 'DMSO,None,'+str(plate) in x and well_cell_count[x]['Number'] > cutoff_min_cells]\n",
    "        DMSO_Wells = np.array(DMSO_Wells)\n",
    "        \n",
    "        #Perform outlier detection\n",
    "        DMSO_EucledianDistances = []\n",
    "        DMSO_values = []\n",
    "        for s1_a in DMSO_Wells:\n",
    "            tmp = []\n",
    "            for s1_b in DMSO_Wells:\n",
    "                sim = np.linalg.norm(s1_a - s1_b) \n",
    "                tmp.append(sim)\n",
    "\n",
    "            DMSO_EucledianDistances.append(np.mean(tmp))\n",
    "            DMSO_values.append(s1_a)\n",
    "        \n",
    "        #Perform actual MAD outlier detection with MAD = 10\n",
    "        good_rows = reject_outliers_2(DMSO_EucledianDistances,2)\n",
    "        keep_values = [DMSO_values[x] for x in range(0,len(DMSO_values)) if good_rows[x]]\n",
    "        \n",
    "        #Add result\n",
    "        dmso_wells_Outlier_Removed[b][plate] = keep_values\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actual Math for calculating the DDIs\n",
    "def unit_vector(vector):\n",
    "    \"\"\" Returns the unit vector of the vector.  \"\"\"\n",
    "    return vector / np.linalg.norm(vector)\n",
    "def angle_between(v1, v2):\n",
    "    \"\"\" Returns the angle in radians between vectors 'v1' and 'v2'::\n",
    "\n",
    "            angle_between((1, 0, 0), (0, 1, 0))\n",
    "            1.5707963267948966\n",
    "            angle_between((1, 0, 0), (1, 0, 0))\n",
    "            0.0\n",
    "            angle_between((1, 0, 0), (-1, 0, 0))\n",
    "            3.141592653589793\n",
    "    \"\"\"\n",
    "    v1_u = unit_vector(v1)\n",
    "    v2_u = unit_vector(v2)\n",
    "    return np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0))\n",
    "def calculate_vector_math_v2(a, b, c):\n",
    "    '''\n",
    "    calculate the amount of single a, single b, and the 'surprise factor)\n",
    "    :param a: vector a (single)\n",
    "    :param b: vector b (single)\n",
    "    :param c: vector c (combination)\n",
    "    :return: alpha, beta and gamma (part of vector a, b and suprise)\n",
    "    '''\n",
    "\n",
    "    if sum(a) != 0 and sum(b) != 0:\n",
    "\n",
    "        \n",
    "        if angle_between(a,b) <= 0.5:\n",
    "            #h = c/(a+b)\n",
    "\n",
    "            A=  np.array([[np.dot(a, a), np.dot(a, b)], [np.dot(a, b), np.dot(b, b)]])\n",
    "            h = np.array([np.dot(a, c), np.dot(b, c)])\n",
    "\n",
    "            alpha =  h[0]/(A[0][0]+A[1][0])\n",
    "            beta = h[1] / (A[0][1]+A[1][1])\n",
    "\n",
    "            n =alpha * a + beta * b - c\n",
    "\n",
    "            gamma = np.linalg.norm(n)\n",
    "            return str(alpha),str(beta),str(gamma)\n",
    "\n",
    "        elif angle_between(a,b) == 3.141592653589793:\n",
    "            A = np.array([[np.dot(a, a), np.dot(a, b)], [np.dot(a, b), np.dot(b, b)]])\n",
    "            h = np.array([np.dot(a, c), np.dot(b, c)])\n",
    "\n",
    "\n",
    "            alpha = h[0] / (A[0][0] + abs(A[1][0]))\n",
    "            beta = h[1] / (abs(A[0][1]) + A[1][1])\n",
    "\n",
    "            n = alpha * a + beta * b - c\n",
    "\n",
    "            gamma = np.linalg.norm(n)\n",
    "\n",
    "            return str(alpha), str(beta), str(gamma)\n",
    "\n",
    "    try:\n",
    "\n",
    "        \n",
    "        if sum(c) != 0 and sum(a) == 0 and sum(b) == 0:\n",
    "            return '1','1',str(dis.euclidean([0]*len(c),c))\n",
    "        elif sum(c) == 0 and sum(a) == 0 and sum(b) == 0:\n",
    "            return '1','1','0'\n",
    "        elif sum(c) == 0 and sum(a) == 0:\n",
    "            return '1','0','0'\n",
    "        elif sum(c) == 0 and sum(b) == 0:\n",
    "            return '0','1','0'\n",
    "\n",
    "        else:\n",
    "            \n",
    "            # Matrix equation\n",
    "            A = np.array([[np.dot(a, a), np.dot(a, b)], [np.dot(a, b), np.dot(b, b)]])\n",
    "\n",
    "            h = np.array([np.dot(a, c), np.dot(b, c)])\n",
    "\n",
    "            \n",
    "            if A[0][0]==0 and h[0] ==0: #one vector zero, so combination can be only 1dim\n",
    "\n",
    "                beta = h[1]/A[1][1]\n",
    "                n = beta * b -c\n",
    "                gamma = np.linalg.norm(n)\n",
    "\n",
    "                if  (len(list(b)) - list(b).count(0) > 2) or np.linalg.norm(b) > 0.5:\n",
    "                    return '1.0',str(beta),str(gamma)\n",
    "                else:\n",
    "                    return '1', '1', str(dis.euclidean([0] * len(c), c))\n",
    "            elif A[1][1]==0 and h[1] ==0:\n",
    "                alpha = h[0]/A[0][0]\n",
    "                n = alpha * a -c\n",
    "                gamma = np.linalg.norm(n)\n",
    "\n",
    "\n",
    "                if len(list(a)) - list(a).count(0) > 2 or np.linalg.norm(a) > 0.5:\n",
    "                    return str(alpha),'1',str(gamma)\n",
    "                else:\n",
    "                    return '1', '1', str(dis.euclidean([0] * len(c), c))\n",
    "            elif h[0] == 0 and h[1] == 0:\n",
    "                gamma = np.linalg.norm(c)\n",
    "                return '0.0','0.0',str(gamma)\n",
    "            elif A[0][0] != 0 and h[0] == 0 and h[1] == 0:\n",
    "                gamma = np.linalg.norm(c)\n",
    "                return '0.0','1.0',str(gamma)\n",
    "            elif A[1][1] != 0 and h[0] == 0 and h[1] == 0:\n",
    "                gamma = np.linalg.norm(c)\n",
    "                return '1.0','0',str(gamma)\n",
    "\n",
    "            p = np.linalg.solve(A, h)\n",
    "            # orthogonal vector\n",
    "            n = p[0] * a + p[1] * b - c\n",
    "\n",
    "            distance = np.linalg.norm(n)\n",
    "            # check\n",
    "            # print('dot product of a and c: %.4f' %(np.dot(a,n)))\n",
    "            # print('dot product of b and c: %.4f' %(np.dot(b,n)))\n",
    "            # print('distance: %.3f' %(distance))\n",
    "            return str(p[0]), str(p[1]), str(distance)\n",
    "    except:\n",
    "        return 'Error', 'Error', 'Error'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate possible interactions for all pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLOUD001\n",
      "CLOUD002\n",
      "CLOUD003\n",
      "CLOUD004\n",
      "CLOUD005\n",
      "CLOUD006\n",
      "CLOUD007\n",
      "CLOUD008\n",
      "CLOUD009\n",
      "CLOUD010\n",
      "CLOUD011\n",
      "CLOUD012\n",
      "CLOUD013\n",
      "CLOUD014\n",
      "CLOUD015\n",
      "CLOUD016\n",
      "CLOUD017\n",
      "CLOUD018\n",
      "CLOUD019\n",
      "CLOUD020\n",
      "CLOUD021\n",
      "CLOUD022\n",
      "CLOUD023\n",
      "CLOUD024\n",
      "CLOUD025\n",
      "CLOUD026\n",
      "CLOUD027\n",
      "CLOUD028\n",
      "CLOUD029\n",
      "CLOUD030\n",
      "CLOUD031\n",
      "CLOUD032\n",
      "CLOUD033\n",
      "CLOUD034\n",
      "CLOUD035\n",
      "CLOUD036\n",
      "CLOUD037\n",
      "CLOUD038\n",
      "CLOUD039\n",
      "CLOUD040\n",
      "CLOUD041\n",
      "CLOUD042\n",
      "CLOUD043\n",
      "CLOUD044\n",
      "CLOUD045\n",
      "CLOUD046\n",
      "CLOUD047\n",
      "CLOUD048\n",
      "CLOUD049\n",
      "CLOUD050\n",
      "CLOUD051\n",
      "CLOUD052\n",
      "CLOUD053\n",
      "CLOUD054\n",
      "CLOUD055\n",
      "CLOUD056\n",
      "CLOUD057\n",
      "CLOUD058\n",
      "CLOUD059\n",
      "CLOUD060\n",
      "CLOUD061\n",
      "CLOUD062\n",
      "CLOUD063\n",
      "CLOUD064\n",
      "CLOUD065\n",
      "CLOUD066\n",
      "CLOUD067\n",
      "CLOUD068\n",
      "CLOUD069\n",
      "CLOUD070\n",
      "CLOUD071\n",
      "CLOUD072\n",
      "CLOUD073\n",
      "CLOUD074\n",
      "CLOUD075\n",
      "CLOUD076\n",
      "CLOUD077\n",
      "CLOUD078\n",
      "CLOUD079\n",
      "CLOUD080\n",
      "CLOUD081\n",
      "CLOUD082\n",
      "CLOUD083\n",
      "CLOUD084\n",
      "CLOUD085\n",
      "CLOUD086\n",
      "CLOUD087\n",
      "CLOUD088\n",
      "CLOUD089\n",
      "CLOUD090\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-5c2dbefff4ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    301\u001b[0m                 \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcombi_Vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                 \u001b[0;31m#Here 500 random tries is already enough since only ca. 250 datapoints in 'possible' results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m                 \u001b[0mcombination_distance_calc_toNI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombination_mp_toNI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCalculate_MahalanobisDistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumberTreatment\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumber_of_RandomTries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musePreComputedRandomDistribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-50-4fa0d12e2932>\u001b[0m in \u001b[0;36mCalculate_MahalanobisDistance\u001b[0;34m(k, numberTreatment, number_of_RandomTries, usePreComputedRandomDistribution, batch)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mall_mahala_distances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_RandomTries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweightedPCA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#BLISS RESULT FILE\n",
    "fp_out = open('../results/Calculate_Interactions/Bliss_Scores_Cytotoxicity.csv','w')\n",
    "fp_out.write('Drug1,Drug2,Batch,Plate,Well,S1,S2,C,Expected,Difference\\n')\n",
    "\n",
    "#MC RESULT FILE - Menche-Caldera Score\n",
    "fp_out2 = open('../results/Calculate_Interactions/MC_Scores.csv','w')\n",
    "fp_out2.write('Drug1,Drug2,Batch,Plate,Well,S1_Mahalanobis,S1_MPValue,S1_Norm,S2_Mahalanobis,S2_MPValue,S2_Norm,Combi_Mahalanobis,Combi_MPValue,Combi_Norm_Norm,Alpha,Beta,Gamma,Alpha_Zero,Beta_Zero,Gamma_Zero,Mahalanobis_Distance_To_NI,MPValue_To_NI\\n')\n",
    "\n",
    "\n",
    "#Results of the combination significances\n",
    "Combination_Drug_Significance = {}\n",
    "\n",
    "#Go through all pairs\n",
    "for cloud1 in All_CLOUDs:\n",
    "    print cloud1\n",
    "    for cloud2 in All_CLOUDs:\n",
    "        if cloud1 > cloud2:\n",
    "\n",
    "            #cloud1 = 'CLOUD011'\n",
    "            #cloud2 = 'CLOUD004'\n",
    "            \n",
    "            #Get the combination well\n",
    "            combination_well =  [x for x in well_cell_count if cloud1+','+cloud2 in x or cloud2+','+cloud1 in x]\n",
    "            \n",
    "            #This should never happen\n",
    "            if len(combination_well) == 0:\n",
    "                print 'Problem!!!'\n",
    "            \n",
    "            #Extract the plate and well information\n",
    "            plate = combination_well[0].split(',')[2]\n",
    "            well = combination_well[0].split(',')[3]\n",
    "                         \n",
    "            #Extract the batch information from the plate number\n",
    "            if int(plate) < 1315065:\n",
    "                b = 'Batch1'\n",
    "            else:\n",
    "                b= 'Batch2'\n",
    "            \n",
    "            #Check if either for the two drugs are in the drugs_to_remove list ==> all this interactions must be discarded (e.g. because the drug oxidized over course of screen)\n",
    "            \n",
    "            \n",
    "            #Get the single replicates\n",
    "            single1_replicate_wells = [x for x in drug_perturbation_vectors[b] if cloud1+',DMSO' in x]\n",
    "            single2_replicate_wells = [x for x in drug_perturbation_vectors[b] if cloud2+',DMSO' in x]\n",
    "\n",
    "            #Get the Combination well cell count, and the transfer status\n",
    "            combi_Number =  well_cell_count[combination_well[0]]['Number']\n",
    "            combi_Worked =  well_cell_count[combination_well[0]]['Worked']\n",
    "            \n",
    "            #Get the singles cell counts\n",
    "            s1_cellCount = [well_cell_count[x]['Number'] for x in single1_replicate_wells if well_cell_count[x]['Worked'] == 'TRUE']\n",
    "            s2_cellCount = [well_cell_count[x]['Number'] for x in single2_replicate_wells if well_cell_count[x]['Worked'] == 'TRUE']\n",
    "            \n",
    "            \n",
    "            #print s1_cellCount\n",
    "            #print s2_cellCount\n",
    "            \n",
    "            #If there was a problem with the drug transfer ===> all this interactions must be discarded (i.e. because no drug was transfered in this well)\n",
    "            if combi_Worked == 'FALSE':\n",
    "                fp_out.write(cloud1+','+cloud2+','+str(b)+','+plate+','+well+','+','.join(['CombinationTransferProblem']*5)+'\\n')\n",
    "                fp_out2.write(cloud1+','+cloud2+','+str(b)+','+plate+','+well+','+','.join(['CombinationTransferProblem']*17)+'\\n')\n",
    "\n",
    "            else:\n",
    "                \n",
    "                '''\n",
    "                Perform CellCount Analysis:\n",
    "                Calculate Bliss Score: E (Expected)= s1 + s2 - s1*s2; S (Score) = c - E \n",
    "                The actual score is the combination cytotoxicity minus what is expected.\n",
    "                '''\n",
    "               \n",
    "                #Remove obvious outliers\n",
    "                s1_cellCount_check = reject_outliers_2(s1_cellCount)\n",
    "                s1_cellCount = [s1_cellCount[x] for x in range(0,len(s1_cellCount)) if s1_cellCount_check[x]]\n",
    "                s2_cellCount_check = reject_outliers_2(s2_cellCount)\n",
    "                s2_cellCount = [s2_cellCount[x] for x in range(0,len(s2_cellCount)) if s2_cellCount_check[x]]\n",
    "\n",
    "                \n",
    "                \n",
    "                #Calculate the s1, s2 and c cytotoxicity; If the drug wells have even more cells than the DMSO control cytotoxicity is set to 0\n",
    "                #Drug1\n",
    "                s1_cytotoxicity = (DMSO_CellCount[b] -  np.mean(s1_cellCount))/DMSO_CellCount[b]\n",
    "                #print s1_cytotoxicity\n",
    "                if s1_cytotoxicity < 0:\n",
    "                    s1_cytotoxicity = 0\n",
    "                #print s1_cytotoxicity\n",
    "                    \n",
    "                #Drug2\n",
    "                s2_cytotoxicity = (DMSO_CellCount[b] -  np.mean(s2_cellCount))/DMSO_CellCount[b]\n",
    "                #print s2_cytotoxicity\n",
    "                if s2_cytotoxicity < 0:\n",
    "                    s2_cytotoxicity = 0\n",
    "                #print s2_cytotoxicity\n",
    "                #print '--'\n",
    "                #Combination\n",
    "                comb_cytotoxicity = (DMSO_CellCount[b] -  combi_Number)/DMSO_CellCount[b]\n",
    "                if comb_cytotoxicity < 0:\n",
    "                    comb_cytotoxicity = 0\n",
    "                \n",
    "                               \n",
    "                #Calculate the expected value (E); if e.g. both drug kill all cells the sum should also be only 100% and not 200%\n",
    "                Bliss_expected = s1_cytotoxicity + s2_cytotoxicity - s1_cytotoxicity*s2_cytotoxicity\n",
    "                if Bliss_expected > 1:\n",
    "                    Bliss_expected = 1\n",
    "                                     \n",
    "                # Calculate the actual score by substracting expected value from the combination cytotoxicity.\n",
    "                # POSITIVE values indicate cytotoxic syngergy while NEGATIVE values indicate cytotoxic antagony\n",
    "                Bliss_Difference = comb_cytotoxicity - Bliss_expected\n",
    "                \n",
    "                \n",
    "                #print np.mean(s1_cellCount)\n",
    "                #print np.mean(s2_cellCount)\n",
    "                \n",
    "                #print DMSO_CellCount[b]\n",
    "                \n",
    "                #print s1_cytotoxicity\n",
    "                #print s2_cytotoxicity\n",
    "                \n",
    "                #Write results to output\n",
    "                fp_out.write(cloud1+','+cloud2+','+str(b)+','+plate+','+well+','+str(s1_cytotoxicity)+','+str(s2_cytotoxicity)+','+str(comb_cytotoxicity)+','+str(Bliss_expected)+','+str(Bliss_Difference)+'\\n')\n",
    "\n",
    "    \n",
    "    \n",
    "                #Check if one of the singles is a cytotoxic drug (i.e. has too few cells in the well) or the combination is cytotoxic\n",
    "                if cloud1 in killing_drugs[b]:\n",
    "                    fp_out2.write(cloud1+','+cloud2+','+str(b)+','+plate+','+well+','+','.join(['CytotoxicDrug1']*17)+'\\n')\n",
    "                    continue\n",
    "                if cloud2 in killing_drugs[b]:\n",
    "                    fp_out2.write(cloud1+','+cloud2+','+str(b)+','+plate+','+well+','+','.join(['CytotoxicDrug2']*17)+'\\n')\n",
    "                    continue\n",
    "                if combi_Number < cutoff_min_cells:\n",
    "                    fp_out2.write(cloud1+','+cloud2+','+str(b)+','+plate+','+well+','+','.join(['CytotoxicCombination']*17)+'\\n')\n",
    "                    continue\n",
    "                \n",
    "\n",
    "                \n",
    "                '''\n",
    "                MORPHOLOGY - MC SCORE CALCULATION\n",
    "                '''\n",
    "                    \n",
    "                    \n",
    "                #################\n",
    "                # FROM HERE actual morphology\n",
    "                # 1.) check if the two singles and/or combination are significant morphological changers\n",
    "                # 2.) depending on that calculate interactions\n",
    "                ###########\n",
    "                \n",
    "                \n",
    "                #Check if combination feature vector exist (if not there might have been a problem with the well; e.g. filtered for bad quality)\n",
    "                if drug_perturbation_vectors[b].has_key(combination_well[0]) == False:\n",
    "                    fp_out2.write(cloud1+','+cloud2+','+str(b)+','+plate+','+well+','+','.join(['ProblemWithCombinationWell']*17)+'\\n')\n",
    "                    continue\n",
    "                \n",
    "                #Get the combination vector\n",
    "                combi_Vector =  drug_perturbation_vectors[b][combination_well[0]]\n",
    "                \n",
    "               \n",
    "                k = [combi_Vector]\n",
    "                numberTreatment = len(k)\n",
    "                k.extend(dmso[b])\n",
    "\n",
    "\n",
    "                #Calculate the mahalanobis distance as well as empirical pValue.\n",
    "                combination_distance_calc, combination_mp, pca1, pca2 = Calculate_MahalanobisDistance(k,numberTreatment,usePreComputedRandomDistribution=True,batch=b)\n",
    "            \n",
    "                \n",
    "                #Calculate the vector length (=norm)\n",
    "                Combi_VectorNorm = np.linalg.norm(combi_Vector)\n",
    "            \n",
    "                #Get the significance of drug1 and drug2\n",
    "                s1_Mahalanobis = Single_Drug_Significance[cloud1][b]['Mahalanobis_Distance'] \n",
    "                s1_MValue = Single_Drug_Significance[cloud1][b]['MP_Value'] \n",
    "                s2_Mahalanobis = Single_Drug_Significance[cloud2][b]['Mahalanobis_Distance'] \n",
    "                s2_MValue = Single_Drug_Significance[cloud2][b]['MP_Value'] \n",
    "            \n",
    "            \n",
    "                ########\n",
    "                # SINGLE 1\n",
    "                #check if drug1 is significant (single1)\n",
    "                s1_significant = False\n",
    "                if s1_Mahalanobis > 7:\n",
    "                    s1_significant = True\n",
    "                s1_Vectors = drug_vectors_WithoutOutliers[b][cloud1].values()     \n",
    "\n",
    "                #Create a numpy array\n",
    "                val =  np.array(s1_Vectors)\n",
    "\n",
    "                #Transform into mean vector\n",
    "                s1_MeanVector = []\n",
    "                for i in range(0,numfeatures):\n",
    "                    s1_MeanVector.append(np.mean(val[:,i]))\n",
    "\n",
    "                #get s1 vector length (=norm)\n",
    "                s1_Mean_VectorNorm = np.linalg.norm(s1_MeanVector)\n",
    "\n",
    "\n",
    "\n",
    "                ########\n",
    "                # SINGLE 2\n",
    "                #check if drug2 is significant (single2)\n",
    "                s2_significant = False\n",
    "                if  s2_Mahalanobis > 7:\n",
    "                    s2_significant = True\n",
    "                s2_Vectors = drug_vectors_WithoutOutliers[b][cloud2].values()    \n",
    "\n",
    "                #Create a numpy array\n",
    "                val =  np.array(s2_Vectors)\n",
    "\n",
    "                #Transform into mean vector\n",
    "                s2_MeanVector = []\n",
    "                for i in range(0,numfeatures):\n",
    "                    s2_MeanVector.append(np.mean(val[:,i]))\n",
    "\n",
    "                #get s2 vector length (=norm)\n",
    "                s2_Mean_VectorNorm = np.linalg.norm(s2_MeanVector)\n",
    "\n",
    "                ########\n",
    "                # Combination\n",
    "                #check if combination is significant; no need to create a mean vector as only one replicate\n",
    "                comb_significant = False\n",
    "                if combination_distance_calc > 7:\n",
    "                    comb_significant = True\n",
    "\n",
    "                #Only if at least one of the three players is significantly perturbed\n",
    "                #if no_interaction == False: \n",
    "\n",
    "                #Transform the three lists into numpy arrays\n",
    "                s1_MeanVector_toCalculate = np.array(s1_MeanVector)\n",
    "                s2_MeanVector_toCalculate = np.array(s2_MeanVector)\n",
    "                comb_MeanVector_toCalculate = np.array(combi_Vector)              \n",
    "\n",
    "                #Calculate alpha/beta/gamma\n",
    "                alpha,beta,gamma = calculate_vector_math_v2(s1_MeanVector_toCalculate,s2_MeanVector_toCalculate,comb_MeanVector_toCalculate)\n",
    "\n",
    "\n",
    "                '''\n",
    "                Additionally one can also set non significant vector to the NULL vectors (then the math is forced to only use significant ones)\n",
    "                '''\n",
    "\n",
    "                if s1_significant == False:\n",
    "                    s1_MeanVector_toCalculate = np.array([0]*numfeatures)                                \n",
    "                if s2_significant == False:\n",
    "                    s2_MeanVector_toCalculate = np.array([0]*numfeatures)                      \n",
    "                if comb_significant == False:\n",
    "                    comb_MeanVector_toCalculate = np.array([0]*numfeatures)\n",
    "\n",
    "                \n",
    "                #Calculate alpha_0/beta_0/gamma_0\n",
    "                alpha_0,beta_0,gamma_0 = calculate_vector_math_v2(s1_MeanVector_toCalculate,s2_MeanVector_toCalculate,comb_MeanVector_toCalculate)\n",
    "\n",
    "\n",
    "                '''\n",
    "                CHECK IF THE INTERACTION IS SIGNIFICANT\n",
    "                1. Calculate all possible vector sums of the single vectors\n",
    "                2. Add intracellular plate variability by adding DMSO vectors\n",
    "                3. Calculate the pValue and the Mahalanobis distance of the interaction to this 'possible vector sums'\n",
    "                '''\n",
    "                \n",
    "                \n",
    "                #Get DMSO wells (of this plate) after outlier detection (these serve ONLY as an ADDITIONAL cell fluctation that is added to all NI (vector sums))\n",
    "                DMSO_Wells = dmso_wells_Outlier_Removed[b][plate]\n",
    "\n",
    "                #Calculate all possible NIs and add the DMSO cell fluctuation to them (randomly choose 10 DMSO)\n",
    "                possible_results = []\n",
    "                for s1 in s1_Vectors:\n",
    "                    tmp = []\n",
    "                    for s2 in s2_Vectors:\n",
    "                        vector_sum = np.array(s1) + np.array(s2)\n",
    "                        possible_results.append(vector_sum)\n",
    "                        #random_DMSO_Wells = random.sample(DMSO_Wells,25)\n",
    "                        for DMSO_well in DMSO_Wells:\n",
    "                            possible_results.append(vector_sum+np.array(DMSO_well))\n",
    "\n",
    "                k = list(possible_results)\n",
    "                k.insert(0,combi_Vector)\n",
    "                #Here 500 random tries is already enough since only ca. 250 datapoints in 'possible' results\n",
    "                combination_distance_calc_toNI, combination_mp_toNI, _, _ = Calculate_MahalanobisDistance(k,numberTreatment,number_of_RandomTries = 10000, usePreComputedRandomDistribution = False)\n",
    "\n",
    "\n",
    "                #Make a PCA plot if it is a significant interaction\n",
    "                if combination_distance_calc_toNI > 3:\n",
    "                #if (combination_mp_toNI < 1 and combination_distance_calc_toNI > 0):\n",
    "\n",
    "\n",
    "\n",
    "                    number_vectorsums = len(k)\n",
    "                    #print number_vectorsums\n",
    "\n",
    "                    color = ['#b2182b']*numberTreatment\n",
    "                    for i in range(1,len(k)):\n",
    "                        color.append('blue')\n",
    "\n",
    "                    #DMSO_Wells  = [drug_perturbation_vectors[b][x] for x in drug_perturbation_vectors[b] if 'DMSO,None,'+str(plate) in x and well_cell_count[x]['Number'] > cutoff_min_cells]\n",
    "                    k.extend(DMSO_Wells)\n",
    "\n",
    "                    for i in range(0,len(DMSO_Wells)):\n",
    "                        color.append('grey')\n",
    "\n",
    "                    k.extend(s1_Vectors)\n",
    "                    for i in range(0,len(s1_Vectors)):\n",
    "                        color.append('#e08214')\n",
    "\n",
    "                    k.extend(s2_Vectors)\n",
    "                    for i in range(0,len(s2_Vectors)):\n",
    "                        color.append('#5aae61')\n",
    "\n",
    "\n",
    "                    pca = PCA(n_components=2)\n",
    "                    pca_vals = pca.fit_transform(k)\n",
    "\n",
    "\n",
    "                    if s1_significant:\n",
    "                        cloud1_name = cloud1 +'(+)'\n",
    "                    else:\n",
    "                        cloud1_name = cloud1 +'(-)'\n",
    "\n",
    "                    if s2_significant:\n",
    "                        cloud2_name = cloud2 +'(+)'\n",
    "                    else:\n",
    "                        cloud2_name = cloud2 +'(-)'\n",
    "\n",
    "\n",
    "                    #Create Legend\n",
    "                    legend_elements = [Patch(facecolor='#b2182b', lw=1,\n",
    "                                         label='Combination\\nMahalanobis Distance: %.2f\\n mp = %.2e' % (combination_distance_calc_toNI, combination_mp_toNI)),\n",
    "                                       Patch(facecolor='blue', \n",
    "                                         label='Vector_Sums'),\n",
    "                                       Patch(facecolor='grey', \n",
    "                                         label='DMSO'),\n",
    "                                       Patch(facecolor='#e08214', \n",
    "                                         label=cloud1_name),\n",
    "                                       Patch(facecolor='#5aae61', \n",
    "                                         label=cloud2_name)]\n",
    "\n",
    "                    plt.figure(figsize=(5,5))\n",
    "                    #Plot possible vector sums\n",
    "                    #plt.scatter(pca_vals[:, 0][1:number_vectorsums], pca_vals[:, 1][1:number_vectorsums], c=color[1:number_vectorsums], alpha=0.4)   #0.31 or 0.2\n",
    "                    sns.kdeplot(pca_vals[:, 0][1:number_vectorsums], pca_vals[:, 1][1:number_vectorsums], n_levels=8,cmap=\"Blues\",alpha=0.6,gridsize = 100,shade=True, shade_lowest=False,  bw='scott', kernel='gau' )\n",
    "\n",
    "                    #Plot DMSO, Single1 and Single2\n",
    "                    plt.scatter(pca_vals[:, 0][number_vectorsums:], pca_vals[:, 1][number_vectorsums:], c=color[number_vectorsums:], alpha=0.6)\n",
    "\n",
    "                    #Plot Combination\n",
    "                    plt.scatter(pca_vals[:, 0][0], pca_vals[:, 1][0], c=color[0], alpha=1)\n",
    "\n",
    "                    #Plot Legend\n",
    "                    plt.legend(handles=legend_elements, loc='best', prop={'size': 7})\n",
    "                    plt.xlim([min(pca_vals[:, 0]) - 0.1, max(pca_vals[:, 0])+0.1])\n",
    "                    plt.ylim([min(pca_vals[:, 1]) - 0.1, max(pca_vals[:, 1])+0.1])\n",
    "                    plt.xlabel('PC1 [%.2f]' %(pca.explained_variance_ratio_[0]))\n",
    "                    plt.ylabel('PC2 [%.2f]' %(pca.explained_variance_ratio_[1]))\n",
    "                    plt.savefig('../results/Calculate_Interactions/Combinations/'+cloud1+'_'+cloud2+'.png')\n",
    "                    plt.close()\n",
    "\n",
    "                    \n",
    "                fp_out2.write(cloud1+','+cloud2+','+str(b)+','+plate+','+well+','+str(s1_Mahalanobis)+','+str(s1_MValue)+','+str(s1_Mean_VectorNorm) +','+str(s2_Mahalanobis)+','+str(s2_MValue)+','+str(s2_Mean_VectorNorm)+','+str(combination_distance_calc)+','+str(combination_mp)+','+str(Combi_VectorNorm)+','+str(alpha)+','+str(beta)+','+str(gamma)+','+str(alpha_0)+','+str(beta_0)+','+str(gamma_0)+','+str(combination_distance_calc_toNI)+','+str(combination_mp_toNI) +'\\n')\n",
    "                            \n",
    "fp_out.close()\n",
    "fp_out2.close()\n",
    "\n",
    "print 'Created all interactions'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check single drug fluctuation\n",
    "Make a sham experiment with the single vector only to check how much a specific drug perturbation fluctuates between replicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_fluctuations = {'Batch1':{},'Batch2':{}}\n",
    "\n",
    "if os.path.isfile('../results/Calculate_Interactions/Singles/Fluctuation_Overview.csv'):\n",
    "    fp = open('../results/Calculate_Interactions/Singles/Fluctuation_Overview.csv','r')\n",
    "    fp.next()\n",
    "    for line in fp:\n",
    "        tmp = line.strip().split(',')\n",
    "        #Single_Drug_Significance[tmp[0]] = {'Batch1' : {'Mahalanobis_Distance':float(tmp[1]), 'MP_Value':float(tmp[2]) }, 'Batch2' : {'Mahalanobis_Distance':float(tmp[3]), 'MP_Value':float(tmp[4]) }}                                  \n",
    "else:\n",
    "    \n",
    "    fp = open('../results/Calculate_Interactions/Singles/Fluctuation_Overview.csv','w')\n",
    "    fp.write('CLOUD,Batch1_AlphaBetaMean,Batch1_AlphaBetaStd,Batch1_GammaMean,Batch1_GammaStd,Batch2_AlphaBetaMean,Batch2_AlphaBetaStd,Batch2_GammaMean,Batch2_GammaStd\\n')\n",
    "    for cloud in All_CLOUDs:\n",
    "        for batch in ['Batch1','Batch2']:\n",
    "            single_Vectors = drug_vectors_WithoutOutliers[batch][cloud]\n",
    "            \n",
    "            \n",
    "            if len(single_Vectors) < 3:\n",
    "                drug_fluctuations[batch][cloud] = {'Mean_AlphaBeta':'Too_Fluctuate', 'Std_AlphaBeta':'Too_Fluctuate','Mean_Gamma':'Too_Fluctuate', 'Std_Gamma':'Too_Fluctuate'}\n",
    "            else:\n",
    "\n",
    "\n",
    "                alpha_beta = []\n",
    "                gamma = []\n",
    "\n",
    "                for vector1 in single_Vectors:\n",
    "                    for vector2 in single_Vectors:\n",
    "                        for vector3 in single_Vectors:\n",
    "                            if vector1 != vector2 and vector1 != vector3 and vector2 != vector3:\n",
    "\n",
    "                                s1 = np.array(single_Vectors[vector1]) * 0.5\n",
    "                                s2 = np.array(single_Vectors[vector2]) * 0.5\n",
    "                                c = np.array(single_Vectors[vector3])\n",
    "\n",
    "\n",
    "                                a,b,g = calculate_vector_math_v2(s1,s2,c)\n",
    "\n",
    "                                alpha_beta.append(float(a))\n",
    "                                alpha_beta.append(float(b))\n",
    "                                gamma.append(float(g))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                drug_fluctuations[batch][cloud] = {'Mean_AlphaBeta':np.mean(alpha_beta), 'Std_AlphaBeta':np.std(alpha_beta),'Mean_Gamma':np.mean(gamma), 'Std_Gamma':np.std(gamma)}\n",
    "\n",
    "\n",
    "    \n",
    "    for cloud in All_CLOUDs:\n",
    "        fp.write(cloud+',' + str(drug_fluctuations['Batch1'][cloud]['Mean_AlphaBeta'])+',' + str(drug_fluctuations['Batch1'][cloud]['Std_AlphaBeta'])+',' + str(drug_fluctuations['Batch1'][cloud]['Mean_Gamma'])+',' + str(drug_fluctuations['Batch1'][cloud]['Std_Gamma'])+',' + str(drug_fluctuations['Batch2'][cloud]['Mean_AlphaBeta'])+',' + str(drug_fluctuations['Batch2'][cloud]['Std_AlphaBeta'])+',' + str(drug_fluctuations['Batch2'][cloud]['Mean_Gamma'])+',' + str(drug_fluctuations['Batch2'][cloud]['Std_Gamma'])+'\\n')\n",
    "    fp.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repair interaction files\n",
    "In case something has to be added or removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "mypath = '../results/Calculate_Interactions/MC_Scores/'\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "\n",
    "for file in onlyfiles:\n",
    "    print file\n",
    "    fp_out = open('../results/Calculate_Interactions/MC_ScoresNew/'+file,'w')\n",
    "    \n",
    "    fp = open(mypath+file)\n",
    "\n",
    "    fp_out.write(fp.readline())\n",
    "    for line in fp:\n",
    "        tmp = line.strip().split(',')\n",
    "        \n",
    "        cloud1 = tmp[0]\n",
    "        cloud2 = tmp[1]\n",
    "        b = tmp[2]\n",
    "        plate = tmp[3]\n",
    "        well = tmp[4]\n",
    "        \n",
    "        combination_well =  [x for x in well_cell_count if cloud1+','+cloud2 in x or cloud2+','+cloud1 in x]\n",
    "        combi_Number =  well_cell_count[combination_well[0]]['Number']\n",
    "        \n",
    "        if combi_Number < cutoff_min_cells:\n",
    "             fp_out.write(cloud1+','+cloud2+','+str(b)+','+plate+','+well+','+','.join(['CytotoxicDrug']*19)+'\\n')\n",
    "        else:\n",
    "            fp_out.write(line)\n",
    "    fp.close()\n",
    "    fp_out.close()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all files\n",
    "This is only important if the clustered or any other tool is used to calculate the individual results files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make Summary File\n",
      "MC_Scores:\n",
      "Done\n",
      "Bliss_Scores:\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print 'Make Summary File'\n",
    "print 'MC_Scores:'\n",
    "MC_Score_Files = [f for f in os.listdir('../results/Calculate_Interactions/MC_Scores/') if os.path.isfile(os.path.join('../results/Calculate_Interactions/MC_Scores/', f))]\n",
    "MC_Score_Files.sort()\n",
    "fp_out = open('../results/Calculate_Interactions/All_MC_Scores.csv','w')\n",
    "fp_out.write('Drug1,Drug2,Batch,Plate,Well,S1_Mahalanobis,S1_MPValue,S1_Norm,S2_Mahalanobis,S2_MPValue,S2_Norm,Combi_Mahalanobis,Combi_MPValue,Combi_Norm_Norm,Alpha,Beta,Gamma,Alpha_Zero,Beta_Zero,Gamma_Zero,DistanceFromOrigin,Mahalanobis_Distance_To_NI,MPValue_To_NI\\n')\n",
    "for file_name in MC_Score_Files:\n",
    "    fp = open('../results/Calculate_Interactions/MC_Scores/'+file_name,'r')\n",
    "    fp.next()\n",
    "    for line in fp:\n",
    "        fp_out.write(line)\n",
    "    fp.close()\n",
    "fp_out.close()\n",
    "print 'Done'\n",
    "\n",
    "print 'Bliss_Scores:'\n",
    "Bliss_Score_Files = [f for f in os.listdir('../results/Calculate_Interactions/Bliss_Scores/') if os.path.isfile(os.path.join('../results/Calculate_Interactions/Bliss_Scores/', f))]\n",
    "Bliss_Score_Files.sort()\n",
    "fp_out = open('../results/Calculate_Interactions/All_Bliss_Scores.csv','w')\n",
    "fp_out.write('Drug1,Drug2,Batch,Plate,Well,S1,S2,C,Expected,Difference\\n')\n",
    "for file_name in Bliss_Score_Files:\n",
    "    fp = open('../results/Calculate_Interactions/Bliss_Scores/'+file_name,'r')\n",
    "    fp.next()\n",
    "    for line in fp:\n",
    "        fp_out.write(line)\n",
    "    fp.close()\n",
    "fp_out.close()\n",
    "print 'Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
